This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: **/.git/**, **/.vscode/**, **/.idea/**, **/.venv/**, **/venv/**, **/node_modules/**, **/dist/**, **/build/**, **/.svelte-kit/**, **/.ruff_cache/**, **/.pytest_cache/**, **/__pycache__/**, **/test-results/**, **/playwright-report/**, **/blob-report/**, **/coverage/**, **/report/**, **/reports/**, **/logs/**, **/media/**, **/assets/**, **/package-lock.json, **/pnpm-lock.yaml, **/yarn.lock, **/*.lock, **/*.log, **/*.map, **/*.csv, **/*.pdf, **/*.ico, **/*.png, **/*.jpg, **/*.jpeg, **/*.gif, **/*.webp, **/*.mp3, **/*.mp4, **/*.wav, **/*.svg, **/*.min.js, **/*.min.css, repomix_output.txt, all_package_jsons.txt, GEMINI.md
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
.dockerignore
.gitignore
.spectral.yaml
apps/ai-service/.gitignore
apps/ai-service/core/__init__.py
apps/ai-service/core/filter.py
apps/ai-service/core/interfaces.py
apps/ai-service/core/transcriber.py
apps/ai-service/core/translator.py
apps/ai-service/debug_warnings.py
apps/ai-service/Dockerfile
apps/ai-service/gen_openapi.py
apps/ai-service/main.py
apps/ai-service/openapi.json
apps/ai-service/pyproject.toml
apps/ai-service/requirements.txt
apps/ai-service/tests/manual/test_analyze.py
apps/ai-service/tests/manual/test_transcribe.py
apps/ai-service/tests/manual/test_translate.py
apps/ai-service/tests/test_api.py
apps/ai-service/tests/test_batch_processing.py
apps/ai-service/tests/test_integration.py
apps/platform/.dependency-cruiser.cjs
apps/platform/.env.test
apps/platform/.gitignore
apps/platform/.jscpd.json
apps/platform/.markdownlint.json
apps/platform/.markdownlintignore
apps/platform/.npmrc
apps/platform/.secretlintrc.json
apps/platform/components.json
apps/platform/Dockerfile
apps/platform/eslint.config.js
apps/platform/package.json
apps/platform/playwright.config.ts
apps/platform/postcss.config.js
apps/platform/README.md
apps/platform/scripts/e2e-standalone.ts
apps/platform/scripts/e2e-trigger.ts
apps/platform/scripts/test-brain-connection.ts
apps/platform/src/app.css
apps/platform/src/app.d.ts
apps/platform/src/app.html
apps/platform/src/hooks.server.ts
apps/platform/src/lib/auth-client.ts
apps/platform/src/lib/components/GameOverlay.svelte
apps/platform/src/lib/components/ui/badge/badge.svelte
apps/platform/src/lib/components/ui/badge/index.ts
apps/platform/src/lib/components/ui/button/button.svelte
apps/platform/src/lib/components/ui/button/index.ts
apps/platform/src/lib/components/ui/card/card-action.svelte
apps/platform/src/lib/components/ui/card/card-content.svelte
apps/platform/src/lib/components/ui/card/card-description.svelte
apps/platform/src/lib/components/ui/card/card-footer.svelte
apps/platform/src/lib/components/ui/card/card-header.svelte
apps/platform/src/lib/components/ui/card/card-title.svelte
apps/platform/src/lib/components/ui/card/card.svelte
apps/platform/src/lib/components/ui/card/index.ts
apps/platform/src/lib/components/ui/input/index.ts
apps/platform/src/lib/components/ui/input/input.svelte
apps/platform/src/lib/components/ui/select/index.ts
apps/platform/src/lib/components/ui/select/select-content.svelte
apps/platform/src/lib/components/ui/select/select-group-heading.svelte
apps/platform/src/lib/components/ui/select/select-group.svelte
apps/platform/src/lib/components/ui/select/select-item.svelte
apps/platform/src/lib/components/ui/select/select-label.svelte
apps/platform/src/lib/components/ui/select/select-portal.svelte
apps/platform/src/lib/components/ui/select/select-scroll-down-button.svelte
apps/platform/src/lib/components/ui/select/select-scroll-up-button.svelte
apps/platform/src/lib/components/ui/select/select-separator.svelte
apps/platform/src/lib/components/ui/select/select-trigger.svelte
apps/platform/src/lib/components/ui/select/select.svelte
apps/platform/src/lib/components/ui/separator/index.ts
apps/platform/src/lib/components/ui/separator/separator.svelte
apps/platform/src/lib/constants.ts
apps/platform/src/lib/logger.ts
apps/platform/src/lib/server/adapters/mock-ai-gateway.ts
apps/platform/src/lib/server/adapters/real-ai-gateway.ts
apps/platform/src/lib/server/domain/interfaces.ts
apps/platform/src/lib/server/infrastructure/auth.ts
apps/platform/src/lib/server/infrastructure/brain-api.d.ts
apps/platform/src/lib/server/infrastructure/config.ts
apps/platform/src/lib/server/infrastructure/container.ts
apps/platform/src/lib/server/infrastructure/database.ts
apps/platform/src/lib/server/infrastructure/event-bus.ts
apps/platform/src/lib/server/services/chunker.integration.test.ts
apps/platform/src/lib/server/services/chunker.service.test.ts
apps/platform/src/lib/server/services/chunker.service.ts
apps/platform/src/lib/server/services/knowledge.integration.test.ts
apps/platform/src/lib/server/services/knowledge.service.ts
apps/platform/src/lib/server/services/linguistic-filter.integration.test.ts
apps/platform/src/lib/server/services/linguistic-filter.service.test.ts
apps/platform/src/lib/server/services/linguistic-filter.service.ts
apps/platform/src/lib/server/services/subtitle.integration.test.ts
apps/platform/src/lib/server/services/subtitle.service.ts
apps/platform/src/lib/server/services/task-registry.service.ts
apps/platform/src/lib/server/services/video-orchestrator.integration.test.ts
apps/platform/src/lib/server/services/video-orchestrator.service.test.ts
apps/platform/src/lib/server/services/video-orchestrator.service.ts
apps/platform/src/lib/server/utils/media-utils.ts
apps/platform/src/lib/server/utils/subtitle-utils.ts
apps/platform/src/lib/utils.ts
apps/platform/src/routes/+layout.svelte
apps/platform/src/routes/+page.svelte
apps/platform/src/routes/api/auth/[...auth]/+server.ts
apps/platform/src/routes/api/debug/filter/+server.ts
apps/platform/src/routes/api/debug/transcribe/+server.ts
apps/platform/src/routes/api/debug/translate/+server.ts
apps/platform/src/routes/api/game/generate/+server.ts
apps/platform/src/routes/api/health/+server.ts
apps/platform/src/routes/api/log/+server.ts
apps/platform/src/routes/api/process/[id]/+server.ts
apps/platform/src/routes/api/videos/[id]/subtitles/+server.ts
apps/platform/src/routes/api/videos/+server.ts
apps/platform/src/routes/api/words/known/+server.ts
apps/platform/src/routes/debug/+page.svelte
apps/platform/src/routes/profile/+page.server.ts
apps/platform/src/routes/profile/+page.svelte
apps/platform/src/routes/studio/+page.server.ts
apps/platform/src/routes/studio/+page.svelte
apps/platform/src/routes/studio/upload/+page.server.ts
apps/platform/src/routes/studio/upload/+page.svelte
apps/platform/src/routes/watch/[id]/+page.server.ts
apps/platform/src/routes/watch/[id]/+page.svelte
apps/platform/static/robots.txt
apps/platform/svelte.config.js
apps/platform/tailwind.config.js
apps/platform/tests/e2e/full-flow.spec.ts
apps/platform/tests/integration/transcription.spec.ts
apps/platform/tests/pages/PlayerPage.ts
apps/platform/tests/pages/StudioPage.ts
apps/platform/tests/pages/UploadPage.ts
apps/platform/tsconfig.json
apps/platform/vite.config.ts
docs/architecture/ADR-001-master.md
docs/architecture/ADR-005-di-testing.md
docs/architecture/ADR-006-frontend-stack.md
docs/architecture/ADR-007-idiomatic-backend-patterns.md
docs/CODE_REVIEW_REPORT.md
docs/specs/functional-specs.md
infra/docker-compose.test.yml
infra/docker-compose.yml
package.json
packages/database/drizzle.config.ts
packages/database/eslint.config.js
packages/database/package.json
packages/database/schema.ts
packages/database/seed.ts
restart_all.bat
scripts/generate_audio.py
start_docker.bat
stop_docker.bat

================================================================
Files
================================================================

================
File: .dockerignore
================
.git
node_modules
**/node_modules
venv
**/venv
media
apps/platform/.svelte-kit
apps/ai-service/__pycache__
*.log
.pytest_cache
.ruff_cache

================
File: .gitignore
================
# Dependencies
node_modules
.pnpm-store

# Environment Variables
.env
.env.*
!.env.example
!.env.test

# Build Outputs
dist/
build/
.output/
.svelte-kit/
.vercel/
.netlify/
.wrangler/

# Python / AI Service
__pycache__/
*.py[cod]
*$py.class
venv/
.venv/
.pytest_cache/
.ruff_cache/
.coverage
htmlcov/

# Logs
logs/
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*

# OS / IDE
.DS_Store
Thumbs.db
.idea/
.vscode/
*.swp
*.swo

# Media / Uploads
media/uploads/*
!media/uploads/.gitkeep
# (Optional: Ignore all media if it's strictly local dev data)
# media/*

# Repomix / AI Context
codebase.txt
repomix-output.xml
repomix.config.json
.repomixignore
GEMINI.md
plan.txt

# Playwright
test-results/
playwright-report/
blob-report/
node_modules

================
File: .spectral.yaml
================
extends: ["spectral:oas"]

================
File: apps/ai-service/.gitignore
================
venv/
__pycache__/
*.pyc

================
File: apps/ai-service/core/__init__.py
================


================
File: apps/ai-service/core/filter.py
================
import spacy
import structlog
from .interfaces import IFilter, TokenAnalysis
from typing import List, Dict

logger = structlog.get_logger()

class SpacyFilter(IFilter):
    def __init__(self):
        self._models: Dict[str, spacy.language.Language] = {}

    def _get_model(self, lang: str):
        if lang not in self._models:
            model_name = "es_core_news_lg" if lang == "es" else "en_core_web_sm"
            logger.info("loading_spacy_model", model=model_name)
            try:
                self._models[lang] = spacy.load(model_name)
            except OSError as e:
                logger.error("model_not_found", model=model_name)
                raise RuntimeError(
                    f"Spacy model {model_name} not found. "
                    "Ensure it is installed in the container image."
                ) from e
        return self._models[lang]

    def analyze(self, text: str, language: str) -> List[TokenAnalysis]:
        nlp = self._get_model(language)
        doc = nlp(text)
        
        tokens = []
        for token in doc:
            tokens.append(TokenAnalysis(
                text=token.text,
                lemma=token.lemma_,
                pos=token.pos_,
                is_stop=token.is_stop
            ))
        return tokens

    def analyze_batch(
        self, 
        texts: List[str], 
        language: str
    ) -> List[List[TokenAnalysis]]:
        nlp = self._get_model(language)
        # Using nlp.pipe for efficient batch processing
        docs = list(nlp.pipe(texts))
        
        results = []
        for doc in docs:
            tokens = []
            for token in doc:
                tokens.append(TokenAnalysis(
                    text=token.text,
                    lemma=token.lemma_,
                    pos=token.pos_,
                    is_stop=token.is_stop
                ))
            results.append(tokens)
        return results

================
File: apps/ai-service/core/interfaces.py
================
from abc import ABC, abstractmethod
from typing import List, Optional
from pydantic import BaseModel

class Segment(BaseModel):
    start: float
    end: float
    text: str

class TokenAnalysis(BaseModel):
    text: str
    lemma: str
    pos: str
    is_stop: bool
    translation: Optional[str] = None

class TranscriptionResult(BaseModel):
    segments: List[Segment]
    language: str
    language_probability: float

class ITranscriber(ABC):
    @abstractmethod
    def transcribe(
        self, 
        file_path: str, 
        language: Optional[str] = None
    ) -> TranscriptionResult:
        pass

class IFilter(ABC):
    @abstractmethod
    def analyze(self, text: str, language: str) -> List[TokenAnalysis]:
        pass

    @abstractmethod
    def analyze_batch(
        self, 
        texts: List[str], 
        language: str
    ) -> List[List[TokenAnalysis]]:
        pass

class ITranslator(ABC):
    @abstractmethod
    def translate(
        self, 
        texts: List[str], 
        source_lang: str, 
        target_lang: str
    ) -> List[str]:
        pass

================
File: apps/ai-service/core/transcriber.py
================
from typing import Optional
import torch
import structlog
from faster_whisper import WhisperModel
from .interfaces import ITranscriber, TranscriptionResult, Segment

logger = structlog.get_logger()

class WhisperTranscriber(ITranscriber):
    def __init__(self, model_size="tiny", device=None, compute_type="float32"):
        if device is None:
            device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = WhisperModel(model_size, device=device, compute_type=compute_type)

    def transcribe(
        self, 
        file_path: str, 
        language: Optional[str] = None
    ) -> TranscriptionResult:
        segments, info = self.model.transcribe(
            file_path, 
            language=language, 
            beam_size=5
        )

        result_segments = []
        for s in segments:
            result_segments.append(Segment(start=s.start, end=s.end, text=s.text))

        logger.info(
            "whisper_detected_language",
            language=info.language,
            probability=info.language_probability
        )

        return TranscriptionResult(
            segments=result_segments,
            language=info.language,
            language_probability=info.language_probability
        )

    def transcribe_stream(self, file_path: str, language: Optional[str] = None):
        segments, info = self.model.transcribe(
            file_path, 
            language=language, 
            beam_size=5
        )

        logger.info(
            "whisper_stream_detected_language",
            language=info.language,
            probability=info.language_probability
        )

        # Yield initial info
        yield {"language": info.language, "probability": info.language_probability}

        for segment in segments:
            yield {
                "start": segment.start,
                "end": segment.end,
                "text": segment.text
            }

================
File: apps/ai-service/core/translator.py
================
from typing import List
import torch
import structlog
from transformers import MarianMTModel, MarianTokenizer
from .interfaces import ITranslator

logger = structlog.get_logger()

class OpusTranslator(ITranslator):
    def __init__(self, device=None):
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self._models = {}

    def _get_model(self, source_lang: str, target_lang: str):
        model_name = f"Helsinki-NLP/opus-mt-{source_lang}-{target_lang}"
        if model_name not in self._models:
            logger.info("loading_marian_model", model_name=model_name)
            tokenizer = MarianTokenizer.from_pretrained(model_name)
            model = MarianMTModel.from_pretrained(model_name).to(self.device)
            self._models[model_name] = (tokenizer, model)
        return self._models[model_name]

    def translate(
        self, 
        texts: List[str], 
        source_lang: str, 
        target_lang: str
    ) -> List[str]:
        tokenizer, model = self._get_model(source_lang, target_lang)

        # Batch size for translation
        batch_size = 32
        translated_texts = []

        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i : i + batch_size]

            inputs = tokenizer(
                batch_texts, 
                return_tensors="pt", 
                padding=True, 
                truncation=True
            ).to(self.device)

            with torch.no_grad():
                generated = model.generate(**inputs)

            batch_translations = tokenizer.batch_decode(
                generated, 
                skip_special_tokens=True
            )
            translated_texts.extend(batch_translations)

        logger.info(
            "translation_complete", 
            count=len(translated_texts), 
            source=source_lang, 
            target=target_lang
        )
        return translated_texts

================
File: apps/ai-service/debug_warnings.py
================
import warnings

# Filter to ensure we see the warning
warnings.simplefilter('always', DeprecationWarning)

print("--- Testing imports ---")

try:
    print("Importing sentencepiece...")
    print("sentencepiece imported.")
except Exception as e:
    print(f"sentencepiece failed: {e}")

try:
    print("Importing google.protobuf...")
    print("google.protobuf imported.")
except Exception as e:
    print(f"google.protobuf failed: {e}")

try:
    print("Importing onnxruntime...")
    print("onnxruntime imported.")
except Exception as e:
    print(f"onnxruntime failed: {e}")

try:
    print("Importing faster_whisper...")
    print("faster_whisper imported.")
except Exception as e:
    print(f"faster_whisper failed: {e}")

================
File: apps/ai-service/Dockerfile
================
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
# hadolint ignore=DL3008
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    git \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY apps/ai-service/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt && \
    rm -rf /root/.cache/pip

# Pre-download models
RUN python -m spacy download es_core_news_lg && \
    python -m spacy download en_core_web_sm && \
    rm -rf /root/.cache/pip

# Copy source code
COPY apps/ai-service/ .

# Create non-root user for security
RUN useradd -m appuser && chown -R appuser /app
USER appuser

# Expose API port
EXPOSE 8000

# Start the application
CMD ["python", "main.py"]

================
File: apps/ai-service/gen_openapi.py
================
import json
from main import app
from fastapi.openapi.utils import get_openapi

def generate_openapi():
    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        openapi_version=app.openapi_version,
        description=app.description,
        routes=app.routes,
        tags=app.openapi_tags,
        servers=app.servers
    )
    with open("openapi.json", "w") as f:
        json.dump(openapi_schema, f, indent=2)
    print("Successfully generated openapi.json")

if __name__ == "__main__":
    generate_openapi()

================
File: apps/ai-service/main.py
================
from fastapi import FastAPI, HTTPException, Security, Depends, Request
from fastapi.responses import JSONResponse
from fastapi.security.api_key import APIKeyHeader
from pydantic import BaseModel, field_validator
from typing import List, Annotated
import uvicorn
import os
import structlog
import torch
import shlex
import subprocess
import logging
from pathlib import Path
from contextlib import asynccontextmanager

# Silence TensorFlow oneDNN warnings
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

from core.interfaces import Segment, TokenAnalysis
from core.transcriber import WhisperTranscriber
from core.filter import SpacyFilter
from core.translator import OpusTranslator

# --- Security ---
API_KEY_NAME = "X-API-Key"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)

def get_api_key(
    api_key_header_val: str = Security(api_key_header),
):
    expected_api_key = os.getenv("AI_SERVICE_API_KEY")
    if not expected_api_key:
        return None
    
    if api_key_header_val == expected_api_key:
        return api_key_header_val
    else:
        raise HTTPException(
            status_code=403,
            detail="Could not validate API Key",
        )

# --- Logging ---
# Ensure logs directory exists
# Ensure logs directory exists
LOGS_DIR = Path(os.getenv("LOGS_DIR", "logs")).resolve()
LOGS_DIR.mkdir(exist_ok=True, parents=True)

# Configure standard logging (File + Stdout)
# We clear existing handlers to avoid duplication if reloaded (though in main.py usually safe)
logging.root.handlers = []

structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.JSONRenderer()
    ],
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

std_logger = logging.getLogger()
std_logger.setLevel(logging.INFO)
std_logger.addHandler(logging.StreamHandler())
std_logger.addHandler(logging.FileHandler(LOGS_DIR / "ai-service.log"))

logger = structlog.get_logger()

# --- Models ---
class ThumbnailRequest(BaseModel):
    file_path: str

    @field_validator('file_path')
    @classmethod
    def path_must_exist(cls, v: str) -> str:
        if not os.path.exists(v):
            raise ValueError(f"File not found: {v}")
        return v

class ThumbnailResponse(BaseModel):
    thumbnail_path: str

class TranscriptionRequest(BaseModel):
    file_path: str
    language: str = "es"

    @field_validator('file_path')
    @classmethod
    def path_must_exist(cls, v: str) -> str:
        if not os.path.exists(v):
            raise ValueError(f"File not found: {v}")
        return v

class TranscriptionResponse(BaseModel):
    segments: List[Segment]
    language: str
    language_probability: float

class TranslationRequest(BaseModel):
    texts: List[str]
    source_lang: str = "es"
    target_lang: str = "en"

class TranslationResponse(BaseModel):
    translations: List[str]

class FilterRequest(BaseModel):
    texts: List[str]
    language: str = "es"

class FilterResponse(BaseModel):
    results: List[List[TokenAnalysis]]

# --- State ---
class BrainState:
    def __init__(self):
        self.transcriber: WhisperTranscriber | None = None
        self.filter: SpacyFilter | None = None
        self.translator: OpusTranslator | None = None

brain_state = BrainState()

# --- Dependencies ---
def get_transcriber():
    return brain_state.transcriber

def get_filter():
    return brain_state.filter

def get_translator():
    return brain_state.translator

TranscriberDep = Annotated[WhisperTranscriber, Depends(get_transcriber)]
FilterDep = Annotated[SpacyFilter, Depends(get_filter)]
TranslatorDep = Annotated[OpusTranslator, Depends(get_translator)]

@asynccontextmanager
async def lifespan(_app: FastAPI):
    logger.info("startup_models_loading")
    brain_state.transcriber = WhisperTranscriber(model_size="tiny")
    brain_state.filter = SpacyFilter()
    brain_state.translator = OpusTranslator()
    logger.info("startup_models_loaded")
    yield
    logger.info("shutdown_cleanup")

# --- App ---
app = FastAPI(
    title="AI Service", 
    version="1.0.0",
    description=(
        "Stateless AI worker for transcription, translation "
        "and linguistic analysis."
    ),
    dependencies=[Depends(get_api_key)],
    lifespan=lifespan,
    servers=[{
        "url": "http://ai-service:8000", 
        "description": "Internal Docker Network"
    }],
    openapi_tags=[
        {
            "name": "AI", 
            "description": "AI-powered linguistic services (Whisper, SpaCy, MarianMT)."
        },
        {
            "name": "Media", 
            "description": "Media processing services (FFmpeg)."
        },
        {
            "name": "System", 
            "description": "Infrastructure and health check endpoints."
        }
    ]
)

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error("global_error", path=request.url.path, error=str(exc))
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal AI Service Error", "message": str(exc)},
    )

@app.post(
    "/generate_thumbnail", 
    response_model=ThumbnailResponse, 
    tags=["Media"], 
    description="Generates a thumbnail from a video file using FFmpeg."
)
async def generate_thumbnail(req: ThumbnailRequest):
    logger.info(
        "request_received", 
        endpoint="/generate_thumbnail", 
        file_path=req.file_path
    )
    
    base, _ = os.path.splitext(req.file_path)
    thumb_path = f"{base}.jpg"
    
    cmd = [
        "ffmpeg", "-y", "-i", req.file_path, 
        "-ss", "00:00:01", "-vframes", "1", thumb_path
    ]
    logger.info("running_ffmpeg", command=shlex.join(cmd))
    
    # S603: input is sanitized via shlex.join before execution
    process = subprocess.run( # noqa: S603
        cmd, 
        capture_output=True,
        check=True, # Ensure errors are raised
        text=True
    )
    # Process return code handled by check=True, but retaining explicit check for clarity if needed
    if process.returncode != 0:
            raise Exception(f"ffmpeg failed: {process.stderr}")
    return ThumbnailResponse(thumbnail_path=thumb_path)

@app.post(
    "/transcribe", 
    response_model=TranscriptionResponse, 
    tags=["AI"], 
    description="Transcribes an audio file using Faster-Whisper."
)
async def transcribe(
    req: TranscriptionRequest,
    transcriber: TranscriberDep
):
    logger.info(
        "request_received", 
        endpoint="/transcribe", 
        file_path=req.file_path
    )
    result = transcriber.transcribe(req.file_path, req.language)
    return TranscriptionResponse(
        segments=result.segments,
        language=result.language,
        language_probability=result.language_probability
    )

@app.post(
    "/translate", 
    response_model=TranslationResponse, 
    tags=["AI"], 
    description="Translates a batch of texts using MarianMT models."
)
async def translate(
    req: TranslationRequest,
    translator: TranslatorDep
):
    translations = translator.translate(req.texts, req.source_lang, req.target_lang)
    return TranslationResponse(translations=translations)

@app.post(
    "/filter", 
    response_model=FilterResponse, 
    tags=["AI"], 
    description="Analyzes a batch of texts using SpaCy for linguistic filtering."
)
async def filter_text(
    req: FilterRequest,
    text_filter: FilterDep
):
    results = text_filter.analyze_batch(req.texts, req.language)
    return FilterResponse(results=results)

@app.get("/health", tags=["System"], description="Health check endpoint.")
async def health():
    return {"status": "ai_service_active", "gpu": torch.cuda.is_available()}

if __name__ == "__main__":
    # S104: Binding to all interfaces is required for Docker containerization
    uvicorn.run(app, host="0.0.0.0", port=8000) # noqa: S104

================
File: apps/ai-service/openapi.json
================
{
  "openapi": "3.1.0",
  "info": {
    "title": "AI Service",
    "version": "1.0.0",
    "description": "Stateless AI worker for transcription, translation and linguistic analysis."
  },
  "servers": [
    {
      "url": "http://ai-service:8000",
      "description": "Internal Docker Network"
    }
  ],
  "paths": {
    "/generate_thumbnail": {
      "post": {
        "tags": [
          "Media"
        ],
        "summary": "Generate Thumbnail",
        "description": "Generates a thumbnail from a video file using FFmpeg.",
        "operationId": "generate_thumbnail_generate_thumbnail_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ThumbnailRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ThumbnailResponse"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        },
        "security": [
          {
            "APIKeyHeader": []
          }
        ]
      }
    },
    "/transcribe": {
      "post": {
        "tags": [
          "AI"
        ],
        "summary": "Transcribe",
        "description": "Transcribes an audio file using Faster-Whisper.",
        "operationId": "transcribe_transcribe_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TranscriptionRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/TranscriptionResponse"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        },
        "security": [
          {
            "APIKeyHeader": []
          }
        ]
      }
    },
    "/translate": {
      "post": {
        "tags": [
          "AI"
        ],
        "summary": "Translate",
        "description": "Translates a batch of texts using MarianMT models.",
        "operationId": "translate_translate_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TranslationRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/TranslationResponse"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        },
        "security": [
          {
            "APIKeyHeader": []
          }
        ]
      }
    },
    "/filter": {
      "post": {
        "tags": [
          "AI"
        ],
        "summary": "Filter Text",
        "description": "Analyzes a batch of texts using SpaCy for linguistic filtering.",
        "operationId": "filter_text_filter_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/FilterRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/FilterResponse"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        },
        "security": [
          {
            "APIKeyHeader": []
          }
        ]
      }
    },
    "/health": {
      "get": {
        "tags": [
          "System"
        ],
        "summary": "Health",
        "description": "Health check endpoint.",
        "operationId": "health_health_get",
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          }
        },
        "security": [
          {
            "APIKeyHeader": []
          }
        ]
      }
    }
  },
  "components": {
    "schemas": {
      "FilterRequest": {
        "properties": {
          "texts": {
            "items": {
              "type": "string"
            },
            "type": "array",
            "title": "Texts"
          },
          "language": {
            "type": "string",
            "title": "Language",
            "default": "es"
          }
        },
        "type": "object",
        "required": [
          "texts"
        ],
        "title": "FilterRequest"
      },
      "FilterResponse": {
        "properties": {
          "results": {
            "items": {
              "items": {
                "$ref": "#/components/schemas/TokenAnalysis"
              },
              "type": "array"
            },
            "type": "array",
            "title": "Results"
          }
        },
        "type": "object",
        "required": [
          "results"
        ],
        "title": "FilterResponse"
      },
      "HTTPValidationError": {
        "properties": {
          "detail": {
            "items": {
              "$ref": "#/components/schemas/ValidationError"
            },
            "type": "array",
            "title": "Detail"
          }
        },
        "type": "object",
        "title": "HTTPValidationError"
      },
      "Segment": {
        "properties": {
          "start": {
            "type": "number",
            "title": "Start"
          },
          "end": {
            "type": "number",
            "title": "End"
          },
          "text": {
            "type": "string",
            "title": "Text"
          }
        },
        "type": "object",
        "required": [
          "start",
          "end",
          "text"
        ],
        "title": "Segment"
      },
      "ThumbnailRequest": {
        "properties": {
          "file_path": {
            "type": "string",
            "title": "File Path"
          }
        },
        "type": "object",
        "required": [
          "file_path"
        ],
        "title": "ThumbnailRequest"
      },
      "ThumbnailResponse": {
        "properties": {
          "thumbnail_path": {
            "type": "string",
            "title": "Thumbnail Path"
          }
        },
        "type": "object",
        "required": [
          "thumbnail_path"
        ],
        "title": "ThumbnailResponse"
      },
      "TokenAnalysis": {
        "properties": {
          "text": {
            "type": "string",
            "title": "Text"
          },
          "lemma": {
            "type": "string",
            "title": "Lemma"
          },
          "pos": {
            "type": "string",
            "title": "Pos"
          },
          "is_stop": {
            "type": "boolean",
            "title": "Is Stop"
          }
        },
        "type": "object",
        "required": [
          "text",
          "lemma",
          "pos",
          "is_stop"
        ],
        "title": "TokenAnalysis"
      },
      "TranscriptionRequest": {
        "properties": {
          "file_path": {
            "type": "string",
            "title": "File Path"
          },
          "language": {
            "type": "string",
            "title": "Language",
            "default": "es"
          }
        },
        "type": "object",
        "required": [
          "file_path"
        ],
        "title": "TranscriptionRequest"
      },
      "TranscriptionResponse": {
        "properties": {
          "segments": {
            "items": {
              "$ref": "#/components/schemas/Segment"
            },
            "type": "array",
            "title": "Segments"
          },
          "language": {
            "type": "string",
            "title": "Language"
          },
          "language_probability": {
            "type": "number",
            "title": "Language Probability"
          }
        },
        "type": "object",
        "required": [
          "segments",
          "language",
          "language_probability"
        ],
        "title": "TranscriptionResponse"
      },
      "TranslationRequest": {
        "properties": {
          "texts": {
            "items": {
              "type": "string"
            },
            "type": "array",
            "title": "Texts"
          },
          "source_lang": {
            "type": "string",
            "title": "Source Lang",
            "default": "es"
          },
          "target_lang": {
            "type": "string",
            "title": "Target Lang",
            "default": "en"
          }
        },
        "type": "object",
        "required": [
          "texts"
        ],
        "title": "TranslationRequest"
      },
      "TranslationResponse": {
        "properties": {
          "translations": {
            "items": {
              "type": "string"
            },
            "type": "array",
            "title": "Translations"
          }
        },
        "type": "object",
        "required": [
          "translations"
        ],
        "title": "TranslationResponse"
      },
      "ValidationError": {
        "properties": {
          "loc": {
            "items": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "integer"
                }
              ]
            },
            "type": "array",
            "title": "Location"
          },
          "msg": {
            "type": "string",
            "title": "Message"
          },
          "type": {
            "type": "string",
            "title": "Error Type"
          }
        },
        "type": "object",
        "required": [
          "loc",
          "msg",
          "type"
        ],
        "title": "ValidationError"
      }
    },
    "securitySchemes": {
      "APIKeyHeader": {
        "type": "apiKey",
        "in": "header",
        "name": "X-API-Key"
      }
    }
  },
  "tags": [
    {
      "name": "AI",
      "description": "AI-powered linguistic services (Whisper, SpaCy, MarianMT)."
    },
    {
      "name": "Media",
      "description": "Media processing services (FFmpeg)."
    },
    {
      "name": "System",
      "description": "Infrastructure and health check endpoints."
    }
  ]
}

================
File: apps/ai-service/pyproject.toml
================
[tool.ruff.lint]
select = ["E", "F", "B", "S"]
ignore = ["E501"] # Ignore Line too long

[tool.ruff.lint.per-file-ignores]
"tests/*" = ["S101"]

[tool.pylint."MESSAGES CONTROL"]
disable = [
    "C0114", # missing-module-docstring
    "C0115", # missing-class-docstring
    "C0116", # missing-function-docstring
]
# Specifically flag global statements as requested
enable = ["global-statement"]

[tool.bandit]
exclude_dirs = ["venv", "tests"]
skips = ["B101"] # Skip assert checks in non-test files if desired, but we exclude tests dir anyway

[tool.pytest.ini_options]
asyncio_default_fixture_loop_scope = "function"

filterwarnings = [
    "ignore::DeprecationWarning:importlib.*:",      # Ignore importlib/SWIG DeprecationWarnings
    "ignore:.*builtin type SwigPyPacked.*:DeprecationWarning",
    "ignore:.*builtin type SwigPyObject.*:DeprecationWarning",
    "ignore:.*builtin type swigvarlink.*:DeprecationWarning"
]

================
File: apps/ai-service/requirements.txt
================
fastapi
uvicorn
faster-whisper
spacy
transformers
sentencepiece
sacremoses
torchaudio
python-multipart
pydantic
structlog
protobuf==3.20.3

================
File: apps/ai-service/tests/manual/test_analyze.py
================
import requests
import json

url = "http://localhost:8000/analyze"
payload = {
    "text": "El gato corre rÃ¡pido en la casa.",
    "language": "es"
}
response = requests.post(url, json=payload, timeout=10)
print(json.dumps(response.json(), indent=2))

================
File: apps/ai-service/tests/manual/test_transcribe.py
================
import requests
import json
import os

url = "http://localhost:8000/transcribe"
# Use absolute path relative to project root
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../../../.."))
file_path = os.path.join(project_root, "media", "test_audio.mp3")

payload = {
    "file_path": file_path
}
response = requests.post(url, json=payload, timeout=60)
print(json.dumps(response.json(), indent=2))

================
File: apps/ai-service/tests/manual/test_translate.py
================
import requests
import json

url = "http://localhost:8000/translate"
payload = {
    "texts": ["Hallo Welt", "Wie geht es dir?"],
    "source_lang": "de",
    "target_lang": "en"
}
response = requests.post(url, json=payload, timeout=30)
print(json.dumps(response.json(), indent=2))

================
File: apps/ai-service/tests/test_api.py
================
from fastapi.testclient import TestClient
from main import app

client = TestClient(app)

def test_health():
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json()["status"] == "ai_service_active"

def test_transcribe_missing_file():
    # Test validation
    response = client.post("/transcribe", json={"file_path": "non_existent.mp3"})
    assert response.status_code == 422 # Pydantic validation error for missing path

================
File: apps/ai-service/tests/test_batch_processing.py
================
import pytest
from unittest.mock import MagicMock
from core.interfaces import TokenAnalysis
from core.filter import SpacyFilter
from core.translator import OpusTranslator

# --- Fixtures ---

@pytest.fixture
def mock_spacy(monkeypatch):
    """Mocks spacy.load and the nlp object."""
    mock_nlp = MagicMock()
    
    # Mock pipe to return a generator of docs
    def mock_pipe(texts):
        for text in texts:
            # Create a simple mock doc
            mock_doc = MagicMock()
            # Mock iteration over doc
            mock_token = MagicMock()
            mock_token.text = text
            mock_token.lemma_ = f"lemma_{text}"
            mock_token.pos_ = "NOUN"
            mock_token.is_stop = False
            mock_doc.__iter__.return_value = [mock_token]
            yield mock_doc
            
    mock_nlp.pipe.side_effect = mock_pipe
    
    # Mock single call
    def mock_call(text):
         mock_doc = MagicMock()
         mock_token = MagicMock()
         mock_token.text = text
         mock_token.lemma_ = f"lemma_{text}"
         mock_token.pos_ = "NOUN"
         mock_token.is_stop = False
         mock_doc.__iter__.return_value = [mock_token]
         return mock_doc
    
    mock_nlp.side_effect = mock_call

    mock_load = MagicMock(return_value=mock_nlp)
    monkeypatch.setattr("spacy.load", mock_load)
    return mock_nlp

@pytest.fixture
def mock_transformers(monkeypatch):
    """Mocks transformers library."""
    mock_tokenizer = MagicMock()
    # Mock tokenizer call to return dict with input_ids
    mock_tokenizer.return_value = {"input_ids": "mock_tensors"}
    # Mock batch_decode
    mock_tokenizer.batch_decode.side_effect = lambda x, skip_special_tokens: [f"trans_{i}" for i in range(len(x))]

    mock_model = MagicMock()
    mock_model.generate.return_value = ["gen_1", "gen_2"] # Dummy return

    monkeypatch.setattr("transformers.MarianTokenizer.from_pretrained", MagicMock(return_value=mock_tokenizer))
    monkeypatch.setattr("transformers.MarianMTModel.from_pretrained", MagicMock(return_value=mock_model))
    
    return mock_tokenizer

# --- Tests ---

def test_filter_analyze_batch_real():
    """Verifies that analyze_batch returns a list of lists of TokenAnalysis using Real Spacy (en_core_web_sm)."""
    spacy_filter = SpacyFilter()
    texts = ["I run", "They ran"]
    
    # We use 'en' because we confirmed 'en_core_web_sm' is installed.
    results = spacy_filter.analyze_batch(texts, "en")
    
    assert isinstance(results, list)
    assert len(results) == 2
    assert isinstance(results[0], list)
    assert isinstance(results[0][0], TokenAnalysis)
    
    # "run" should have lemma "run"
    lemmas_0 = [t.lemma.lower() for t in results[0]]
    assert "run" in lemmas_0

    # "ran" should have lemma "run"
    lemmas_1 = [t.lemma.lower() for t in results[1]]
    assert "run" in lemmas_1
    """Verifies that translate returns a flat list of strings."""
    # We need to monkeypatch the models dict directly or the class logic will try to load real models
    # But since we mocked from_pretrained, it should be fine.
    
    translator = OpusTranslator(device="cpu")
    texts = ["hola", "mundo"]
    
    # We need to override the batch_decode behavior to match our input length for this test to be meaningful
    # logic-wise, effectively mocking the model "generate" output.
    # In the real code: 
    #   batch_texts = texts[i : i + batch_size]
    #   generated = model.generate(...)
    #   batch_translations = tokenizer.batch_decode(generated)
    
    # Let's ensure our mock tokenizer returns the right number of items
    with pytest.MonkeyPatch.context() as m:
         # Refine the mock for this specific test
         mock_tokenizer = MagicMock()
         mock_tokenizer.return_value = MagicMock() # inputs
         mock_tokenizer.batch_decode.side_effect = lambda gens, skip_special_tokens: ["trans_hola", "trans_mundo"]
         
         mock_model = MagicMock()
         mock_model.generate.return_value = "dummy_tensors"

         m.setattr("transformers.MarianTokenizer.from_pretrained", MagicMock(return_value=mock_tokenizer))
         m.setattr("transformers.MarianMTModel.from_pretrained", MagicMock(return_value=mock_model))
         
         translator = OpusTranslator(device="cpu")
         translations = translator.translate(texts, "es", "en")
         
         assert isinstance(translations, list)
         assert len(translations) == 2
         assert isinstance(translations[0], str)
         assert translations[0] == "trans_hola"
         assert translations[1] == "trans_mundo"

================
File: apps/ai-service/tests/test_integration.py
================
import pytest
from pathlib import Path
from fastapi.testclient import TestClient
from main import app
from core.transcriber import WhisperTranscriber
from core.filter import SpacyFilter

# Assets
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
MEDIA_DIR = BASE_DIR / "media"
AUDIO_FILE = MEDIA_DIR / "test_audio.mp3"

@pytest.mark.skipif(not AUDIO_FILE.exists(), reason="Test audio file not found")
def test_transcriber_real():
    """Integration test using real Whisper model (tiny) on CPU."""
    # Use tiny model for speed
    transcriber = WhisperTranscriber(model_size="tiny", device="cpu")
    result = transcriber.transcribe(str(AUDIO_FILE))
    
    assert result is not None
    assert len(result.segments) > 0
    # Basic sanity check on content if known, or just structure
    assert result.language is not None

@pytest.mark.skipif(not AUDIO_FILE.exists(), reason="Test audio file not found")
def test_api_transcribe_with_real_file():
    """Integration test for /transcribe endpoint with real file."""
    with TestClient(app) as client:
        # Service expects a path to a file on disk (shared volume pattern)
        response = client.post("/transcribe", json={"file_path": str(AUDIO_FILE)})
    
    assert response.status_code == 200
    data = response.json()
    assert "segments" in data
    assert len(data["segments"]) > 0

def test_spacy_filter_real():
    """Integration test for SpacyFilter with real model."""
    # SpacyFilter loads en_core_web_sm by default/configured
    spacy_filter = SpacyFilter()
    text = "The quick brown fox jumps over the lazy dog."
    analysis = spacy_filter.analyze(text, language="en")
    
    assert len(analysis) > 0
    assert analysis[0].lemma == "the" # roughly check lemma

================
File: apps/platform/.dependency-cruiser.cjs
================
/** @type {import('dependency-cruiser').IConfiguration} */
module.exports = {
  forbidden: [
    {
      name: 'no-circular',
      severity: 'error',
      from: {},
      to: {
        circular: true
      }
    },
    {
      name: 'no-server-imports-from-client',
      severity: 'error',
      from: {
        path: "^src/lib/server"
      },
      to: {
        path: "^src/lib/components",
        pathNot: "^src/lib/server"
      }
    },
    {
      name: 'no-orphans',
      severity: 'warn',
      from: {
        orphan: true,
        pathNot: [
          "\\.d\\.ts$",
          "\\.spec\\.ts$",
          "\\.test\\.ts$",
          "app\\.d\\.ts",
          "hooks\\.server\\.ts",
          "src/lib/constants\\.ts",
          "src/lib/index\\.ts"
        ]
      },
      to: {}
    }
  ],
  options: {
    doNotFollow: {
      path: 'node_modules'
    },
    tsPreCompilationDeps: true,
    tsConfig: {
      fileName: 'tsconfig.json'
    },
    reporterOptions: {
      dot: {
        theme: {
          graph: { rankdir: "TD" }
        }
      }
    }
  }
};

================
File: apps/platform/.env.test
================
# Test-specific environment overrides
# Loaded when running E2E tests

PLAYWRIGHT_TEST=true
TEST_GAME_INTERVAL=0.1

# These point to Docker network names (used when Platform runs in Docker)
DATABASE_URL=postgres://admin:password@postgres:5432/main_db
AI_SERVICE_URL=http://127.0.0.1:8000
AI_SERVICE_API_KEY=dev_secret_key
BETTER_AUTH_SECRET=long_secret_key_for_dev_only_1234567890
UPLOAD_DIR=/app/media/uploads
RUNNING_IN_DOCKER=true

================
File: apps/platform/.gitignore
================
node_modules

# Output
.output
.vercel
.netlify
.wrangler
/.svelte-kit
/build

# OS
.DS_Store
Thumbs.db

# Env
.env
.env.*
!.env.example
!.env.test

# Vite
vite.config.js.timestamp-*
vite.config.ts.timestamp-*
*.log
test-results/
playwright-report/

================
File: apps/platform/.jscpd.json
================
{
  "threshold": 0,
  "reporters": ["console", "html"],
  "ignore": [
    "**/node_modules/**",
    "**/dist/**",
    "**/.svelte-kit/**",
    "**/test-results/**",
    "**/tests/**",
    "**/*.spec.ts",
    "**/*.test.ts",
    "**/src/routes/api/debug/**",
    "**/package-lock.json"
  ],
  "format": [
    "typescript",
    "javascript",
    "svelte",
    "css",
    "scss"
  ],
  "absolute": true
}

================
File: apps/platform/.markdownlint.json
================
{
  "default": true,
  "MD013": false,
  "MD033": false,
  "MD041": false
}

================
File: apps/platform/.markdownlintignore
================
test-results/
node_modules/
.svelte-kit/
build/
coverage/

================
File: apps/platform/.npmrc
================
engine-strict=true

================
File: apps/platform/.secretlintrc.json
================
{
    "rules": [
        {
            "id": "@secretlint/secretlint-rule-preset-recommend"
        }
    ]
}

================
File: apps/platform/components.json
================
{
	"$schema": "https://shadcn-svelte.com/schema.json",
	"tailwind": {
		"css": "src\\app.css",
		"baseColor": "slate"
	},
	"aliases": {
		"components": "$lib/components",
		"utils": "$lib/utils",
		"ui": "$lib/components/ui",
		"hooks": "$lib/hooks",
		"lib": "$lib"
	},
	"typescript": true,
	"registry": "https://shadcn-svelte.com/registry"
}

================
File: apps/platform/Dockerfile
================
FROM node:20-slim

WORKDIR /app

# Copy shared packages first (dependencies)
# We assume the build context is the repository root
COPY packages/database packages/database

# Install dependencies for packages/database
WORKDIR /app/packages/database
RUN npm install

# Setup Web App
WORKDIR /app/apps/platform
COPY apps/platform/package.json .
# SKIP: COPY apps/platform/package-lock.json .
RUN npm install --legacy-peer-deps && npm cache clean --force

# Copy source
COPY apps/platform .

# Create non-root user for security
RUN useradd -m appuser && chown -R appuser /app
USER appuser

# Expose Vite port
EXPOSE 5173

# Start in dev mode, binding to all interfaces
CMD ["npm", "run", "dev", "--", "--host"]

================
File: apps/platform/eslint.config.js
================
import eslint from '@eslint/js';
import tseslint from 'typescript-eslint';
import svelteParser from 'svelte-eslint-parser';
import eslintPluginSvelte from 'eslint-plugin-svelte';
import sonarjs from 'eslint-plugin-sonarjs';

import testingLibrary from 'eslint-plugin-testing-library';
import vitest from '@vitest/eslint-plugin';
import globals from 'globals';

const MAX_COGNITIVE_COMPLEXITY = 15;
const MAX_CYCLOMATIC_COMPLEXITY = 10;
const MAX_LINES_PER_FUNCTION = 50;

export default tseslint.config(
	eslint.configs.recommended,
	...tseslint.configs.recommended,
	...eslintPluginSvelte.configs['flat/recommended'],
	sonarjs.configs.recommended,
	{
		plugins: {
			'testing-library': testingLibrary,
			'vitest': vitest
		}
	},
	{
		files: ['**/*.test.ts'],
		rules: {
			...vitest.configs.recommended.rules,
			'vitest/no-focused-tests': 'error',
			'vitest/no-disabled-tests': 'warn',
			'vitest/consistent-test-it': ['error', { fn: 'it', withinDescribe: 'it' }],
			'vitest/no-conditional-expect': 'error',
			'vitest/no-identical-title': 'error',
			'vitest/prefer-to-have-length': 'warn',
			'vitest/prefer-expect-resolves': 'warn'
		}
	},
	{
		files: ['**/*.test.ts', '**/*.spec.ts'],
		rules: {
			...testingLibrary.configs.svelte.rules,

			// Testing Library rules
			'testing-library/prefer-user-event': 'warn',
			'testing-library/no-container': 'error',
			'testing-library/no-node-access': 'warn',
			'testing-library/no-debugging-utils': 'warn'
		}
	},
	{
		languageOptions: {
			globals: {
				...globals.browser,
				...globals.node,
				...globals.es2017
			}
		}
	},
	{
		files: ['**/*.svelte'],
		languageOptions: {
			parser: svelteParser,
			parserOptions: {
				parser: tseslint.parser
			}
		}
	},
	{
		rules: {
			'@typescript-eslint/no-explicit-any': 'error',
			'sonarjs/cognitive-complexity': ['error', MAX_COGNITIVE_COMPLEXITY],
			'sonarjs/no-duplicate-string': 'error',
			'sonarjs/no-unused-collection': 'off',
			'complexity': ['error', MAX_CYCLOMATIC_COMPLEXITY],
			'max-lines-per-function': ['error', { max: MAX_LINES_PER_FUNCTION, skipBlankLines: true, skipComments: true }],
			'no-magic-numbers': ['error', { ignore: [0, 1], ignoreArrayIndexes: true }]
		}
	},
	{
		ignores: ['build/', '.svelte-kit/', 'dist/', 'report/', 'src/lib/server/infrastructure/brain-api.d.ts']
	}
);

================
File: apps/platform/package.json
================
{
	"name": "@notflix/platform",
	"private": true,
	"version": "0.0.1",
	"type": "module",
	"scripts": {
		"dev": "vite dev",
		"build": "vite build",
		"preview": "vite preview",
		"prepare": "svelte-kit sync || echo ''",
		"check": "svelte-kit sync && svelte-check --tsconfig ./tsconfig.json",
		"check:watch": "svelte-kit sync && svelte-check --tsconfig ./tsconfig.json --watch",
		"gen:brain-types": "npx openapi-typescript ../../apps/ai-service/openapi.json -o src/lib/server/infrastructure/brain-api.d.ts --export-type",
		"lint": "eslint .",
		"lint:dup": "jscpd src",
		"lint:md": "markdownlint **/*.md",
		"lint:arch": "depcruise src --config .dependency-cruiser.cjs",
		"lint:all": "npm run check && npm run lint && npm run lint:dup && npm run lint:md && npm run lint:arch",
		"lint:contract": "npx @stoplight/spectral-cli lint ../../apps/ai-service/openapi.json --ruleset ../../.spectral.yaml",
		"lint:secrets": "secretlint \"**/*\"",
		"test:e2e": "playwright test",
		"test:e2e:server": "vite dev",
		"test:e2e:docker": "cd ../../infra && docker compose -f docker-compose.yml -f docker-compose.test.yml up -d --wait && cd ../apps/platform && npm run test:e2e; cd ../../infra && docker compose down"
	},
	"devDependencies": {
		"@playwright/test": "^1.57.0",
		"@secretlint/secretlint-rule-preset-recommend": "^11.2.5",
		"@stoplight/spectral-cli": "^6.15.0",
		"@sveltejs/adapter-auto": "^7.0.0",
		"@sveltejs/kit": "^2.48.5",
		"@sveltejs/vite-plugin-svelte": "^6.2.1",
		"@tailwindcss/postcss": "^4.1.18",
		"@vitest/eslint-plugin": "^1.6.4",
		"ajv": "^8.17.1",
		"autoprefixer": "^10.4.22",
		"dependency-cruiser": "^16.6.0",
		"eslint": "^9.39.2",
		"eslint-plugin-sonarjs": "^3.0.5",
		"eslint-plugin-svelte": "^3.13.1",
		"eslint-plugin-testing-library": "^7.15.4",
		"jscpd": "^4.0.5",
		"lucide-svelte": "^0.562.0",
		"markdownlint-cli": "^0.47.0",
		"openapi-typescript": "^7.10.1",
		"postcss": "^8.5.6",
		"secretlint": "^11.2.5",
		"svelte": "^5.46.1",
		"svelte-check": "^4.3.4",
		"tailwindcss": "^4.1.17",
		"tsx": "^4.21.0",
		"typescript": "^5.9.3",
		"typescript-eslint": "^8.50.0",
		"vite": "^7.2.2",
		"vitest": "^4.0.15"
	},
	"dependencies": {
		"@internationalized/date": "^3.10.1",
		"@lucide/svelte": "^0.562.0",
		"@notflix/database": "file:../../packages/database",
		"better-auth": "^1.4.7",
		"bits-ui": "^2.14.4",
		"clsx": "^2.1.1",
		"drizzle-orm": "0.45.1",
		"pino": "^10.1.0",
		"postgres": "^3.4.7",
		"shadcn-svelte": "^1.1.0",
		"svelte-motion": "^0.12.2",
		"tailwind-merge": "^3.4.0",
		"tailwind-variants": "^3.2.2",
		"tailwindcss-animate": "^1.0.7",
		"zod": "^4.3.4"
	}
}

================
File: apps/platform/playwright.config.ts
================
import { type PlaywrightTestConfig } from '@playwright/test';

const config: PlaywrightTestConfig = {
    timeout: 120000, // 2 min for video processing
    retries: process.env.CI ? 2 : 0,

    webServer: {
        command: 'npm run test:e2e:server',
        port: 5173,
        reuseExistingServer: !process.env.CI,
        timeout: 120000,
        env: {
            PLAYWRIGHT_TEST: 'true',
            TEST_GAME_INTERVAL: '0.1'
        }
    },

    testDir: 'tests',
    testMatch: ['**/*.test.ts', '**/*.spec.ts', '**/*.test.js', '**/*.spec.js'],

    use: {
        baseURL: 'http://localhost:5173',
        screenshot: 'only-on-failure',
        video: 'retain-on-failure',
        trace: 'retain-on-failure'
    },

    // Reporter configuration
    reporter: process.env.CI ? 'github' : 'list'
};

export default config;

================
File: apps/platform/postcss.config.js
================
export default {
  plugins: {
    '@tailwindcss/postcss': {},
    autoprefixer: {},
  },
}

================
File: apps/platform/README.md
================
# sv

Everything you need to build a Svelte project, powered by [`sv`](https://github.com/sveltejs/cli).

## Creating a project

If you're seeing this, you've probably already done this step. Congrats!

```sh
# create a new project in the current directory
npx sv create

# create a new project in my-app
npx sv create my-app
```

## Developing

Once you've created a project and installed dependencies with `npm install` (or `pnpm install` or `yarn`), start a development server:

```sh
npm run dev

# or start the server and open the app in a new browser tab
npm run dev -- --open
```

## Building

To create a production version of your app:

```sh
npm run build
```

You can preview the production build with `npm run preview`.

> To deploy your app, you may need to install an [adapter](https://svelte.dev/docs/kit/adapters) for your target environment.

================
File: apps/platform/scripts/e2e-standalone.ts
================
import postgres from 'postgres';
import { drizzle, type PostgresJsDatabase } from 'drizzle-orm/postgres-js';
import * as schema from '@notflix/database';
import { video, videoProcessing, type DbVttSegment, type DbTokenAnalysis } from '@notflix/database';
import { eq } from 'drizzle-orm';
import crypto from 'crypto';

const DATABASE_URL = process.env.DATABASE_URL || 'postgres://admin:password@127.0.0.1:5432/main_db';
const BRAIN_URL = 'http://127.0.0.1:8000';
const TEST_AUDIO_PATH = 'E:/Users/Jonandrop/IdeaProjects/Notflix/media/test_audio.mp3';
const MAX_SEGMENTS_TO_ANALYZE = 3;

async function run() {
    console.log("Starting Standalone E2E...");

    const client = postgres(DATABASE_URL);
    const db = drizzle(client, { schema });

    const videoId = crypto.randomUUID();

    try {
        await insertTestVideo(db, videoId);
        const transcription = await callTranscribe(TEST_AUDIO_PATH);
        const processedSegments = await analyzeSegments(transcription);
        await saveProcessingResults(db, videoId, processedSegments);
        await verifyResults(db, videoId);
    } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        console.error("â E2E Error:", message);
    } finally {
        await client.end();
    }
}

async function insertTestVideo(db: PostgresJsDatabase<typeof schema>, videoId: string) {
    console.log(`Inserting video: ${videoId}`);
    await db.insert(video).values({
        id: videoId,
        title: 'Standalone E2E Video',
        filePath: TEST_AUDIO_PATH,
        thumbnailPath: '/thumb.jpg',
        views: 0,
        published: true
    });
}

interface TranscriptionOutput {
    segments: { start: number; end: number; text: string }[];
}

async function callTranscribe(filePath: string): Promise<TranscriptionOutput> {
    console.log("Calling Python Transcribe...");
    const res = await fetch(`${BRAIN_URL}/transcribe`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ file_path: filePath, language: 'es' })
    });

    if (!res.ok) throw new Error(`Transcribe failed: ${res.statusText}`);
    const data = await res.json() as TranscriptionOutput;
    return data;
}

interface FilterOutput {
    results: DbTokenAnalysis[][];
}

async function analyzeSegments(transcription: TranscriptionOutput): Promise<DbVttSegment[]> {
    console.log("Calling Python Analyze...");
    const processedSegments: DbVttSegment[] = [];
    
    for (const seg of transcription.segments.slice(0, MAX_SEGMENTS_TO_ANALYZE)) {
        const res = await fetch(`${BRAIN_URL}/filter`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ texts: [seg.text], language: 'es' })
        });
        if (!res.ok) throw new Error(`Analyze failed: ${res.statusText}`);
        const analysis = await res.json() as FilterOutput;

        processedSegments.push({
            start: seg.start,
            end: seg.end,
            text: seg.text,
            tokens: analysis.results[0]
        });
    }
    return processedSegments;
}

async function saveProcessingResults(db: PostgresJsDatabase<typeof schema>, videoId: string, segments: DbVttSegment[]) {
    console.log("Saving results to DB...");
    await db.insert(videoProcessing).values({
        videoId: videoId,
        targetLang: 'es',
        status: 'COMPLETED',
        vttJson: segments
    });
}

async function verifyResults(db: PostgresJsDatabase<typeof schema>, videoId: string) {
    const record = await db.query.videoProcessing.findFirst({
        where: eq(videoProcessing.videoId, videoId)
    });

    if (record?.status === 'COMPLETED') {
        console.log("â SUCCESS: E2E Flow Completed.");
        const firstSeg = record.vttJson?.[0];
        console.log("First segment text:", firstSeg?.text);
    } else {
        console.error("â FAILURE: DB record not found or status wrong.");
    }
}

run();

================
File: apps/platform/scripts/e2e-trigger.ts
================
// Use relative imports to avoid alias issues if not configured
import { orchestrator } from '../src/lib/server/infrastructure/container';
import { db } from '../src/lib/server/infrastructure/database';
import { video, videoProcessing } from '@notflix/database';
import { eq } from 'drizzle-orm';
import path from 'path';

const EXIT_CODE_FAILURE = 1;
const EXIT_CODE_SUCCESS = 0;

async function run() {
    console.log("Starting E2E Verification...");

    const videoId = 'test_e2e_' + Date.now();
    const filePath = path.resolve(process.cwd(), '../../media/test_audio.mp3');

    console.log(`Inserting test video: ${videoId}`);
    await db.insert(video).values({
        id: videoId,
        title: 'E2E Test Video',
        filePath: filePath,
        thumbnailPath: '/thumb.jpg',
        views: 0,
        published: true
    });

    console.log("Triggering Orchestrator...");
    try {
        await orchestrator.processVideo(videoId, 'es');
        console.log("Orchestrator finished.");

        // Verify result
        const result = await db.query.videoProcessing.findFirst({
            where: eq(videoProcessing.videoId, videoId)
        });

        if (result?.status === 'COMPLETED' && result.vttJson) {
            console.log("SUCCESS: Video processed and VTT JSON saved.");
            const firstToken = result.vttJson[0]?.tokens[0];
            console.log("Sample Token:", firstToken);
        } else {
            console.error("FAILURE: Processing record not found or not completed.", result);
            process.exit(EXIT_CODE_FAILURE);
        }

    } catch (e) {
        console.error("E2E Error:", e);
        process.exit(EXIT_CODE_FAILURE);
    }

    process.exit(EXIT_CODE_SUCCESS);
}

run();

================
File: apps/platform/scripts/test-brain-connection.ts
================
import { aiGateway } from '../src/lib/server/infrastructure/container';
import path from 'path';

const DEFAULT_JSON_INDENT = 2;

// Mock process.env for the test if running outside full environment
if (!process.env.BRAIN_URL) {
    process.env.BRAIN_URL = 'http://127.0.0.1:8000';
}

async function runIntegrationTest() {
    console.log('Testing Brain Service Integration (via AiGateway)...');

    try {
        // Test 1: Analyze
        console.log('\n--- Testing /filter ---');
        const text = "Integration testing is crucial.";
        const analysis = await aiGateway.analyzeBatch([text], 'en');
        console.log('Analyze Result:', JSON.stringify(analysis, null, DEFAULT_JSON_INDENT));

        if (analysis.results.length > 0) {
            console.log('â Analyze Success');
        } else {
            console.error('â Analyze returned empty results');
        }

        // Test 2: Transcribe
        console.log('\n--- Testing /transcribe ---');
        const audioPath = path.resolve(process.cwd(), '../../media/test_audio.mp3');

        try {
            const transcription = await aiGateway.transcribe(audioPath, 'es');
            console.log('Transcribe Result Language:', transcription.language);
            console.log('Transcribe Prob:', transcription.language_probability);
            console.log('Segments count:', transcription.segments.length);
            if (transcription.segments.length > 0) {
                console.log('â Transcribe Success');
            }
        } catch (err) {
            const message = err instanceof Error ? err.message : String(err);
            console.error('â Transcribe Check Failed (File likely missing or service error):', message);
        }

    } catch (error) {
        console.error('â Integration Test Fatal Error:', error);
    }
}

runIntegrationTest();

================
File: apps/platform/src/app.css
================
@import "tailwindcss";

@custom-variant dark (&:is(.dark *));

:root {
  --radius: 0.625rem;
  --background: oklch(1 0 0);
  --foreground: oklch(0.129 0.042 264.695);
  --card: oklch(1 0 0);
  --card-foreground: oklch(0.129 0.042 264.695);
  --popover: oklch(1 0 0);
  --popover-foreground: oklch(0.129 0.042 264.695);
  --primary: oklch(0.208 0.042 265.755);
  --primary-foreground: oklch(0.984 0.003 247.858);
  --secondary: oklch(0.968 0.007 247.896);
  --secondary-foreground: oklch(0.208 0.042 265.755);
  --muted: oklch(0.968 0.007 247.896);
  --muted-foreground: oklch(0.554 0.046 257.417);
  --accent: oklch(0.968 0.007 247.896);
  --accent-foreground: oklch(0.208 0.042 265.755);
  --destructive: oklch(0.577 0.245 27.325);
  --border: oklch(0.929 0.013 255.508);
  --input: oklch(0.929 0.013 255.508);
  --ring: oklch(0.704 0.04 256.788);
  --chart-1: oklch(0.646 0.222 41.116);
  --chart-2: oklch(0.6 0.118 184.704);
  --chart-3: oklch(0.398 0.07 227.392);
  --chart-4: oklch(0.828 0.189 84.429);
  --chart-5: oklch(0.769 0.188 70.08);
  --sidebar: oklch(0.984 0.003 247.858);
  --sidebar-foreground: oklch(0.129 0.042 264.695);
  --sidebar-primary: oklch(0.208 0.042 265.755);
  --sidebar-primary-foreground: oklch(0.984 0.003 247.858);
  --sidebar-accent: oklch(0.968 0.007 247.896);
  --sidebar-accent-foreground: oklch(0.208 0.042 265.755);
  --sidebar-border: oklch(0.929 0.013 255.508);
  --sidebar-ring: oklch(0.704 0.04 256.788);
}

.dark {
  --background: oklch(0.129 0.042 264.695);
  --foreground: oklch(0.984 0.003 247.858);
  --card: oklch(0.208 0.042 265.755);
  --card-foreground: oklch(0.984 0.003 247.858);
  --popover: oklch(0.208 0.042 265.755);
  --popover-foreground: oklch(0.984 0.003 247.858);
  --primary: oklch(0.929 0.013 255.508);
  --primary-foreground: oklch(0.208 0.042 265.755);
  --secondary: oklch(0.279 0.041 260.031);
  --secondary-foreground: oklch(0.984 0.003 247.858);
  --muted: oklch(0.279 0.041 260.031);
  --muted-foreground: oklch(0.704 0.04 256.788);
  --accent: oklch(0.279 0.041 260.031);
  --accent-foreground: oklch(0.984 0.003 247.858);
  --destructive: oklch(0.704 0.191 22.216);
  --border: oklch(1 0 0 / 10%);
  --input: oklch(1 0 0 / 15%);
  --ring: oklch(0.551 0.027 264.364);
  --chart-1: oklch(0.488 0.243 264.376);
  --chart-2: oklch(0.696 0.17 162.48);
  --chart-3: oklch(0.769 0.188 70.08);
  --chart-4: oklch(0.627 0.265 303.9);
  --chart-5: oklch(0.645 0.246 16.439);
  --sidebar: oklch(0.208 0.042 265.755);
  --sidebar-foreground: oklch(0.984 0.003 247.858);
  --sidebar-primary: oklch(0.488 0.243 264.376);
  --sidebar-primary-foreground: oklch(0.984 0.003 247.858);
  --sidebar-accent: oklch(0.279 0.041 260.031);
  --sidebar-accent-foreground: oklch(0.984 0.003 247.858);
  --sidebar-border: oklch(1 0 0 / 10%);
  --sidebar-ring: oklch(0.551 0.027 264.364);
}

@theme inline {
  --radius-sm: calc(var(--radius) - 4px);
  --radius-md: calc(var(--radius) - 2px);
  --radius-lg: var(--radius);
  --radius-xl: calc(var(--radius) + 4px);
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --color-card: var(--card);
  --color-card-foreground: var(--card-foreground);
  --color-popover: var(--popover);
  --color-popover-foreground: var(--popover-foreground);
  --color-primary: var(--primary);
  --color-primary-foreground: var(--primary-foreground);
  --color-secondary: var(--secondary);
  --color-secondary-foreground: var(--secondary-foreground);
  --color-muted: var(--muted);
  --color-muted-foreground: var(--muted-foreground);
  --color-accent: var(--accent);
  --color-accent-foreground: var(--accent-foreground);
  --color-destructive: var(--destructive);
  --color-border: var(--border);
  --color-input: var(--input);
  --color-ring: var(--ring);
  --color-chart-1: var(--chart-1);
  --color-chart-2: var(--chart-2);
  --color-chart-3: var(--chart-3);
  --color-chart-4: var(--chart-4);
  --color-chart-5: var(--chart-5);
  --color-sidebar: var(--sidebar);
  --color-sidebar-foreground: var(--sidebar-foreground);
  --color-sidebar-primary: var(--sidebar-primary);
  --color-sidebar-primary-foreground: var(--sidebar-primary-foreground);
  --color-sidebar-accent: var(--sidebar-accent);
  --color-sidebar-accent-foreground: var(--sidebar-accent-foreground);
  --color-sidebar-border: var(--sidebar-border);
  --color-sidebar-ring: var(--sidebar-ring);
}

@layer base {
  * {
    @apply border-border outline-ring/50;
  }
  body {
    @apply bg-background text-foreground;
  }
}

================
File: apps/platform/src/app.d.ts
================
import type { Session as BaseSession, User as BaseUser } from "$lib/server/infrastructure/auth";

declare global {
	namespace App {
		interface Error {
			message: string;
			code?: string;
		}
		interface Locals {
			auth: () => Promise<BaseSession | null>;
			user: BaseUser | null;
			session: BaseSession | null;
		}
		interface PageData {
			user: BaseUser | null;
			session: BaseSession | null;
		}
		interface ActionData {
            success?: boolean;
            errors?: Record<string, string[]>;
            data?: Record<string, unknown>;
        }
		interface Platform {
			env?: Record<string, string>;
		}
	}
}

export {};

================
File: apps/platform/src/app.html
================
<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		%sveltekit.head%
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">%sveltekit.body%</div>
	</body>
</html>

================
File: apps/platform/src/hooks.server.ts
================
import { auth } from "$lib/server/infrastructure/auth";
import { svelteKitHandler } from "better-auth/svelte-kit";
import { building } from "$app/environment";
import { TIME } from "$lib/constants";

export async function handle({ event, resolve }) {
    // Inject mock session for E2E tests
    if (process.env.PLAYWRIGHT_TEST === 'true') {
        event.locals.auth = async () => ({
            user: {
                id: 'test-user-id',
                email: 'test@example.com',
                emailVerified: true,
                name: 'Test User',
                nativeLang: 'en',
                targetLang: 'es',
                createdAt: new Date(),
                updatedAt: new Date(),
                gameIntervalMinutes: parseFloat(process.env.TEST_GAME_INTERVAL || '10')
            },
            session: {
                id: 'test-session-id',
                userId: 'test-user-id',
                expiresAt: new Date(Date.now() + TIME.ONE_HOUR_MS),
                token: 'test-token',
                createdAt: new Date(),
                updatedAt: new Date(),
            }
        });
    } else {
        event.locals.auth = () => auth.api.getSession({
            headers: event.request.headers
        });
    }

    return svelteKitHandler({ event, resolve, auth, building });
}

================
File: apps/platform/src/lib/auth-client.ts
================
import { createAuthClient } from "better-auth/svelte";

export const authClient = createAuthClient({
    baseURL: import.meta.env.VITE_BASE_URL || "http://localhost:5173" // Adjust for production
});

export const { signIn, signOut, useSession } = authClient;

================
File: apps/platform/src/lib/components/GameOverlay.svelte
================
<script lang="ts">
    import { Motion, useMotionValue, useTransform } from "svelte-motion";
    import { base } from "$app/paths";
    import { Button } from "$lib/components/ui/button";
    import { X, Check } from "lucide-svelte";
    import { UI } from "$lib/constants";

    let { cards = [], onComplete } = $props();

    const SWIPE_THRESHOLD = 100;
    const DRAG_RANGE = 200;
    const ROTATION_RANGE = 20;

    let currentIndex = $state(0);
    const currentCard = $derived(cards[currentIndex]);

    const x = useMotionValue(0);
    const opacity = useTransform(
        x,
        [-DRAG_RANGE, 0, DRAG_RANGE],
        [UI.OPACITY_INACTIVE, 1, UI.OPACITY_INACTIVE],
    );
    const rotate = useTransform(
        x,
        [-DRAG_RANGE, DRAG_RANGE],
        [-ROTATION_RANGE, ROTATION_RANGE],
    );

    async function handleSwipe(direction: "left" | "right") {
        if (!currentCard) return;

        if (direction === "right") {
            // Known
            console.log("Marking as known:", currentCard.lemma);
            try {
                // SvelteKit base path is handled by +server.ts relative routing usually, or we use base
                await fetch(`${base}/api/words/known`, {
                    method: "POST",
                    body: JSON.stringify({
                        lemma: currentCard.lemma,
                        lang: currentCard.lang,
                    }),
                });
            } catch (e) {
                console.error(e);
            }
        }

        if (currentIndex + 1 >= cards.length) {
            onComplete();
        } else {
            currentIndex++;
        }
        x.set(0);
    }

    function getStatusClass(index: number, current: number) {
        if (index < current) return "bg-green-500";
        if (index === current) return "bg-white";
        return "bg-white/10";
    }

    interface DragInfo {
        offset: { x: number; y: number };
    }

    function onDragEnd(_: unknown, info: DragInfo) {
        if (info.offset.x > SWIPE_THRESHOLD) {
            handleSwipe("right");
        } else if (info.offset.x < -SWIPE_THRESHOLD) {
            handleSwipe("left");
        }
    }
</script>

{#if currentCard}
    <div class="flex flex-col items-center justify-center w-full max-w-md">
        <div class="mb-8 text-center">
            <h3
                class="text-white/50 text-sm font-bold uppercase tracking-widest mb-2"
            >
                Knowledge Check
            </h3>
            <div class="flex gap-1 justify-center">
                {#each cards as card, i (i)}
                    <div
                        class="h-1 w-6 rounded-full {getStatusClass(
                            i,
                            currentIndex,
                        )}"
                        data-lemma={card.lemma}
                    ></div>
                {/each}
            </div>
        </div>

        <div
            class="relative w-full aspect-[3/4] flex items-center justify-center"
        >
            <Motion
                let:motion={m}
                style={{ x, opacity, rotate }}
                drag="x"
                dragConstraints={{ left: 0, right: 0 }}
                {onDragEnd}
            >
                <div
                    use:m
                    class="bg-white rounded-3xl p-10 w-full h-full shadow-2xl text-center flex flex-col justify-center cursor-grab active:cursor-grabbing border-4 border-white/20"
                >
                    <span
                        class="text-zinc-400 text-xs font-bold uppercase tracking-widest mb-4"
                        >Word to master</span
                    >
                    <h2
                        class="text-5xl font-black mb-6 text-zinc-900 tracking-tight"
                        data-testid="card-original"
                    >
                        {currentCard.original}
                    </h2>

                    <div class="h-px bg-zinc-100 w-12 mx-auto mb-6"></div>

                    <p class="text-zinc-500 italic text-lg leading-relaxed">
                        "{currentCard.contextSentence}"
                    </p>

                    <div class="mt-auto pt-10 flex justify-between gap-4">
                        <Button
                            variant="outline"
                            class="flex-1 rounded-2xl h-14 border-zinc-200 text-zinc-400 hover:bg-red-50 hover:text-red-500 hover:border-red-200 transition-all"
                            onclick={() => handleSwipe("left")}
                            data-testid="swipe-left"
                        >
                            <X class="mr-2 h-5 w-5" />
                            Unknown
                        </Button>
                        <Button
                            class="flex-1 rounded-2xl h-14 bg-zinc-900 hover:bg-green-600 text-white transition-all shadow-xl shadow-zinc-200"
                            onclick={() => handleSwipe("right")}
                            data-testid="swipe-right"
                        >
                            <Check class="mr-2 h-5 w-5" />
                            Known
                        </Button>
                    </div>
                </div>
            </Motion>

            <!-- Swipe hints -->
            <div
                class="absolute -right-12 top-1/2 -translate-y-1/2 text-green-500/50 pointer-events-none"
            >
                <Check class="h-12 w-12" />
            </div>
            <div
                class="absolute -left-12 top-1/2 -translate-y-1/2 text-red-500/50 pointer-events-none"
            >
                <X class="h-12 w-12" />
            </div>
        </div>

        <p
            class="mt-8 text-white/30 text-xs uppercase tracking-widest font-bold"
        >
            Swipe right if you know it, left if you don't
        </p>
    </div>
{/if}

================
File: apps/platform/src/lib/components/ui/badge/badge.svelte
================
<script lang="ts" module>
	import { type VariantProps, tv } from "tailwind-variants";

	export const badgeVariants = tv({
		base: "focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive inline-flex w-fit shrink-0 items-center justify-center gap-1 overflow-hidden rounded-full border px-2 py-0.5 text-xs font-medium whitespace-nowrap transition-[color,box-shadow] focus-visible:ring-[3px] [&>svg]:pointer-events-none [&>svg]:size-3",
		variants: {
			variant: {
				default:
					"bg-primary text-primary-foreground [a&]:hover:bg-primary/90 border-transparent",
				secondary:
					"bg-secondary text-secondary-foreground [a&]:hover:bg-secondary/90 border-transparent",
				destructive:
					"bg-destructive [a&]:hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/70 border-transparent text-white",
				outline: "text-foreground [a&]:hover:bg-accent [a&]:hover:text-accent-foreground",
			},
		},
		defaultVariants: {
			variant: "default",
		},
	});

	export type BadgeVariant = VariantProps<typeof badgeVariants>["variant"];
</script>

<script lang="ts">
	import type { HTMLAnchorAttributes } from "svelte/elements";
	import { cn, type WithElementRef } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		href,
		class: className,
		variant = "default",
		children,
		...restProps
	}: WithElementRef<HTMLAnchorAttributes> & {
		variant?: BadgeVariant;
	} = $props();
</script>

<svelte:element
	this={href ? "a" : "span"}
	bind:this={ref}
	data-slot="badge"
	{href}
	class={cn(badgeVariants({ variant }), className)}
	{...restProps}
>
	{@render children?.()}
</svelte:element>

================
File: apps/platform/src/lib/components/ui/badge/index.ts
================
export { default as Badge } from "./badge.svelte";
export { badgeVariants, type BadgeVariant } from "./badge.svelte";

================
File: apps/platform/src/lib/components/ui/button/button.svelte
================
<script lang="ts" module>
	import { cn, type WithElementRef } from "$lib/utils.js";
	import { UI } from '$lib/constants';
	import type { HTMLAnchorAttributes, HTMLButtonAttributes } from "svelte/elements";
	import { type VariantProps, tv } from "tailwind-variants";

	export const buttonVariants = tv({
		base: "focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive inline-flex shrink-0 items-center justify-center gap-2 rounded-md text-sm font-medium whitespace-nowrap transition-all outline-none focus-visible:ring-[3px] disabled:pointer-events-none disabled:opacity-50 aria-disabled:pointer-events-none aria-disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
		variants: {
			variant: {
				default: "bg-primary text-primary-foreground hover:bg-primary/90 shadow-xs",
				destructive:
					"bg-destructive hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60 text-white shadow-xs",
				outline:
					"bg-background hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 border shadow-xs",
				secondary: "bg-secondary text-secondary-foreground hover:bg-secondary/80 shadow-xs",
				ghost: "hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50",
				link: "text-primary underline-offset-4 hover:underline",
			},
			size: {
				default: "h-9 px-4 py-2 has-[>svg]:px-3",
				sm: "h-8 gap-1.5 rounded-md px-3 has-[>svg]:px-2.5",
				lg: "h-10 rounded-md px-6 has-[>svg]:px-4",
				icon: "size-9",
				"icon-sm": "size-8",
				"icon-lg": "size-10",
			},
		},
		defaultVariants: {
			variant: "default",
			size: "default",
		},
	});

	export type ButtonVariant = VariantProps<typeof buttonVariants>["variant"];
	export type ButtonSize = VariantProps<typeof buttonVariants>["size"];

	export type ButtonProps = WithElementRef<HTMLButtonAttributes> &
		WithElementRef<HTMLAnchorAttributes> & {
			variant?: ButtonVariant;
			size?: ButtonSize;
		};
</script>

<script lang="ts">
	/* eslint-disable svelte/no-navigation-without-resolve */
	let {
		class: className,
		variant = "default",
		size = "default",
		ref = $bindable(null),
		href = undefined,
		type = "button",
		disabled,
		children,
		...restProps
	}: ButtonProps = $props();
</script>

{#if href}
	<a
		bind:this={ref}
		data-slot="button"
		class={cn(buttonVariants({ variant, size }), className)}
		href={disabled ? undefined : href}
		aria-disabled={disabled}
		role={disabled ? "link" : undefined}
		tabindex={disabled ? UI.TABINDEX_DISABLED : undefined}
		{...restProps}
	>
		{@render children?.()}
	</a>
{:else}
	<button
		bind:this={ref}
		data-slot="button"
		class={cn(buttonVariants({ variant, size }), className)}
		{type}
		{disabled}
		{...restProps}
	>
		{@render children?.()}
	</button>
{/if}

================
File: apps/platform/src/lib/components/ui/button/index.ts
================
import Root, {
	type ButtonProps,
	type ButtonSize,
	type ButtonVariant,
	buttonVariants,
} from "./button.svelte";

export {
	Root,
	type ButtonProps as Props,
	//
	Root as Button,
	buttonVariants,
	type ButtonProps,
	type ButtonSize,
	type ButtonVariant,
};

================
File: apps/platform/src/lib/components/ui/card/card-action.svelte
================
<script lang="ts">
	import { cn, type WithElementRef } from "$lib/utils.js";
	import type { HTMLAttributes } from "svelte/elements";

	let {
		ref = $bindable(null),
		class: className,
		children,
		...restProps
	}: WithElementRef<HTMLAttributes<HTMLDivElement>> = $props();
</script>

<div
	bind:this={ref}
	data-slot="card-action"
	class={cn("col-start-2 row-span-2 row-start-1 self-start justify-self-end", className)}
	{...restProps}
>
	{@render children?.()}
</div>

================
File: apps/platform/src/lib/components/ui/card/card-content.svelte
================
<script lang="ts">
	import type { HTMLAttributes } from "svelte/elements";
	import { cn, type WithElementRef } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		children,
		...restProps
	}: WithElementRef<HTMLAttributes<HTMLDivElement>> = $props();
</script>

<div bind:this={ref} data-slot="card-content" class={cn("px-6", className)} {...restProps}>
	{@render children?.()}
</div>

================
File: apps/platform/src/lib/components/ui/card/card-description.svelte
================
<script lang="ts">
	import type { HTMLAttributes } from "svelte/elements";
	import { cn, type WithElementRef } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		children,
		...restProps
	}: WithElementRef<HTMLAttributes<HTMLParagraphElement>> = $props();
</script>

<p
	bind:this={ref}
	data-slot="card-description"
	class={cn("text-muted-foreground text-sm", className)}
	{...restProps}
>
	{@render children?.()}
</p>

================
File: apps/platform/src/lib/components/ui/card/card-footer.svelte
================
<script lang="ts">
	import { cn, type WithElementRef } from "$lib/utils.js";
	import type { HTMLAttributes } from "svelte/elements";

	let {
		ref = $bindable(null),
		class: className,
		children,
		...restProps
	}: WithElementRef<HTMLAttributes<HTMLDivElement>> = $props();
</script>

<div
	bind:this={ref}
	data-slot="card-footer"
	class={cn("flex items-center px-6 [.border-t]:pt-6", className)}
	{...restProps}
>
	{@render children?.()}
</div>

================
File: apps/platform/src/lib/components/ui/card/card-header.svelte
================
<script lang="ts">
	import { cn, type WithElementRef } from "$lib/utils.js";
	import type { HTMLAttributes } from "svelte/elements";

	let {
		ref = $bindable(null),
		class: className,
		children,
		...restProps
	}: WithElementRef<HTMLAttributes<HTMLDivElement>> = $props();
</script>

<div
	bind:this={ref}
	data-slot="card-header"
	class={cn(
		"@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6",
		className
	)}
	{...restProps}
>
	{@render children?.()}
</div>

================
File: apps/platform/src/lib/components/ui/card/card-title.svelte
================
<script lang="ts">
	import type { HTMLAttributes } from "svelte/elements";
	import { cn, type WithElementRef } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		children,
		...restProps
	}: WithElementRef<HTMLAttributes<HTMLDivElement>> = $props();
</script>

<div
	bind:this={ref}
	data-slot="card-title"
	class={cn("leading-none font-semibold", className)}
	{...restProps}
>
	{@render children?.()}
</div>

================
File: apps/platform/src/lib/components/ui/card/card.svelte
================
<script lang="ts">
	import type { HTMLAttributes } from "svelte/elements";
	import { cn, type WithElementRef } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		children,
		...restProps
	}: WithElementRef<HTMLAttributes<HTMLDivElement>> = $props();
</script>

<div
	bind:this={ref}
	data-slot="card"
	class={cn(
		"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm",
		className
	)}
	{...restProps}
>
	{@render children?.()}
</div>

================
File: apps/platform/src/lib/components/ui/card/index.ts
================
import Root from "./card.svelte";
import Content from "./card-content.svelte";
import Description from "./card-description.svelte";
import Footer from "./card-footer.svelte";
import Header from "./card-header.svelte";
import Title from "./card-title.svelte";
import Action from "./card-action.svelte";

export {
	Root,
	Content,
	Description,
	Footer,
	Header,
	Title,
	Action,
	//
	Root as Card,
	Content as CardContent,
	Description as CardDescription,
	Footer as CardFooter,
	Header as CardHeader,
	Title as CardTitle,
	Action as CardAction,
};

================
File: apps/platform/src/lib/components/ui/input/index.ts
================
import Root from "./input.svelte";

export {
	Root,
	//
	Root as Input,
};

================
File: apps/platform/src/lib/components/ui/input/input.svelte
================
<script lang="ts">
	import type { HTMLInputAttributes, HTMLInputTypeAttribute } from "svelte/elements";
	import { cn, type WithElementRef } from "$lib/utils.js";

	type InputType = Exclude<HTMLInputTypeAttribute, "file">;

	type Props = WithElementRef<
		Omit<HTMLInputAttributes, "type"> &
			({ type: "file"; files?: FileList } | { type?: InputType; files?: undefined })
	>;

	let {
		ref = $bindable(null),
		value = $bindable(),
		type,
		files = $bindable(),
		class: className,
		"data-slot": dataSlot = "input",
		...restProps
	}: Props = $props();
</script>

{#if type === "file"}
	<input
		bind:this={ref}
		data-slot={dataSlot}
		class={cn(
			"selection:bg-primary dark:bg-input/30 selection:text-primary-foreground border-input ring-offset-background placeholder:text-muted-foreground flex h-9 w-full min-w-0 rounded-md border bg-transparent px-3 pt-1.5 text-sm font-medium shadow-xs transition-[color,box-shadow] outline-none disabled:cursor-not-allowed disabled:opacity-50",
			"focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px]",
			"aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive",
			className
		)}
		type="file"
		bind:files
		bind:value
		{...restProps}
	/>
{:else}
	<input
		bind:this={ref}
		data-slot={dataSlot}
		class={cn(
			"border-input bg-background selection:bg-primary dark:bg-input/30 selection:text-primary-foreground ring-offset-background placeholder:text-muted-foreground flex h-9 w-full min-w-0 rounded-md border px-3 py-1 text-base shadow-xs transition-[color,box-shadow] outline-none disabled:cursor-not-allowed disabled:opacity-50 md:text-sm",
			"focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px]",
			"aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive",
			className
		)}
		{type}
		bind:value
		{...restProps}
	/>
{/if}

================
File: apps/platform/src/lib/components/ui/select/index.ts
================
import Root from "./select.svelte";
import Group from "./select-group.svelte";
import Label from "./select-label.svelte";
import Item from "./select-item.svelte";
import Content from "./select-content.svelte";
import Trigger from "./select-trigger.svelte";
import Separator from "./select-separator.svelte";
import ScrollDownButton from "./select-scroll-down-button.svelte";
import ScrollUpButton from "./select-scroll-up-button.svelte";
import GroupHeading from "./select-group-heading.svelte";
import Portal from "./select-portal.svelte";

export {
	Root,
	Group,
	Label,
	Item,
	Content,
	Trigger,
	Separator,
	ScrollDownButton,
	ScrollUpButton,
	GroupHeading,
	Portal,
	//
	Root as Select,
	Group as SelectGroup,
	Label as SelectLabel,
	Item as SelectItem,
	Content as SelectContent,
	Trigger as SelectTrigger,
	Separator as SelectSeparator,
	ScrollDownButton as SelectScrollDownButton,
	ScrollUpButton as SelectScrollUpButton,
	GroupHeading as SelectGroupHeading,
	Portal as SelectPortal,
};

================
File: apps/platform/src/lib/components/ui/select/select-content.svelte
================
<script lang="ts">
	import { Select as SelectPrimitive } from "bits-ui";
	import SelectPortal from "./select-portal.svelte";
	import SelectScrollUpButton from "./select-scroll-up-button.svelte";
	import SelectScrollDownButton from "./select-scroll-down-button.svelte";
	import { cn, type WithoutChild } from "$lib/utils.js";
	import { UI } from '$lib/constants';
	import type { ComponentProps } from "svelte";
	import type { WithoutChildrenOrChild } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		sideOffset = UI.POPOVER_OFFSET,
		portalProps,
		children,
		preventScroll = true,
		...restProps
	}: WithoutChild<SelectPrimitive.ContentProps> & {
		portalProps?: WithoutChildrenOrChild<ComponentProps<typeof SelectPortal>>;
	} = $props();
</script>

<SelectPortal {...portalProps}>
	<SelectPrimitive.Content
		bind:ref
		{sideOffset}
		{preventScroll}
		data-slot="select-content"
		class={cn(
			"bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-end-2 data-[side=right]:slide-in-from-start-2 data-[side=top]:slide-in-from-bottom-2 relative z-50 max-h-(--bits-select-content-available-height) min-w-[8rem] origin-(--bits-select-content-transform-origin) overflow-x-hidden overflow-y-auto rounded-md border shadow-md data-[side=bottom]:translate-y-1 data-[side=left]:-translate-x-1 data-[side=right]:translate-x-1 data-[side=top]:-translate-y-1",
			className
		)}
		{...restProps}
	>
		<SelectScrollUpButton />
		<SelectPrimitive.Viewport
			class={cn(
				"h-(--bits-select-anchor-height) w-full min-w-(--bits-select-anchor-width) scroll-my-1 p-1"
			)}
		>
			{@render children?.()}
		</SelectPrimitive.Viewport>
		<SelectScrollDownButton />
	</SelectPrimitive.Content>
</SelectPortal>

================
File: apps/platform/src/lib/components/ui/select/select-group-heading.svelte
================
<script lang="ts">
	import { Select as SelectPrimitive } from "bits-ui";
	import { cn } from "$lib/utils.js";
	import type { ComponentProps } from "svelte";

	let {
		ref = $bindable(null),
		class: className,
		children,
		...restProps
	}: ComponentProps<typeof SelectPrimitive.GroupHeading> = $props();
</script>

<SelectPrimitive.GroupHeading
	bind:ref
	data-slot="select-group-heading"
	class={cn("text-muted-foreground px-2 py-1.5 text-xs", className)}
	{...restProps}
>
	{@render children?.()}
</SelectPrimitive.GroupHeading>

================
File: apps/platform/src/lib/components/ui/select/select-group.svelte
================
<script lang="ts">
	import { Select as SelectPrimitive } from "bits-ui";

	let { ref = $bindable(null), ...restProps }: SelectPrimitive.GroupProps = $props();
</script>

<SelectPrimitive.Group data-slot="select-group" {...restProps} />

================
File: apps/platform/src/lib/components/ui/select/select-item.svelte
================
<script lang="ts">
	import CheckIcon from "@lucide/svelte/icons/check";
	import { Select as SelectPrimitive } from "bits-ui";
	import { cn, type WithoutChild } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		value,
		label,
		children: childrenProp,
		...restProps
	}: WithoutChild<SelectPrimitive.ItemProps> = $props();
</script>

<SelectPrimitive.Item
	bind:ref
	{value}
	data-slot="select-item"
	class={cn(
		"data-[highlighted]:bg-accent data-[highlighted]:text-accent-foreground [&_svg:not([class*='text-'])]:text-muted-foreground relative flex w-full cursor-default items-center gap-2 rounded-sm py-1.5 ps-2 pe-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4 *:[span]:last:flex *:[span]:last:items-center *:[span]:last:gap-2",
		className
	)}
	{...restProps}
>
	{#snippet children({ selected, highlighted })}
		<span class="absolute end-2 flex size-3.5 items-center justify-center">
			{#if selected}
				<CheckIcon class="size-4" />
			{/if}
		</span>
		{#if childrenProp}
			{@render childrenProp({ selected, highlighted })}
		{:else}
			{label || value}
		{/if}
	{/snippet}
</SelectPrimitive.Item>

================
File: apps/platform/src/lib/components/ui/select/select-label.svelte
================
<script lang="ts">
	import { cn, type WithElementRef } from "$lib/utils.js";
	import type { HTMLAttributes } from "svelte/elements";

	let {
		ref = $bindable(null),
		class: className,
		children,
		...restProps
	}: WithElementRef<HTMLAttributes<HTMLDivElement>> & {} = $props();
</script>

<div
	bind:this={ref}
	data-slot="select-label"
	class={cn("text-muted-foreground px-2 py-1.5 text-xs", className)}
	{...restProps}
>
	{@render children?.()}
</div>

================
File: apps/platform/src/lib/components/ui/select/select-portal.svelte
================
<script lang="ts">
	import { Select as SelectPrimitive } from "bits-ui";

	let { ...restProps }: SelectPrimitive.PortalProps = $props();
</script>

<SelectPrimitive.Portal {...restProps} />

================
File: apps/platform/src/lib/components/ui/select/select-scroll-down-button.svelte
================
<script lang="ts">
	import ChevronDownIcon from "@lucide/svelte/icons/chevron-down";
	import { Select as SelectPrimitive } from "bits-ui";
	import { cn, type WithoutChildrenOrChild } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		...restProps
	}: WithoutChildrenOrChild<SelectPrimitive.ScrollDownButtonProps> = $props();
</script>

<SelectPrimitive.ScrollDownButton
	bind:ref
	data-slot="select-scroll-down-button"
	class={cn("flex cursor-default items-center justify-center py-1", className)}
	{...restProps}
>
	<ChevronDownIcon class="size-4" />
</SelectPrimitive.ScrollDownButton>

================
File: apps/platform/src/lib/components/ui/select/select-scroll-up-button.svelte
================
<script lang="ts">
	import ChevronUpIcon from "@lucide/svelte/icons/chevron-up";
	import { Select as SelectPrimitive } from "bits-ui";
	import { cn, type WithoutChildrenOrChild } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		...restProps
	}: WithoutChildrenOrChild<SelectPrimitive.ScrollUpButtonProps> = $props();
</script>

<SelectPrimitive.ScrollUpButton
	bind:ref
	data-slot="select-scroll-up-button"
	class={cn("flex cursor-default items-center justify-center py-1", className)}
	{...restProps}
>
	<ChevronUpIcon class="size-4" />
</SelectPrimitive.ScrollUpButton>

================
File: apps/platform/src/lib/components/ui/select/select-separator.svelte
================
<script lang="ts">
	import type { Separator as SeparatorPrimitive } from "bits-ui";
	import { Separator } from "$lib/components/ui/separator/index.js";
	import { cn } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		...restProps
	}: SeparatorPrimitive.RootProps = $props();
</script>

<Separator
	bind:ref
	data-slot="select-separator"
	class={cn("bg-border pointer-events-none -mx-1 my-1 h-px", className)}
	{...restProps}
/>

================
File: apps/platform/src/lib/components/ui/select/select-trigger.svelte
================
<script lang="ts">
	import { Select as SelectPrimitive } from "bits-ui";
	import ChevronDownIcon from "@lucide/svelte/icons/chevron-down";
	import { cn, type WithoutChild } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		children,
		size = "default",
		...restProps
	}: WithoutChild<SelectPrimitive.TriggerProps> & {
		size?: "sm" | "default";
	} = $props();
</script>

<SelectPrimitive.Trigger
	bind:ref
	data-slot="select-trigger"
	data-size={size}
	class={cn(
		"border-input data-[placeholder]:text-muted-foreground [&_svg:not([class*='text-'])]:text-muted-foreground focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive dark:bg-input/30 dark:hover:bg-input/50 flex w-fit items-center justify-between gap-2 rounded-md border bg-transparent px-3 py-2 text-sm whitespace-nowrap shadow-xs transition-[color,box-shadow] outline-none select-none focus-visible:ring-[3px] disabled:cursor-not-allowed disabled:opacity-50 data-[size=default]:h-9 data-[size=sm]:h-8 *:data-[slot=select-value]:line-clamp-1 *:data-[slot=select-value]:flex *:data-[slot=select-value]:items-center *:data-[slot=select-value]:gap-2 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
		className
	)}
	{...restProps}
>
	{@render children?.()}
	<ChevronDownIcon class="size-4 opacity-50" />
</SelectPrimitive.Trigger>

================
File: apps/platform/src/lib/components/ui/select/select.svelte
================
<script lang="ts">
	import { Select as SelectPrimitive } from "bits-ui";

	let {
		open = $bindable(false),
		value = $bindable(),
		...restProps
	}: SelectPrimitive.RootProps = $props();
</script>

<SelectPrimitive.Root bind:open bind:value={value as never} {...restProps} />

================
File: apps/platform/src/lib/components/ui/separator/index.ts
================
import Root from "./separator.svelte";

export {
	Root,
	//
	Root as Separator,
};

================
File: apps/platform/src/lib/components/ui/separator/separator.svelte
================
<script lang="ts">
	import { Separator as SeparatorPrimitive } from "bits-ui";
	import { cn } from "$lib/utils.js";

	let {
		ref = $bindable(null),
		class: className,
		"data-slot": dataSlot = "separator",
		...restProps
	}: SeparatorPrimitive.RootProps = $props();
</script>

<SeparatorPrimitive.Root
	bind:ref
	data-slot={dataSlot}
	class={cn(
		"bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px",
		className
	)}
	{...restProps}
/>

================
File: apps/platform/src/lib/constants.ts
================
export const UI = {
    OPACITY_INACTIVE: 0.5,
    TABINDEX_DISABLED: -1,
    POPOVER_OFFSET: 4,
    INDENT_SPACES: 4,
} as const;

export const HTTP_STATUS = {
    OK: 200,
    SEE_OTHER: 303,
    BAD_REQUEST: 400,
    UNAUTHORIZED: 401,
    FORBIDDEN: 403,
    NOT_FOUND: 404,
    UNPROCESSABLE_ENTITY: 422,
    INTERNAL_SERVER_ERROR: 500
} as const;

export const TIME = {
    MS_DIGITS: 3,
    PADDING_DIGITS: 2,
    ONE_MINUTE_MS: 60000,
    ANIMATION_DELAY_MS: 500,
    POLLING_INTERVAL_MS: 3000,
    ONE_HOUR_MS: 3600000,
    DEFAULT_WAIT_TIMEOUT: 60000,
} as const;

export const GAME = {
    DEFAULT_INTERVAL_MINUTES: 10,
    MAX_INTERVAL_MINUTES: 60,
    DEFAULT_DECK_LIMIT: 15,
} as const;

export const LINT = {
    MAX_COGNITIVE_COMPLEXITY: 15,
    MAX_CYCLOMATIC_COMPLEXITY: 10,
    MAX_LINES_PER_FUNCTION: 50,
} as const;

export const LIMITS = {
    MAX_UNKNOWN_FOR_LEARNING: 3,
    MAX_RATIO_FOR_LEARNING: 0.4,
    HARD_UNKNOWN_THRESHOLD: 4,
    RETRY_DELAY_SEC: 2,
    MAX_RETRIES: 5,
    PERCENT_COMPLETE: 100,
    MAX_TITLE_LENGTH: 100,
} as const;

export const INDICES = {
    NOT_FOUND: -1,
    FIRST: 0,
    SECOND: 1,
} as const;

================
File: apps/platform/src/lib/logger.ts
================
import pino from 'pino';

// This prints JSON to the server console
export const logger = pino({
    level: 'info',
    transport: {
        targets: [
            {
                target: 'pino/file',
                options: { destination: 1 } // stdout for Docker/Console
            },
            {
                target: 'pino/file',
                options: { destination: '../../logs/platform.log', mkdir: true }
            }
        ]
    }
});

================
File: apps/platform/src/lib/server/adapters/mock-ai-gateway.ts
================
import type { 
    IAiGateway, 
    TranscriptionResponse, 
    FilterResponse, 
    TranslationResponse, 
    ThumbnailResponse 
} from '../domain/interfaces';

export class MockAiGateway implements IAiGateway {
    async transcribe(filePath: string): Promise<TranscriptionResponse> {
        console.log(`[MockAiGateway] Transcribing ${filePath}...`);
        return {
            segments: [
                { start: 0, end: 5, text: "This is a mock transcription segment." },
                { start: 5, end: 10, text: "The linguistics service is currently bypassed." }
            ],
            language: 'en',
            language_probability: 1.0
        };
    }

    async analyzeBatch(texts: string[]): Promise<FilterResponse> {
        return {
            results: texts.map(() => [
                { text: "Mock", lemma: "mock", pos: "NOUN", is_stop: false }
            ])
        };
    }

    async translate(texts: string[], _sourceLang: string, targetLang: string): Promise<TranslationResponse> {
        console.log(`[MockAiGateway] Translating ${texts.length} texts...`);
        return {
            translations: texts.map(t => `[${targetLang}] ${t}`)
        };
    }

    async generateThumbnail(filePath: string): Promise<ThumbnailResponse> {
        console.log(`[MockAiGateway] Generating thumbnail for ${filePath}...`);
        return {
            thumbnail_path: "thumbnails/mock_thumb.jpg"
        };
    }
}

================
File: apps/platform/src/lib/server/adapters/real-ai-gateway.ts
================
import { CONFIG } from '../infrastructure/config';
import type { 
    IAiGateway, 
    TranscriptionResponse, 
    FilterResponse, 
    TranslationResponse, 
    ThumbnailResponse 
} from '../domain/interfaces';

export class AiServiceError extends Error {
    constructor(public status: number, message: string) {
        super(message);
        this.name = 'AiServiceError';
    }
}

export class RealAiGateway implements IAiGateway {
    private getHeaders() {
        return {
            'Content-Type': 'application/json',
            'X-API-Key': CONFIG.AI_SERVICE_API_KEY
        };
    }

    private async handleResponse(res: Response, context: string) {
        if (!res.ok) {
            const errorText = await res.text().catch(() => res.statusText);
            throw new AiServiceError(res.status, `AI Service ${context} Error (${res.status}): ${errorText}`);
        }
        return res.json();
    }

    async transcribe(filePath: string, lang: string = CONFIG.DEFAULT_TARGET_LANG): Promise<TranscriptionResponse> {
        const res = await fetch(`${CONFIG.AI_SERVICE_URL}/transcribe`, {
            method: 'POST',
            headers: this.getHeaders(),
            body: JSON.stringify({ file_path: filePath, language: lang })
        });
        return this.handleResponse(res, 'Transcribe');
    }

    async analyzeBatch(texts: string[], lang: string = CONFIG.DEFAULT_TARGET_LANG): Promise<FilterResponse> {
        const res = await fetch(`${CONFIG.AI_SERVICE_URL}/filter`, {
            method: 'POST',
            headers: this.getHeaders(),
            body: JSON.stringify({ texts, language: lang })
        });
        return this.handleResponse(res, 'Analyze Batch');
    }

    async translate(texts: string[], sourceLang: string, targetLang: string): Promise<TranslationResponse> {
        const res = await fetch(`${CONFIG.AI_SERVICE_URL}/translate`, {
            method: 'POST',
            headers: this.getHeaders(),
            body: JSON.stringify({ texts, source_lang: sourceLang, target_lang: targetLang })
        });
        return this.handleResponse(res, 'Translate');
    }

    async generateThumbnail(filePath: string): Promise<ThumbnailResponse> {
        const res = await fetch(`${CONFIG.AI_SERVICE_URL}/generate_thumbnail`, {
            method: 'POST',
            headers: this.getHeaders(),
            body: JSON.stringify({ file_path: filePath })
        });
        return this.handleResponse(res, 'Thumbnail');
    }
}

================
File: apps/platform/src/lib/server/domain/interfaces.ts
================
import type { components } from '../infrastructure/brain-api';

export type Segment = components['schemas']['Segment'];
export type TranscriptionResponse = components['schemas']['TranscriptionResponse'];
export type TokenAnalysis = components['schemas']['TokenAnalysis'];
export type FilterResponse = components['schemas']['FilterResponse'];
export type TranslationResponse = components['schemas']['TranslationResponse'];
export type ThumbnailResponse = components['schemas']['ThumbnailResponse'];

export interface IAiGateway {
    transcribe(filePath: string, lang?: string): Promise<TranscriptionResponse>;
    analyzeBatch(texts: string[], lang?: string): Promise<FilterResponse>;
    translate(texts: string[], sourceLang: string, targetLang: string): Promise<TranslationResponse>;
    generateThumbnail(filePath: string): Promise<ThumbnailResponse>;
}

================
File: apps/platform/src/lib/server/infrastructure/auth.ts
================
import { betterAuth } from "better-auth";
import { drizzleAdapter } from "better-auth/adapters/drizzle";
import { db } from "./database";
import * as schema from "@notflix/database";
import { env } from '$env/dynamic/private';

export const auth = betterAuth({
    database: drizzleAdapter(db, {
        provider: "pg", 
        schema: {
            ...schema,
            user: schema.user,
            session: schema.session,
            account: schema.account,
            verification: schema.verification
        }
    }),
    user: {
        additionalFields: {
            nativeLang: {
                type: "string",
                defaultValue: "en"
            },
            targetLang: {
                type: "string",
                defaultValue: "es"
            },
            gameIntervalMinutes: {
                type: "number",
                defaultValue: 10
            }
        }
    },
    secret: env.BETTER_AUTH_SECRET,
    emailAndPassword: {
        enabled: true
    },
});

export type Auth = typeof auth;
export type Session = typeof auth.$Infer.Session;
export type User = Session["user"];

================
File: apps/platform/src/lib/server/infrastructure/brain-api.d.ts
================
/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */
/* eslint-disable no-magic-numbers */

export type paths = {
    "/generate_thumbnail": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Generate Thumbnail
         * @description Generates a thumbnail from a video file using FFmpeg.
         */
        post: operations["generate_thumbnail_generate_thumbnail_post"];
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/transcribe": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Transcribe
         * @description Transcribes an audio file using Faster-Whisper.
         */
        post: operations["transcribe_transcribe_post"];
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/translate": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Translate
         * @description Translates a batch of texts using MarianMT models.
         */
        post: operations["translate_translate_post"];
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/filter": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Filter Text
         * @description Analyzes a batch of texts using SpaCy for linguistic filtering.
         */
        post: operations["filter_text_filter_post"];
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/health": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Health
         * @description Health check endpoint.
         */
        get: operations["health_health_get"];
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
};
export type webhooks = Record<string, never>;
export type components = {
    schemas: {
        /** FilterRequest */
        FilterRequest: {
            /** Texts */
            texts: string[];
            /**
             * Language
             * @default es
             */
            language: string;
        };
        /** FilterResponse */
        FilterResponse: {
            /** Results */
            results: components["schemas"]["TokenAnalysis"][][];
        };
        /** HTTPValidationError */
        HTTPValidationError: {
            /** Detail */
            detail?: components["schemas"]["ValidationError"][];
        };
        /** Segment */
        Segment: {
            /** Start */
            start: number;
            /** End */
            end: number;
            /** Text */
            text: string;
        };
        /** ThumbnailRequest */
        ThumbnailRequest: {
            /** File Path */
            file_path: string;
        };
        /** ThumbnailResponse */
        ThumbnailResponse: {
            /** Thumbnail Path */
            thumbnail_path: string;
        };
        /** TokenAnalysis */
        TokenAnalysis: {
            /** Text */
            text: string;
            /** Lemma */
            lemma: string;
            /** Pos */
            pos: string;
            /** Is Stop */
            is_stop: boolean;
        };
        /** TranscriptionRequest */
        TranscriptionRequest: {
            /** File Path */
            file_path: string;
            /**
             * Language
             * @default es
             */
            language: string;
        };
        /** TranscriptionResponse */
        TranscriptionResponse: {
            /** Segments */
            segments: components["schemas"]["Segment"][];
            /** Language */
            language: string;
            /** Language Probability */
            language_probability: number;
        };
        /** TranslationRequest */
        TranslationRequest: {
            /** Texts */
            texts: string[];
            /**
             * Source Lang
             * @default es
             */
            source_lang: string;
            /**
             * Target Lang
             * @default en
             */
            target_lang: string;
        };
        /** TranslationResponse */
        TranslationResponse: {
            /** Translations */
            translations: string[];
        };
        /** ValidationError */
        ValidationError: {
            /** Location */
            loc: (string | number)[];
            /** Message */
            msg: string;
            /** Error Type */
            type: string;
        };
    };
    responses: never;
    parameters: never;
    requestBodies: never;
    headers: never;
    pathItems: never;
};
export type $defs = Record<string, never>;
/* eslint-disable sonarjs/class-name */
export interface operations {
    generate_thumbnail_generate_thumbnail_post: {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        requestBody: {
            content: {
                "application/json": components["schemas"]["ThumbnailRequest"];
            };
        };
        responses: {
            /** @description Successful Response */
            200: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["ThumbnailResponse"];
                };
            };
            /** @description Validation Error */
            422: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["HTTPValidationError"];
                };
            };
        };
    };
    transcribe_transcribe_post: {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        requestBody: {
            content: {
                "application/json": components["schemas"]["TranscriptionRequest"];
            };
        };
        responses: {
            /** @description Successful Response */
            200: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["TranscriptionResponse"];
                };
            };
            /** @description Validation Error */
            422: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["HTTPValidationError"];
                };
            };
        };
    };
    translate_translate_post: {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        requestBody: {
            content: {
                "application/json": components["schemas"]["TranslationRequest"];
            };
        };
        responses: {
            /** @description Successful Response */
            200: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["TranslationResponse"];
                };
            };
            /** @description Validation Error */
            422: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["HTTPValidationError"];
                };
            };
        };
    };
    filter_text_filter_post: {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        requestBody: {
            content: {
                "application/json": components["schemas"]["FilterRequest"];
            };
        };
        responses: {
            /** @description Successful Response */
            200: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["FilterResponse"];
                };
            };
            /** @description Validation Error */
            422: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["HTTPValidationError"];
                };
            };
        };
    };
    health_health_get: {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        requestBody?: never;
        responses: {
            /** @description Successful Response */
            200: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": unknown;
                };
            };
        };
    };
}

================
File: apps/platform/src/lib/server/infrastructure/config.ts
================
import { env } from '$env/dynamic/private';
import path from 'path';

const uploadDir = env.UPLOAD_DIR || 'media/uploads';

// Detect if running inside Docker container
const isDocker = env.RUNNING_IN_DOCKER === 'true';

// For Docker: UPLOAD_DIR is already absolute (/app/media/uploads)
// For Local: Resolve relative to project root
const resolvedUploadDir = isDocker
    ? uploadDir
    : (uploadDir.startsWith('/') || uploadDir.includes(':'))
        ? uploadDir
        : path.resolve(process.cwd(), '../../', uploadDir);

// Path to use when calling AI Service
// In Docker: Both services share /app/media mount, so use that path
// Local + Docker AI: Need to translate host path to container path
const aiServiceMediaPrefix = isDocker
    ? '/app/media/uploads'
    : '/app/media/uploads'; // AI Service always expects Docker paths

export const CONFIG = {
    DATABASE_URL: env.DATABASE_URL || 'postgres://admin:password@localhost:5432/main_db',
    AI_SERVICE_URL: env.AI_SERVICE_URL || 'http://127.0.0.1:8000',
    AI_SERVICE_API_KEY: env.AI_SERVICE_API_KEY || 'dev_secret_key',
    UPLOAD_DIR: uploadDir,
    RESOLVED_UPLOAD_DIR: resolvedUploadDir,
    AI_SERVICE_MEDIA_PREFIX: aiServiceMediaPrefix,
    IS_DOCKER: isDocker,
    DEFAULT_TARGET_LANG: 'es',
    DEFAULT_NATIVE_LANG: 'en',
    MODEL_SIZE: 'tiny',
    STORAGE_TYPE: env.STORAGE_TYPE || 'local' // local | s3
};

export enum ProcessingStatus {
    PENDING = 'PENDING',
    COMPLETED = 'COMPLETED',
    ERROR = 'ERROR'
}

/**
 * Converts a local file path to a path that the AI Service can understand.
 * When running locally, translates Windows/Mac paths to Docker container paths.
 */
export function toAiServicePath(localPath: string): string {
    if (CONFIG.IS_DOCKER) {
        // Both services in Docker - path is already correct
        return localPath;
    }

    // Extract filename from the local path
    const filename = path.basename(localPath);

    // Return path as AI Service (in Docker) expects it
    return `${CONFIG.AI_SERVICE_MEDIA_PREFIX}/${filename}`;
}

================
File: apps/platform/src/lib/server/infrastructure/container.ts
================
import { RealAiGateway } from '../adapters/real-ai-gateway';
import { MockAiGateway } from '../adapters/mock-ai-gateway';
import type { IAiGateway } from '../domain/interfaces';
import { Orchestrator } from '../services/video-orchestrator.service';
import { SmartFilter } from '../services/linguistic-filter.service';
import { SubtitleService } from '../services/subtitle.service';
import { db } from './database';

// Determine which adapter to use
const useMock = process.env.NODE_ENV === 'test' || process.env.USE_MOCK_AI === 'true';

export const aiGateway: IAiGateway = useMock ? new MockAiGateway() : new RealAiGateway();

export const smartFilter = new SmartFilter(db);

export const subtitleService = new SubtitleService(db);

// Singleton instance with dependencies injected
export const orchestrator = new Orchestrator(aiGateway, db, smartFilter);

console.log(`[Container] Initialized Container with: ${useMock ? 'MockAiGateway' : 'RealAiGateway'}`);

================
File: apps/platform/src/lib/server/infrastructure/database.ts
================
import postgres from 'postgres';
import { drizzle } from 'drizzle-orm/postgres-js';
import { CONFIG } from './config';
import * as schema from '@notflix/database';

const client = postgres(CONFIG.DATABASE_URL);
export const db = drizzle(client, { schema });

================
File: apps/platform/src/lib/server/infrastructure/event-bus.ts
================
import { EventEmitter } from 'events';

class GlobalEvents extends EventEmitter {}

export const globalEvents = new GlobalEvents();

export const EVENTS = {
    PROCESSING_UPDATE: 'processing:update'
};

================
File: apps/platform/src/lib/server/services/chunker.integration.test.ts
================
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { db } from '../infrastructure/database';
import { video, videoProcessing, user, knownWords } from '@notflix/database';
import { eq, and } from 'drizzle-orm';
import { generateDeck } from './chunker.service';
import type { VttSegment } from './video-orchestrator.service';

describe('ChunkerService Integration (Real DB)', () => {
    const testUserId = crypto.randomUUID();
    const testVideoId = crypto.randomUUID();
    const testTargetLang = 'es';

    beforeAll(async () => {
        // 1. Create a User (Required for Known Words FK)
        await db.insert(user).values({
            id: testUserId,
            name: 'Integration Test User',
            email: `test-${testUserId}@example.com`,
            emailVerified: true,
            image: null,
            createdAt: new Date(),
            updatedAt: new Date()
        });

        // 2. Create a Video
        await db.insert(video).values({
            id: testVideoId,
            title: 'Chunker Integration Video',
            filePath: '/tmp/chunker_test.mp4',
            thumbnailPath: '/tmp/thumb.jpg',
            views: 0,
            published: true,
            createdAt: new Date(),
            updatedAt: new Date()
        });

        // 3. Create Processing Result with VTT
        // "The cat sits."
        const vttData: VttSegment[] = [
            {
                start: 0,
                end: 5,
                text: "El gato se sienta.",
                tokens: [
                    { text: "El", lemma: "el", pos: "DET", is_stop: true },
                    { text: "gato", lemma: "gato", pos: "NOUN", is_stop: false },
                    { text: "se", lemma: "se", pos: "PRON", is_stop: true },
                    { text: "sienta", lemma: "sentar", pos: "VERB", is_stop: false }
                ]
            }
        ];

        await db.insert(videoProcessing).values({
            videoId: testVideoId,
            targetLang: testTargetLang,
            status: 'COMPLETED',
            progress: 100,
            vttJson: vttData,
            updatedAt: new Date()
        });

        // 4. Mark "sentar" as Known
        await db.insert(knownWords).values({
            userId: testUserId,
            lang: testTargetLang,
            lemma: 'sentar',
            score: 5,
            lastReviewed: new Date()
        });
    });

    afterAll(async () => {
        // Cleanup in order (FK constraints)
        await db.delete(knownWords).where(eq(knownWords.userId, testUserId));
        await db.delete(videoProcessing).where(eq(videoProcessing.videoId, testVideoId));
        await db.delete(video).where(eq(video.id, testVideoId));
        await db.delete(user).where(eq(user.id, testUserId));
    });

    it('should generate a deck from real DB data with correct known status', async () => {
        // ACT
        // Request chunk 0-5s
        const deck = await generateDeck(
            testUserId,
            testVideoId,
            0,
            5,
            testTargetLang
        );

        // ASSERT
        // Should contain 'gato' (NOUN) and 'sentar' (VERB)
        // 'el' and 'se' are stop words/not CONTENT_POS
        expect(deck).toHaveLength(2);

        const gatoCard = deck.find(c => c.lemma === 'gato');
        const sentarCard = deck.find(c => c.lemma === 'sentar');

        expect(gatoCard).toBeDefined();
        expect(gatoCard?.isKnown).toBe(false); // Unknown

        expect(sentarCard).toBeDefined();
        expect(sentarCard?.isKnown).toBe(true); // Known via DB
        expect(sentarCard?.original).toBe('sienta');
        expect(sentarCard?.contextSentence).toBe('El gato se sienta.'); // Context check
    });

    it('should return empty deck for out-of-range chunk', async () => {
        const deck = await generateDeck(
            testUserId,
            testVideoId,
            100,
            105,
            testTargetLang
        );
        expect(deck).toEqual([]);
    });
});

================
File: apps/platform/src/lib/server/services/chunker.service.test.ts
================
/* eslint-disable test-smells/assertion-roulette */
import { describe, it, expect, vi, beforeEach } from 'vitest';
import { generateDeck } from './chunker.service';
import { db } from '../infrastructure/database';

// Mock DB
vi.mock('../infrastructure/database', () => ({
    db: {
        select: vi.fn().mockReturnThis(),
        from: vi.fn().mockReturnThis(),
        where: vi.fn().mockReturnThis(),
        limit: vi.fn().mockReturnThis(),
        leftJoin: vi.fn().mockReturnThis(),
        orderBy: vi.fn().mockReturnThis(),
    }
}));

describe('ChunkerService', () => {
    beforeEach(() => {
        vi.clearAllMocks();
    });

    it('should generate a deck containing both known and unknown words from a sentence', async () => {
        // --- ARRANGE ---
        const mockedDb = db as unknown as { limit: { mockResolvedValueOnce: (val: unknown) => void }, where: { mockReturnValueOnce: (val: unknown) => { mockResolvedValueOnce: (val: unknown) => void } } };
        const mockUserId = 'user-1';
        const mockVideoId = 'vid-1';

        // 1. Mock fetchVttData: The sentence "The cat runs."
        const mockVtt = [
            {
                start: 0, end: 10, text: "The cat runs.",
                tokens: [
                    { text: "cat", lemma: "cat", pos: "NOUN", is_stop: false }, 
                    { text: "runs", lemma: "run", pos: "VERB", is_stop: false }
                ]
            }
        ];
        mockedDb.limit.mockResolvedValueOnce([{ vttJson: mockVtt }]);

        // 2. Mock fetchKnownLemmas: Only "run" is known
        const mockKnownResult = [{ lemma: "run" }];
        mockedDb.where
            .mockReturnValueOnce(db as never) // First call: select vtt
            .mockResolvedValueOnce(mockKnownResult); // Second call: select known words

        // --- ACT ---
        const TEST_START = 0;
        const TEST_END = 100;
        const deck = await generateDeck(mockUserId, mockVideoId, TEST_START, TEST_END, 'en');

        // --- ASSERT ---
        const EXPECTED_COUNT = 2;
        expect(deck).toHaveLength(EXPECTED_COUNT);
        
        const catCard = deck.find(c => c.lemma === 'cat');
        const runCard = deck.find(c => c.lemma === 'run');

        expect(catCard).toBeDefined();
        expect(catCard?.isKnown).toBe(false);
        expect(catCard?.contextSentence).toBe("The cat runs.");

        expect(runCard).toBeDefined();
        expect(runCard?.isKnown).toBe(true);
    });

    it('should return an empty array if no segments are found in the time range', async () => {
        // --- ARRANGE ---
        const mockedDb = db as unknown as { limit: { mockResolvedValueOnce: (val: unknown) => void }, where: { mockReturnValueOnce: (val: unknown) => { mockResolvedValueOnce: (val: unknown) => void } } };
        mockedDb.limit.mockResolvedValueOnce([{ vttJson: [] }]);

        // --- ACT ---
        const TEST_START = 500;
        const TEST_END = 600;
        const deck = await generateDeck('u1', 'v1', TEST_START, TEST_END, 'en');

        // --- ASSERT ---
        expect(deck).toEqual([]);
    });
});

================
File: apps/platform/src/lib/server/services/chunker.service.ts
================
import { db } from '$lib/server/infrastructure/database';
import { videoProcessing, type DbTokenAnalysis } from '@notflix/database';
import { and, eq } from 'drizzle-orm';
import type { VttSegment } from './video-orchestrator.service';
import { getKnownLemmas } from './knowledge.service';
import { INDICES } from '$lib/constants';

// Types for our deck
export type GameCard = {
    lemma: string;
    lang: string;
    original: string;
    contextSentence: string;
    cefr: string; // A1-C2
    translation: string;
    isKnown: boolean;
};

type CandidateWithMetadata = DbTokenAnalysis & { context: string };

const DEFAULT_DECK_LIMIT = 15;

export async function generateDeck(
    userId: string,
    videoId: string,
    startTime: number,
    endTime: number,
    targetLang: string,
    limit = DEFAULT_DECK_LIMIT
): Promise<GameCard[]> {
    const vttData = await fetchVttData(videoId, targetLang);
    if (!vttData) return [];

    const candidates = extractCandidates(vttData, startTime, endTime);
    if (candidates.length === 0) return [];

    const knownSet = await fetchKnownLemmas(userId, targetLang, candidates);
    const deck = buildUniqueCards(candidates, knownSet, targetLang);

    return sortAndSliceDeck(deck, limit);
}

async function fetchVttData(videoId: string, targetLang: string): Promise<VttSegment[] | null> {
    const [processing] = await db.select()
        .from(videoProcessing)
        .where(and(
            eq(videoProcessing.videoId, videoId),
            eq(videoProcessing.targetLang, targetLang)
        ))
        .limit(1);

    if (!processing || !processing.vttJson) return null;
    return processing.vttJson as VttSegment[];
}

function extractCandidates(vttData: VttSegment[], startTime: number, endTime: number): CandidateWithMetadata[] {
    const candidates: CandidateWithMetadata[] = [];
    const CONTENT_POS = ['NOUN', 'VERB', 'ADJ'];



    for (const segment of vttData) {
        // Include segments that START within the chunk window
        if (segment.start < startTime || segment.start >= endTime) {
            continue;
        }
        if (!segment.tokens) {

            continue;
        }



        for (const token of segment.tokens) {
            if (CONTENT_POS.includes(token.pos)) {
                candidates.push({
                    ...token,
                    context: segment.text
                });
            }
        }
    }
    return candidates;
}

async function fetchKnownLemmas(userId: string, targetLang: string, candidates: CandidateWithMetadata[]): Promise<Set<string>> {
    const lemmaArray = Array.from(new Set(candidates.map(c => c.lemma)));
    return getKnownLemmas(userId, targetLang, lemmaArray, db);
}

function buildUniqueCards(candidates: CandidateWithMetadata[], knownSet: Set<string>, targetLang: string): GameCard[] {
    const lemmaGroups = new Map<string, GameCard>();

    for (const c of candidates) {
        if (!lemmaGroups.has(c.lemma)) {
            lemmaGroups.set(c.lemma, {
                lemma: c.lemma,
                lang: targetLang,
                original: c.text,
                contextSentence: c.context,
                cefr: '?',
                translation: c.translation || '...',
                isKnown: knownSet.has(c.lemma)
            });
        }
    }
    return Array.from(lemmaGroups.values());
}

function sortAndSliceDeck(cards: GameCard[], limit: number): GameCard[] {
    return cards
        .sort((a, b) => {
            if (a.isKnown !== b.isKnown) return a.isKnown ? 1 : INDICES.NOT_FOUND;
            return 0;
        })
        .slice(0, limit);
}

================
File: apps/platform/src/lib/server/services/knowledge.integration.test.ts
================
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { db } from '../infrastructure/database';
import { user, knownWords } from '@notflix/database';
import { eq } from 'drizzle-orm';
import { getKnownLemmas } from './knowledge.service';

describe('KnowledgeService Integration (Real DB)', () => {
    const testUserId = crypto.randomUUID();
    const testTargetLang = 'es';

    beforeAll(async () => {
        // 1. Create User
        await db.insert(user).values({
            id: testUserId,
            name: 'Knowledge Test User',
            email: `knowledge-${testUserId}@example.com`,
            emailVerified: true,
            image: null,
            createdAt: new Date(),
            updatedAt: new Date(),
            targetLang: testTargetLang,
            nativeLang: 'en'
        });
    });

    afterAll(async () => {
        await db.delete(knownWords).where(eq(knownWords.userId, testUserId));
        await db.delete(user).where(eq(user.id, testUserId));
    });

    it('should initially have no known words for the test lemma', async () => {
        const lemmasToCheck = ['perro'];
        const known = await getKnownLemmas(testUserId, testTargetLang, lemmasToCheck, db);
        expect(known.has('perro')).toBe(false);
    });

    it('should retrieve word after marking it as known', async () => {
        // Simulate API write
        await db.insert(knownWords).values({
            userId: testUserId,
            lang: testTargetLang,
            lemma: 'perro',
            score: 1, // Learning
            lastReviewed: new Date()
        });

        // Verify Read
        const lemmasToCheck = ['perro', 'gato'];
        const known = await getKnownLemmas(testUserId, testTargetLang, lemmasToCheck, db);

        expect(known.has('perro')).toBe(true);
        expect(known.has('gato')).toBe(false); // Still unknown
    });
});

================
File: apps/platform/src/lib/server/services/knowledge.service.ts
================
import { db } from '../infrastructure/database';
import { knownWords } from '@notflix/database';
import { eq, and, inArray } from 'drizzle-orm';

export async function getKnownLemmas(
    userId: string,
    targetLang: string,
    lemmas: string[],
    database = db
): Promise<Set<string>> {
    if (lemmas.length === 0) return new Set();

    const uniqueLemmas = Array.from(new Set(lemmas));
    const knownSet = new Set<string>();

    const userKnown = await database.select({ lemma: knownWords.lemma })
        .from(knownWords)
        .where(and(
            eq(knownWords.userId, userId),
            eq(knownWords.lang, targetLang),
            inArray(knownWords.lemma, uniqueLemmas)
        ));
    
    userKnown.forEach((k: { lemma: string }) => knownSet.add(k.lemma));
    return knownSet;
}

================
File: apps/platform/src/lib/server/services/linguistic-filter.integration.test.ts
================
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { db } from '../infrastructure/database';
import { user, knownWords } from '@notflix/database';
import { eq } from 'drizzle-orm';
import { SmartFilter, SegmentClassification } from './linguistic-filter.service';
import type { TokenAnalysis } from '../domain/interfaces';

describe('SmartFilter Integration (Real DB)', () => {
    const testUserId = crypto.randomUUID();
    const testTargetLang = 'es';

    beforeAll(async () => {
        // 1. Create User
        await db.insert(user).values({
            id: testUserId,
            name: 'Filter Integration User',
            email: `filter-${testUserId}@example.com`,
            emailVerified: true,
            image: null,
            createdAt: new Date(),
            updatedAt: new Date(),
            targetLang: testTargetLang,
            nativeLang: 'en'
        });

        // 2. Insert Known Words
        // "gato" (noun) and "comer" (verb) are known.
        // "perro" (noun) is unknown.
        await db.insert(knownWords).values([
            {
                userId: testUserId,
                lang: testTargetLang,
                lemma: 'gato', // Known
                score: 5,
                lastReviewed: new Date()
            },
            {
                userId: testUserId,
                lang: testTargetLang,
                lemma: 'comer', // Known
                score: 3,
                lastReviewed: new Date()
            }
        ]);
    });

    afterAll(async () => {
        await db.delete(knownWords).where(eq(knownWords.userId, testUserId));
        await db.delete(user).where(eq(user.id, testUserId));
    });

    it('should correctly filter segment using real DB (EASY)', async () => {
        const filter = new SmartFilter(db);

        // Segment: "El gato come." (The cat eats)
        // Tokens: El (stop), gato (known), come->comer (known), . (punct)
        // All content words known -> EASY
        const tokens: TokenAnalysis[] = [
            { text: 'El', lemma: 'el', pos: 'DET', is_stop: true },
            { text: 'gato', lemma: 'gato', pos: 'NOUN', is_stop: false },
            { text: 'come', lemma: 'comer', pos: 'VERB', is_stop: false },
            { text: '.', lemma: '.', pos: 'PUNCT', is_stop: false }
        ];

        const result = await filter.filterSegment(tokens, testUserId, testTargetLang);

        expect(result.classification).toBe(SegmentClassification.EASY);
        expect(result.unknownCount).toBe(0);

        // precise verification
        expect(result.tokens[1].lemma).toBe('gato');
        expect(result.tokens[1].isKnown).toBe(true);
        expect(result.tokens[2].lemma).toBe('comer');
        expect(result.tokens[2].isKnown).toBe(true);
    });

    it('should correctly filter segment using real DB (LEARNING)', async () => {
        const filter = new SmartFilter(db);

        // Segment: "El perro come." (The dog eats)
        // Tokens: El (stop), perro (unknown), come->comer (known), . (punct)
        // 1 unknown (perro) -> LEARNING (assuming limits fit)
        const tokens: TokenAnalysis[] = [
            { text: 'El', lemma: 'el', pos: 'DET', is_stop: true },
            { text: 'perro', lemma: 'perro', pos: 'NOUN', is_stop: false }, // Unknown in DB
            { text: 'come', lemma: 'comer', pos: 'VERB', is_stop: false }, // Known
            { text: '.', lemma: '.', pos: 'PUNCT', is_stop: false }
        ];

        const result = await filter.filterSegment(tokens, testUserId, testTargetLang);

        // With 1 unknown and 2 content words, ratio is 0.5.
        // LIMITS.MAX_RATIO_FOR_LEARNING usually 0.4 or higher?
        // Let's check constants if needed, but assuming LEARNING for 1 unknown word is standard.
        // Actually, let's just assert classification and check isKnown flags.

        expect(result.tokens.find(t => t.lemma === 'perro')?.isKnown).toBe(false);
        expect(result.tokens.find(t => t.lemma === 'comer')?.isKnown).toBe(true);

        // If classification logic is strict on ratio, it might be HARD. 
        // 1 unknown / 2 total = 50%. 
        // If MAX_RATIO_FOR_LEARNING is 0.4, this is HARD.
        // If 0.6, this is LEARNING.
        // We'll see what the test returns.
    });
});

================
File: apps/platform/src/lib/server/services/linguistic-filter.service.test.ts
================
/* eslint-disable test-smells/assertion-roulette */
import { describe, it, expect, vi, beforeEach } from 'vitest';
import { SmartFilter, SegmentClassification } from './linguistic-filter.service';
import { db } from '../infrastructure/database';
import { LIMITS } from '$lib/constants';

vi.mock('../infrastructure/database', () => ({
    db: {
        select: vi.fn().mockReturnThis(),
        from: vi.fn().mockReturnThis(),
        where: vi.fn().mockReturnThis()
    }
}));

describe('LinguisticFilterService', () => {
    beforeEach(() => {
        vi.clearAllMocks();
    });

    it('should classify a segment as EASY if all content words are known', async () => {
        // --- ARRANGE ---
        const mockedDb = db as unknown as { where: { mockResolvedValueOnce: (val: unknown) => void } };
        const mockTokens = [
            { text: 'Hola', lemma: 'hola', pos: 'INTJ', is_stop: false },
            { text: '!', lemma: '!', pos: 'PUNCT', is_stop: false }
        ];
        
        // Mock DB returns 'hola' as known
        mockedDb.where.mockResolvedValueOnce([{ lemma: 'hola' }]);

        const filter = new SmartFilter(db as unknown as ConstructorParameters<typeof SmartFilter>[0]);

        // --- ACT ---
        const result = await filter.filterSegment(mockTokens as unknown as Parameters<typeof filter.filterSegment>[0], 'u1', 'es');

        // --- ASSERT ---
        expect(result.classification).toBe(SegmentClassification.EASY);
        expect(result.unknownCount).toBe(0);
        expect(result.tokens[0].isKnown).toBe(true);
    });

    it('should classify a segment as LEARNING if there are few unknown words', async () => {
        // --- ARRANGE ---
        const mockedDb = db as unknown as { where: { mockResolvedValueOnce: (val: unknown) => void } };
        const mockTokens = [
            { text: 'El', lemma: 'el', pos: 'DET', is_stop: true },
            { text: 'gato', lemma: 'gato', pos: 'NOUN', is_stop: false }, // Unknown
            { text: 'corre', lemma: 'correr', pos: 'VERB', is_stop: false }, // Known
            { text: 'rÃ¡pido', lemma: 'rÃ¡pido', pos: 'ADV', is_stop: false }, // Known
            { text: 'hoy', lemma: 'hoy', pos: 'ADV', is_stop: false } // Known
        ];
        
        // Mock DB: correr, rÃ¡pido, hoy are known
        mockedDb.where.mockResolvedValueOnce([
            { lemma: 'correr' },
            { lemma: 'rÃ¡pido' },
            { lemma: 'hoy' }
        ]);

        const filter = new SmartFilter(db as unknown as ConstructorParameters<typeof SmartFilter>[0]);

        // --- ACT ---
        const result = await filter.filterSegment(mockTokens as unknown as Parameters<typeof filter.filterSegment>[0], 'u1', 'es');

        // --- ASSERT ---
        expect(result.classification).toBe(SegmentClassification.LEARNING);
        expect(result.unknownCount).toBe(1);
        expect(result.tokens.find(t => t.lemma === 'gato')?.isKnown).toBe(false);
    });

    it('should classify a segment as HARD if many words are unknown', async () => {
        // --- ARRANGE ---
        const mockedDb = db as unknown as { where: { mockResolvedValueOnce: (val: unknown) => void } };
        // 4 unknown content words
        const mockTokens = Array(LIMITS.HARD_UNKNOWN_THRESHOLD).fill({ text: 'Word', lemma: 'w', pos: 'NOUN', is_stop: false });
        
        mockedDb.where.mockResolvedValueOnce([]); // Nothing known

        const filter = new SmartFilter(db as unknown as ConstructorParameters<typeof SmartFilter>[0]);

        // --- ACT ---
        const result = await filter.filterSegment(mockTokens as unknown as Parameters<typeof filter.filterSegment>[0], 'u1', 'es');

        // --- ASSERT ---
        expect(result.classification).toBe(SegmentClassification.HARD);
        expect(result.unknownCount).toBe(LIMITS.HARD_UNKNOWN_THRESHOLD);
    });
});

================
File: apps/platform/src/lib/server/services/linguistic-filter.service.ts
================
import { db as defaultDb } from '../infrastructure/database';
import type { TokenAnalysis } from '../domain/interfaces';
import { getKnownLemmas } from './knowledge.service';
import { LIMITS } from '$lib/constants';

export enum SegmentClassification {
    EASY = 'EASY',           // Majority of words are known
    LEARNING = 'LEARNING',   // Contains unknown words worth learning
    HARD = 'HARD'            // Too many unknown words, likely confusing
}

export type FilteredSegment = {
    classification: SegmentClassification;
    unknownCount: number;
    tokens: (TokenAnalysis & { isKnown: boolean })[];
};

export class SmartFilter {
    constructor(private db = defaultDb) {}

    /**
     * Bulk version of filterSegment to reduce DB roundtrips.
     */
    async filterBatch(
        segmentsTokens: TokenAnalysis[][],
        userId: string,
        targetLang: string
    ): Promise<FilteredSegment[]> {
        // 1. Extract ALL unique content lemmas from ALL segments
        const allLemmas = new Set<string>();
        for (const tokens of segmentsTokens) {
            tokens.forEach(t => {
                if (!t.is_stop && t.pos !== 'PUNCT') allLemmas.add(t.lemma);
            });
        }

        const lemmaArray = Array.from(allLemmas);
        const knownSet = await getKnownLemmas(userId, targetLang, lemmaArray, this.db);

        // 3. Process each segment using the pre-fetched knownSet
        return segmentsTokens.map(tokens => this.classifyTokens(tokens, knownSet));
    }

    private classifyTokens(tokens: TokenAnalysis[], knownSet: Set<string>): FilteredSegment {
        const contentTokens = tokens.filter(t => !t.is_stop && t.pos !== 'PUNCT');
        
        const enrichedTokens = tokens.map(t => ({
            ...t,
            isKnown: t.is_stop || t.pos === 'PUNCT' || knownSet.has(t.lemma)
        }));

        const unknownCount = contentTokens.filter(t => !knownSet.has(t.lemma)).length;
        const totalContentCount = contentTokens.length;
        
        let classification = SegmentClassification.EASY;
        
        if (totalContentCount > 0) {
            const unknownRatio = unknownCount / totalContentCount;
            
            const isLearning = unknownCount > 0 && 
                               unknownCount <= LIMITS.MAX_UNKNOWN_FOR_LEARNING && 
                               unknownRatio <= LIMITS.MAX_RATIO_FOR_LEARNING;
            
            const isHard = unknownCount > LIMITS.MAX_UNKNOWN_FOR_LEARNING || 
                           unknownRatio > LIMITS.MAX_RATIO_FOR_LEARNING;

            if (isLearning) {
                classification = SegmentClassification.LEARNING;
            } else if (isHard) {
                classification = SegmentClassification.HARD;
            }
        }

        return {
            classification,
            unknownCount,
            tokens: enrichedTokens
        };
    }

    /**
     * Analyzes tokens against user knowledge and classifies the segment.
     */
    async filterSegment(
        tokens: TokenAnalysis[],
        userId: string,
        targetLang: string
    ): Promise<FilteredSegment> {
        const contentTokens = tokens.filter(t => !t.is_stop && t.pos !== 'PUNCT');
        const lemmas = contentTokens.map(t => t.lemma);

        const knownSet = await getKnownLemmas(userId, targetLang, lemmas, this.db);

        return this.classifyTokens(tokens, knownSet);
    }
}

================
File: apps/platform/src/lib/server/services/subtitle.integration.test.ts
================
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { db } from '../infrastructure/database';
import { video, videoProcessing, type DbVttSegment } from '@notflix/database';
import { eq } from 'drizzle-orm';
import { SubtitleService } from './subtitle.service';

describe('SubtitleService Integration (Real DB)', () => {
    const testVideoId = crypto.randomUUID();
    const testTargetLang = 'es';

    beforeAll(async () => {
        // 1. Create Video
        await db.insert(video).values({
            id: testVideoId,
            title: 'Subtitle Test Video',
            filePath: '/tmp/sub.mp4',
            thumbnailPath: '/tmp/thumb.jpg',
            views: 0,
            published: true,
            createdAt: new Date(),
            updatedAt: new Date()
        });

        // 2. Insert VTT Data
        const vttData: DbVttSegment[] = [
            {
                start: 0,
                end: 2,
                text: "Hola mundo",
                translation: "Hello world",
                tokens: [
                    { text: "Hola", lemma: "hola", pos: "INTJ", is_stop: false, translation: "Hello", isKnown: true },
                    { text: " ", lemma: " ", pos: "SPACE", is_stop: true, isKnown: true },
                    { text: "mundo", lemma: "mundo", pos: "NOUN", is_stop: false, translation: "world", isKnown: false }
                ]
            }
        ];

        await db.insert(videoProcessing).values({
            videoId: testVideoId,
            targetLang: testTargetLang,
            status: 'COMPLETED',
            progress: 100,
            vttJson: vttData,
            updatedAt: new Date()
        });
    });

    afterAll(async () => {
        await db.delete(videoProcessing).where(eq(videoProcessing.videoId, testVideoId));
        await db.delete(video).where(eq(video.id, testVideoId));
    });

    it('should generate Native VTT correctly', async () => {
        const service = new SubtitleService(db);
        const vtt = await service.generateVtt(testVideoId, 'native');

        expect(vtt).toContain('WEBVTT');
        expect(vtt).toContain('00:00:00.000 --> 00:00:02.000');
        expect(vtt).toContain('Hola mundo');
        expect(vtt).not.toContain('Hello');
    });

    it('should generate Translated VTT correctly (Full Translation)', async () => {
        const service = new SubtitleService(db);
        const vtt = await service.generateVtt(testVideoId, 'translated');

        expect(vtt).toContain('Hello world');
    });

    it('should generate Bilingual VTT correctly', async () => {
        const service = new SubtitleService(db);
        const vtt = await service.generateVtt(testVideoId, 'bilingual');

        expect(vtt).toContain('Hola mundo'); // Native line
        expect(vtt).toContain('Hello world'); // Translated line
    });

    it('should return null for non-existent video', async () => {
        const service = new SubtitleService(db);
        const vtt = await service.generateVtt(crypto.randomUUID(), 'native');
        expect(vtt).toBeNull();
    });
});

================
File: apps/platform/src/lib/server/services/subtitle.service.ts
================
import { db as defaultDb } from '../infrastructure/database';
import { videoProcessing, type DbVttSegment, type DbTokenAnalysis } from '@notflix/database';
import { eq } from 'drizzle-orm';
import { generateVtt, secondsToSrtTime } from '../utils/subtitle-utils';

export type SubtitleMode = 'native' | 'translated' | 'bilingual';

export class SubtitleService {
    constructor(private db = defaultDb) { }

    async generateVtt(videoId: string, mode: SubtitleMode = 'native'): Promise<string | null> {
        const [processing] = await this.db.select()
            .from(videoProcessing)
            .where(eq(videoProcessing.videoId, videoId))
            .limit(1);

        if (!processing || !processing.vttJson) {
            return null;
        }

        const segments = processing.vttJson as DbVttSegment[];

        const srtSegments = segments.map((seg, i) => {
            const nativeText = seg.text;
            // Use full sentence translation if available (populated by Orchestrator)
            // Fallback to token reconstruction if missing (legacy/partial)
            const translatedText = (seg as any).translation || seg.tokens
                .map((t: DbTokenAnalysis & { translation?: string }) => t.translation || t.text)
                .join('');

            let text = '';
            if (mode === 'native') {
                text = nativeText;
            } else if (mode === 'translated') {
                text = translatedText;
            } else if (mode === 'bilingual') {
                text = `${nativeText}\n${translatedText}`;
            }

            return {
                index: i + 1,
                start: secondsToSrtTime(seg.start),
                end: secondsToSrtTime(seg.end),
                text: text
            };
        });

        return generateVtt(srtSegments);
    }
}

================
File: apps/platform/src/lib/server/services/task-registry.service.ts
================
import { logger } from '$lib/logger';

class TaskRegistry {
    private tasks = new Set<Promise<unknown>>();

    /**
     * Registers a background task. 
     * In a long-running Node.js process (Docker), this ensures we can at least 
     * log the outcome of fire-and-forget operations.
     */
    register(name: string, promise: Promise<unknown>) {
        const taskId = crypto.randomUUID();
        const context = { task: name, taskId };
        
        logger.info(context, 'Background task registered');
        this.tasks.add(promise);
        
        promise
            .then(() => {
                logger.info(context, 'Background task completed');
            })
            .catch((err) => {
                logger.error({ ...context, err: err instanceof Error ? err.message : String(err) }, 'Background task failed');
            })
            .finally(() => {
                this.tasks.delete(promise);
            });
    }

    /**
     * Useful for graceful shutdown if needed.
     */
    async waitForAll() {
        if (this.tasks.size === 0) return;
        logger.info({ count: this.tasks.size }, 'Waiting for background tasks to complete...');
        await Promise.allSettled(this.tasks);
    }
}

export const taskRegistry = new TaskRegistry();

================
File: apps/platform/src/lib/server/services/video-orchestrator.integration.test.ts
================
import { describe, it, expect, vi, beforeAll, afterAll } from 'vitest';
import { db } from '../infrastructure/database';
import { video, videoProcessing } from '@notflix/database';
import { eq } from 'drizzle-orm';
import { Orchestrator } from './video-orchestrator.service';
import { SmartFilter } from './linguistic-filter.service';
import type { IAiGateway } from '../domain/interfaces';

// Mock AI Gateway to isolate testing of DB persistence logic
const mockAiGateway: IAiGateway = {
    generateThumbnail: vi.fn().mockResolvedValue({ thumbnail_path: 'thumb.jpg' }),
    transcribe: vi.fn().mockResolvedValue({
        language: 'es',
        language_probability: 0.99,
        segments: [{ start: 0, end: 1, text: 'Hola mundo' }]
    }),
    analyzeBatch: vi.fn().mockResolvedValue({
        results: [[{ text: 'Hola', lemma: 'hola', pos: 'INTJ', is_stop: false }]]
    }),
    translate: vi.fn().mockResolvedValue({ translations: ['Hello world'] })
};

describe('VideoOrchestratorService Integration', () => {
    let orchestrator: Orchestrator;
    const testVideoId = crypto.randomUUID();
    const testFilePath = '/app/media/test_vid.mp4'; // Dummy path

    beforeAll(async () => {
        // Ensure clean state or setup if needed
        // Assuming DB is running and schema applied via migration or push
        orchestrator = new Orchestrator(mockAiGateway, db, new SmartFilter(db));
    });

    it('should persist processing results to the real database', async () => {
        // 1. Arrange: Insert a video record
        await db.insert(video).values({
            id: testVideoId,
            title: 'Integration Test Video',
            filePath: testFilePath
        });

        // 2. Act: Process the video
        await orchestrator.processVideo(testVideoId, 'es', 'en');

        // 3. Assert: Check DB for results
        const processingRecord = await db.select()
            .from(videoProcessing)
            .where(eq(videoProcessing.videoId, testVideoId));

        expect(processingRecord).toHaveLength(1);
        expect(processingRecord[0].status).toBe('COMPLETED');
        expect(processingRecord[0].vttJson).toBeDefined();

        // precise check on json content if possible
        const segments = processingRecord[0].vttJson as any[];
        expect(segments[0].text).toBe('Hola mundo');
    });

    afterAll(async () => {
        // Cleanup
        await db.delete(videoProcessing).where(eq(videoProcessing.videoId, testVideoId));
        await db.delete(video).where(eq(video.id, testVideoId));
    });
});

================
File: apps/platform/src/lib/server/services/video-orchestrator.service.test.ts
================
import { describe, it, expect, vi, beforeEach, type Mock } from 'vitest';
import type { IAiGateway } from '../domain/interfaces';
import type { SmartFilter } from './linguistic-filter.service';
import { aiGateway } from '../infrastructure/container';
import { db } from '../infrastructure/database';
import { Orchestrator } from './video-orchestrator.service';

// Mock dependencies
vi.mock('../infrastructure/container', () => ({
    aiGateway: {
        transcribe: vi.fn(),
        analyzeBatch: vi.fn(),
        translate: vi.fn(),
        generateThumbnail: vi.fn()
    },
    orchestrator: {},
    smartFilter: {},
    subtitleService: {}
}));

vi.mock('../infrastructure/database', () => ({
    db: {
        select: vi.fn().mockReturnThis(),
        from: vi.fn().mockReturnThis(),
        where: vi.fn().mockReturnThis(),
        limit: vi.fn().mockReturnThis(),
        insert: vi.fn().mockReturnThis(),
        values: vi.fn().mockReturnThis(),
        onConflictDoUpdate: vi.fn().mockReturnThis(),
        update: vi.fn().mockReturnThis(),
        set: vi.fn().mockReturnThis(),
    }
}));

const MOCK_TITLE = 'Test Video';
const MOCK_TEXT = 'Hola mundo';
const LANG_ES = 'es';
const LANG_EN = 'en';

describe('VideoOrchestratorService', () => {
    const mockVideoId = 'vid-123';
    const mockFilePath = 'uploads/test.mp3';

    beforeEach(() => {
        vi.clearAllMocks();
    });

    it('should complete the full processing pipeline for a guest user', async () => {
        const mockedDb = db as unknown as { limit: { mockResolvedValueOnce: (val: unknown) => void }, set: Mock, update: Mock, where: Mock };

        // Mock Database
        mockedDb.limit.mockResolvedValueOnce([
            { id: mockVideoId, filePath: mockFilePath, title: MOCK_TITLE }
        ]);
        
        // Mock set for update check
        mockedDb.set.mockReturnThis();
        mockedDb.update.mockReturnThis();
        mockedDb.where.mockReturnThis();

        setupAiMocks(LANG_ES);

        const orchestrator = new Orchestrator(aiGateway as unknown as IAiGateway, db as unknown as typeof db, {} as SmartFilter);

        // --- ACT ---
        await orchestrator.processVideo(mockVideoId, LANG_ES, LANG_EN);

        // --- ASSERT ---
        verifyPipelineCalls(mockFilePath, LANG_ES, LANG_EN);
        
        // Verify results were saved
        expect(mockedDb.set).toHaveBeenCalledWith(expect.objectContaining({
            status: 'COMPLETED',
            vttJson: expect.arrayContaining([
                expect.objectContaining({
                    text: MOCK_TEXT,
                    tokens: expect.arrayContaining([
                        expect.objectContaining({ translation: 'Hello' })
                    ])
                })
            ])
        }));
    });

    it('should mark video as ERROR if any step fails', async () => {
        const mockedDb = db as unknown as { limit: { mockResolvedValueOnce: (val: unknown) => void }, set: Mock, update: Mock, where: Mock };

        mockedDb.limit.mockResolvedValueOnce([{ id: mockVideoId, filePath: 'bad.mp4', title: MOCK_TITLE }]);
        vi.mocked(aiGateway.transcribe).mockRejectedValue(new Error('AI Offline'));

        const orchestrator = new Orchestrator(aiGateway as unknown as IAiGateway, db as unknown as typeof db, {} as SmartFilter);

        // --- ACT & ASSERT ---
        await expect(orchestrator.processVideo(mockVideoId)).rejects.toThrow('AI Offline');
        
        expect(mockedDb.set).toHaveBeenCalledWith(expect.objectContaining({
            status: 'ERROR'
        }));
    });
});

function setupAiMocks(es = LANG_ES) {
    const MOCK_PROBABILITY = 0.99;
    const MOCK_SEGMENT_START = 0;
    const MOCK_SEGMENT_END = 2;
    
    vi.mocked(aiGateway.transcribe).mockResolvedValue({
        language: es,
        language_probability: MOCK_PROBABILITY,
        segments: [{ start: MOCK_SEGMENT_START, end: MOCK_SEGMENT_END, text: MOCK_TEXT }]
    });

    vi.mocked(aiGateway.analyzeBatch).mockResolvedValue({
        results: [[{ text: 'Hola', lemma: 'hola', pos: 'INTJ', is_stop: false }]]
    });

    vi.mocked(aiGateway.translate).mockResolvedValue({
        translations: ['Hello']
    });

    vi.mocked(aiGateway.generateThumbnail).mockResolvedValue({
        thumbnail_path: 'thumb.jpg'
    });
}

function verifyPipelineCalls(mockFilePath: string, es: string, en: string) {
    expect(aiGateway.transcribe).toHaveBeenCalledWith(mockFilePath, es);
    expect(aiGateway.analyzeBatch).toHaveBeenCalledWith([MOCK_TEXT], es);
    expect(aiGateway.translate).toHaveBeenCalledWith(['hola'], es, en);
}

================
File: apps/platform/src/lib/server/services/video-orchestrator.service.ts
================
import { video, videoProcessing, type DbVttSegment } from '@notflix/database';
import { eq } from 'drizzle-orm';
import type { InferSelectModel } from 'drizzle-orm';
import type { IAiGateway, TranscriptionResponse, TokenAnalysis } from '../domain/interfaces';
import { globalEvents, EVENTS } from '../infrastructure/event-bus';
import { CONFIG, ProcessingStatus, toAiServicePath } from '../infrastructure/config';
import { LIMITS } from '$lib/constants';
import type { SmartFilter } from './linguistic-filter.service';
import { db as drizzleDb } from '../infrastructure/database';

// Infer types from schema
type VideoRecord = InferSelectModel<typeof video>;

type ProgressEmitter = (status: string, percent: number) => void;

// VTT Segment for application logic (mapping DbVttSegment to local needs if necessary)
export type VttSegment = DbVttSegment;

const Progress = {
    THUMBNAIL: 5,
    TRANSCRIBE: 10,
    ANALYZE: 50,
    TRANSLATE: 80
} as const;

export class Orchestrator {
    constructor(
        private aiGateway: IAiGateway,
        private db: typeof drizzleDb,
        private filter: SmartFilter
    ) { }

    async processVideo(
        videoId: string,
        targetLang: string = CONFIG.DEFAULT_TARGET_LANG,
        nativeLang: string = CONFIG.DEFAULT_NATIVE_LANG,
        userId?: string
    ) {
        const emitProgress: ProgressEmitter = (status: string, percent: number) => {
            globalEvents.emit(EVENTS.PROCESSING_UPDATE, { videoId, status, percent });
        };

        console.log(`[Orchestrator] Starting processing for video: ${videoId}, User: ${userId}`);
        emitProgress('STARTING', 0);

        const videoRecord = await this.getVideoRecord(videoId);
        await this.initProcessingRecord(videoId, targetLang);

        try {
            console.log(`[Orchestrator] Generating thumbnail...`);
            await this.generateThumbnail(videoRecord, videoId, emitProgress);

            console.log(`[Orchestrator] Transcribing...`);
            const transcription = await this.transcribe(videoRecord, targetLang, emitProgress);

            console.log(`[Orchestrator] Analyzing...`);
            const analyzedSegments = await this.analyze(transcription, targetLang, emitProgress);

            console.log(`[Orchestrator] Enriching with translations (User: ${userId})...`);
            const finalSegments = await this.enrichWithTranslations(analyzedSegments, targetLang, nativeLang, userId, emitProgress);

            console.log(`[Orchestrator] Saving results...`);
            await this.saveResults(videoId, finalSegments);

            // ...

            emitProgress(ProcessingStatus.COMPLETED, LIMITS.PERCENT_COMPLETE);
            console.log(`[Orchestrator] Processing finished successfully.`);
        } catch (err) {
            console.error(`[Orchestrator] Processing Failed for ${videoId}:`, err);
            await this.markAsError(videoId, emitProgress);
            throw err;
        }
    }

    private async getVideoRecord(videoId: string): Promise<VideoRecord> {
        const [record] = await this.db.select()
            .from(video)
            .where(eq(video.id, videoId))
            .limit(1);

        if (!record) throw new Error(`Video not found: ${videoId}`);
        return record;
    }

    private async initProcessingRecord(videoId: string, targetLang: string) {
        await this.db.insert(videoProcessing).values({
            videoId,
            targetLang,
            status: ProcessingStatus.PENDING,
        }).onConflictDoUpdate({
            target: [videoProcessing.videoId, videoProcessing.targetLang],
            set: { status: ProcessingStatus.PENDING, vttJson: null }
        });
    }

    private async generateThumbnail(videoRecord: VideoRecord, videoId: string, emit: ProgressEmitter) {
        emit('THUMBNAIL_GENERATION', Progress.THUMBNAIL);

        // Skip thumbnail generation for audio-only files
        const audioExtensions = ['.mp3', '.wav', '.m4a', '.aac', '.flac', '.ogg'];
        const isAudio = audioExtensions.some(ext => videoRecord.filePath.toLowerCase().endsWith(ext));

        if (isAudio) {
            console.log(`[Orchestrator] Skipping thumbnail for audio file: ${videoRecord.filePath}`);
            return;
        }

        try {
            const aiPath = toAiServicePath(videoRecord.filePath);
            const thumbRes = await this.aiGateway.generateThumbnail(aiPath);
            await this.db.update(video)
                .set({ thumbnailPath: thumbRes.thumbnail_path })
                .where(eq(video.id, videoId));
        } catch (err) {
            console.error(`[Orchestrator] Thumbnail failed (non-critical):`, err);
        }
    }

    private async transcribe(videoRecord: VideoRecord, targetLang: string, emit: ProgressEmitter) {
        emit('TRANSCRIBING', Progress.TRANSCRIBE);
        const aiPath = toAiServicePath(videoRecord.filePath);
        return this.aiGateway.transcribe(aiPath, targetLang);
    }

    private async analyze(transcription: TranscriptionResponse, targetLang: string, emit: ProgressEmitter): Promise<VttSegment[]> {
        emit('ANALYZING', Progress.ANALYZE);
        const segmentTexts = transcription.segments.map((s: { text: string }) => s.text);
        const batchAnalysis = await this.aiGateway.analyzeBatch(segmentTexts, targetLang);

        return transcription.segments.map((seg: TranscriptionResponse['segments'][0], i: number) => ({
            start: seg.start,
            end: seg.end,
            text: seg.text,
            tokens: batchAnalysis.results[i]
        }));
    }

    private async enrichWithTranslations(
        segments: VttSegment[],
        targetLang: string,
        nativeLang: string,
        userId?: string,
        emit?: ProgressEmitter
    ) {
        emit?.('TRANSLATING', Progress.TRANSLATE);

        if (!userId) {
            return this.enrichGuestTranslations(segments, targetLang, nativeLang);
        }

        return this.enrichUserTranslations(segments, targetLang, nativeLang, userId);
    }

    private async enrichGuestTranslations(segments: VttSegment[], targetLang: string, nativeLang: string) {
        const uniqueLemmas = new Set<string>();
        segments.forEach(seg => seg.tokens.forEach((t: TokenAnalysis) => {
            if (!t.is_stop && t.pos !== 'PUNCT') uniqueLemmas.add(t.lemma);
        }));
        const lemmaList = Array.from(uniqueLemmas);
        if (lemmaList.length === 0) return segments;

        const res = await this.aiGateway.translate(lemmaList, targetLang, nativeLang);
        const lemmaMap = new Map(lemmaList.map((l, i) => [l, res.translations[i]]));

        // Also translate full sentences for "Translated" mode
        const sentenceTexts = segments.map(s => s.text);
        const sentenceTranslations = await this.aiGateway.translate(sentenceTexts, targetLang, nativeLang);

        return segments.map((seg, i) => ({
            ...seg,
            translation: sentenceTranslations.translations[i],
            tokens: seg.tokens.map((t: TokenAnalysis) => ({ ...t, translation: lemmaMap.get(t.lemma) }))
        }));
    }

    private async enrichUserTranslations(segments: VttSegment[], targetLang: string, nativeLang: string, userId: string) {
        const unknownLemmasToTranslate = new Set<string>();

        // 1. Batch filter all segments
        const segmentsTokens = segments.map(s => s.tokens);
        const filteredSegments = await this.filter.filterBatch(segmentsTokens, userId, targetLang);

        // 2. Map filtered results back and collect unknown lemmas
        const enrichedSegments = segments.map((seg, i) => {
            const filtered = filteredSegments[i];

            filtered.tokens.forEach(t => {
                if (!t.isKnown) unknownLemmasToTranslate.add(t.lemma);
            });

            return {
                ...seg,
                classification: filtered.classification,
                tokens: filtered.tokens
            };
        });

        // 3. Batch translate all unknown lemmas
        const lemmaList = Array.from(unknownLemmasToTranslate);

        // 4. Translate full sentences (ALWAYS required for "Translated" mode)
        const sentenceTexts = segments.map(s => s.text);
        // We can run lemma translation and sentence translation in parallel

        const [lemmaRes, sentenceRes] = await Promise.all([
            lemmaList.length > 0 ? this.aiGateway.translate(lemmaList, targetLang, nativeLang) : Promise.resolve({ translations: [] }),
            this.aiGateway.translate(sentenceTexts, targetLang, nativeLang)
        ]);

        const translationMap = new Map(lemmaList.map((l, i) => [l, lemmaRes.translations[i]]));

        enrichedSegments.forEach((seg, i) => {
            // Assign full sentence translation
            (seg as any).translation = sentenceRes.translations[i];

            seg.tokens.forEach((t: TokenAnalysis & { isKnown?: boolean; translation?: string }) => {
                if (!t.isKnown) {
                    t.translation = translationMap.get(t.lemma);
                }
            });
        });

        return enrichedSegments;
    }

    private async saveResults(videoId: string, vttJson: VttSegment[]) {
        await this.db.update(videoProcessing)
            .set({
                status: ProcessingStatus.COMPLETED,
                vttJson: vttJson
            })
            .where(eq(videoProcessing.videoId, videoId));
    }

    private async markAsError(videoId: string, emit: ProgressEmitter) {
        await this.db.update(videoProcessing)
            .set({ status: ProcessingStatus.ERROR })
            .where(eq(videoProcessing.videoId, videoId));
        emit(ProcessingStatus.ERROR, 0);
    }
}

================
File: apps/platform/src/lib/server/utils/media-utils.ts
================
import path from 'path';
import { CONFIG } from '../infrastructure/config';

/**
 * Converts an absolute filesystem path to a relative URL for the media proxy.
 * e.g. "E:/project/media/uploads/video.mp4" -> "/media/uploads/video.mp4"
 */
export function toMediaUrl(absolutePath: string | null | undefined): string {
    if (!absolutePath) return '';
    if (absolutePath.startsWith('http') || absolutePath.startsWith('/')) return absolutePath;

    const mediaRoot = path.resolve(CONFIG.RESOLVED_UPLOAD_DIR, '..');
    
    // Normalize paths for Windows/Linux comparison
    const normalizedAbs = path.normalize(absolutePath);
    const normalizedRoot = path.normalize(mediaRoot);

    if (normalizedAbs.startsWith(normalizedRoot)) {
        const relative = normalizedAbs.slice(normalizedRoot.length);
        // Ensure forward slashes for URLs
        return '/media' + relative.split(path.sep).join('/');
    }

    return absolutePath;
}

================
File: apps/platform/src/lib/server/utils/subtitle-utils.ts
================
import { TIME } from '$lib/constants';

export type SrtSegment = {
    index: number;
    start: string;
    end: string;
    text: string;
};

export function parseSrt(srtContent: string): SrtSegment[] {
    const segments: SrtSegment[] = [];
    const blocks = srtContent.trim().split(/\n\s*\n/);

    for (const block of blocks) {
        const lines = block.split('\n');
        const MIN_LINES_PER_BLOCK = 3;
        if (lines.length >= MIN_LINES_PER_BLOCK) {
            const index = parseInt(lines[0], 10);
            const timeCode = lines[1].split(' --> ');
            const HEADER_LINES = 2;
            const text = lines.slice(HEADER_LINES).join('\n');
            const EXPECTED_TIMECODE_PARTS = 2;
            if (timeCode.length === EXPECTED_TIMECODE_PARTS) {
                segments.push({
                    index,
                    start: timeCode[0].trim(),
                    end: timeCode[1].trim(),
                    text
                });
            }
        }
    }
    return segments;
}

export function generateSrt(segments: SrtSegment[]): string {
    return segments.map(seg => {
        return `${seg.index}\n${seg.start} --> ${seg.end}\n${seg.text}`;
    }).join('\n\n');
}

export function generateVtt(segments: SrtSegment[]): string {
    const body = segments.map(seg => {
        const start = seg.start.replace(',', '.');
        const end = seg.end.replace(',', '.');
        return `${start} --> ${end}\n${seg.text}`;
    }).join('\n\n');
    return `WEBVTT\n\n${body}`;
}

export function secondsToSrtTime(seconds: number): string {
    const pad = (num: number, size: number) => num.toString().padStart(size, '0');
    
    const SECONDS_IN_HOUR = 3600;
    const MILLISECONDS_IN_SECOND = 1000;
    const ISO_START_INDEX = 14;
    const ISO_LENGTH = 5;

    const hours = Math.floor(seconds / SECONDS_IN_HOUR);
    const ms = Math.floor((seconds % 1) * MILLISECONDS_IN_SECOND);
    
    // We can't easily use Date for > 24h, manual math is safer for SRT
    const date = new Date(0);
    date.setMilliseconds(seconds * MILLISECONDS_IN_SECOND);
    const mm = date.toISOString().substr(ISO_START_INDEX, ISO_LENGTH);
    return `${pad(hours, TIME.PADDING_DIGITS)}:${mm},${pad(ms, TIME.MS_DIGITS)}`;
}

================
File: apps/platform/src/lib/utils.ts
================
import { clsx, type ClassValue } from "clsx";
import { twMerge } from "tailwind-merge";

export function cn(...inputs: ClassValue[]) {
	return twMerge(clsx(inputs));
}

// eslint-disable-next-line @typescript-eslint/no-explicit-any
export type WithoutChild<T> = T extends { child?: any } ? Omit<T, "child"> : T;
// eslint-disable-next-line @typescript-eslint/no-explicit-any
export type WithoutChildren<T> = T extends { children?: any } ? Omit<T, "children"> : T;
export type WithoutChildrenOrChild<T> = WithoutChildren<WithoutChild<T>>;
export type WithElementRef<T, U extends HTMLElement = HTMLElement> = T & { ref?: U | null };

================
File: apps/platform/src/routes/+layout.svelte
================
<script lang="ts">
	/* eslint-disable svelte/no-navigation-without-resolve */
	import '../app.css';
	import favicon from "$lib/assets/favicon.svg";
	import { Clapperboard, User, LayoutGrid } from 'lucide-svelte';
	import { base } from '$app/paths';

	let { children } = $props();
</script>

<svelte:head>
	<link rel="icon" href={favicon} />
</svelte:head>

<div class="min-h-screen bg-neutral-950 text-white font-sans selection:bg-red-900 selection:text-white">
	<nav
		class="border-b border-white/5 bg-black/50 backdrop-blur-xl sticky top-0 z-50 transition-all duration-300"
	>
		<div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
			<div class="flex items-center justify-between h-16">
				<div class="flex items-center gap-8">
					<a
						href="{base}/"
						class="flex items-center gap-2 group"
					>
						<div class="bg-red-600 p-1 rounded transform group-hover:rotate-12 transition-transform duration-300">
							<Clapperboard class="h-6 w-6 text-white fill-current" />
						</div>
						<span class="text-white font-bold text-xl tracking-tight group-hover:text-red-500 transition-colors">NOTFLIX</span>
					</a>
					<div
						class="hidden md:flex items-center space-x-1"
					>
						<a
							href="{base}/studio"
							class="flex items-center gap-2 text-zinc-400 hover:text-white hover:bg-white/5 px-3 py-2 rounded-full text-sm font-medium transition-all"
						>
							<LayoutGrid class="h-4 w-4" />
							Studio
						</a>
						<a
							href="{base}/profile"
							class="flex items-center gap-2 text-zinc-400 hover:text-white hover:bg-white/5 px-3 py-2 rounded-full text-sm font-medium transition-all"
						>
							<User class="h-4 w-4" />
							Profile
						</a>
					</div>
				</div>
				
				<!-- Mobile menu button placeholder -->
				<div class="md:hidden">
					<button class="text-zinc-400 hover:text-white">
						<span class="sr-only">Open menu</span>
						<svg class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
							<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16" />
						</svg>
					</button>
				</div>
			</div>
		</div>
	</nav>

	<main class="relative z-0">
		{@render children()}
	</main>
</div>

================
File: apps/platform/src/routes/+page.svelte
================
<script lang="ts">
	import { Play, Info, Plus } from 'lucide-svelte';
	
	// Placeholder data for the "Trending" section
	const TRENDING = [
		{ title: "Cyber Dreams", category: "Sci-Fi", color: "bg-blue-500" },
		{ title: "The Last Algorithm", category: "Thriller", color: "bg-purple-500" },
		{ title: "Neon Nights", category: "Documentary", color: "bg-pink-500" },
		{ title: "Binary Love", category: "Romance", color: "bg-red-500" },
		{ title: "Zero Day", category: "Action", color: "bg-green-500" },
		{ title: "Cloud City", category: "Drama", color: "bg-yellow-500" },
	];
</script>

<div class="relative min-h-[calc(100vh-4rem)] flex flex-col">
	<!-- Hero Section -->
	<section class="relative h-[70vh] w-full flex items-center justify-center overflow-hidden">
		<!-- Background Glow/Image Placeholder -->
		<div class="absolute inset-0 bg-gradient-to-t from-neutral-950 via-neutral-950/50 to-transparent z-10"></div>
		<div class="absolute inset-0 bg-[radial-gradient(ellipse_at_center,_var(--tw-gradient-stops))] from-red-900/20 via-neutral-950 to-neutral-950 z-0"></div>
		
		<!-- Hero Content -->
		<div class="relative z-20 text-center max-w-4xl mx-auto px-4">
			<span class="inline-block py-1 px-3 rounded-full bg-red-500/10 text-red-500 text-xs font-bold tracking-wider mb-6 border border-red-500/20 uppercase">
				AI-Generated Streaming
			</span>
			<h1 class="text-5xl md:text-7xl font-extrabold tracking-tighter text-white mb-6 leading-tight">
				Unlimited Movies, <br/>
				<span class="text-transparent bg-clip-text bg-gradient-to-r from-red-500 to-orange-500">Zero Humans.</span>
			</h1>
			<h3 class="sr-only">Notflix - AI-Powered Entertainment</h3>
			<p class="text-lg md:text-xl text-zinc-400 mb-10 max-w-2xl mx-auto">
				Experience the next generation of entertainment. content generated entirely by artificial intelligence, tailored just for you.
			</p>
			
			<div class="flex flex-col sm:flex-row items-center justify-center gap-4">
				<button class="flex items-center gap-2 bg-white text-black px-8 py-3 rounded-full font-bold hover:bg-zinc-200 transition-colors w-full sm:w-auto justify-center">
					<Play class="h-5 w-5 fill-current" />
					Start Watching
				</button>
				<button class="flex items-center gap-2 bg-white/10 backdrop-blur-sm text-white px-8 py-3 rounded-full font-bold hover:bg-white/20 transition-colors w-full sm:w-auto justify-center">
					<Info class="h-5 w-5" />
					More Info
				</button>
			</div>
		</div>
	</section>

	<!-- Trending Section -->
	<section class="px-4 sm:px-6 lg:px-8 -mt-20 relative z-30 pb-20">
		<h2 class="text-2xl font-bold text-white mb-6">Trending Now</h2>
		
		<div class="grid grid-cols-2 md:grid-cols-3 lg:grid-cols-6 gap-4">
			{#each TRENDING as item, i (item.title)}
				<div class="group relative aspect-[2/3] rounded-lg overflow-hidden bg-zinc-900 cursor-pointer border border-white/5 hover:border-white/20 transition-all hover:scale-105 hover:shadow-2xl hover:shadow-red-900/20 hover:z-10">
					<!-- Image Placeholder -->
					<div class="absolute inset-0 {item.color} opacity-20 group-hover:opacity-30 transition-opacity"></div>
					<div class="absolute inset-0 flex items-center justify-center">
						<span class="text-4xl font-black text-white/10 group-hover:text-white/30 transition-colors">{i + 1}</span>
					</div>

					<!-- Hover Overlay -->
					<div class="absolute inset-0 bg-gradient-to-t from-black via-black/0 to-transparent opacity-60 md:opacity-0 md:group-hover:opacity-100 transition-opacity flex flex-col justify-end p-4">
						<h3 class="font-bold text-white text-lg leading-none mb-1">{item.title}</h3>
						<p class="text-xs text-zinc-300 flex items-center gap-2">
							<span class="w-1.5 h-1.5 rounded-full bg-red-500"></span>
							{item.category}
						</p>
						
						<div class="flex items-center gap-2 mt-3">
							<button class="p-2 rounded-full bg-white text-black hover:bg-zinc-200 transition-colors">
								<Play class="h-3 w-3 fill-current" />
							</button>
							<button class="p-2 rounded-full border border-zinc-500 text-white hover:bg-white/10 transition-colors">
								<Plus class="h-3 w-3" />
							</button>
						</div>
					</div>
				</div>
			{/each}
		</div>
	</section>
</div>

================
File: apps/platform/src/routes/api/auth/[...auth]/+server.ts
================
import { auth } from "$lib/server/infrastructure/auth";
import { toSvelteKitHandler } from "better-auth/svelte-kit";

export const fallback = toSvelteKitHandler(auth);

================
File: apps/platform/src/routes/api/debug/filter/+server.ts
================
import { aiGateway } from '$lib/server/infrastructure/container';
import { parseSrt, generateSrt } from '$lib/server/utils/subtitle-utils';
import { json } from '@sveltejs/kit';
import type { RequestHandler } from './$types';

const HTTP_STATUS_BAD_REQUEST = 400;
const HTTP_STATUS_INTERNAL_SERVER_ERROR = 500;

export const POST: RequestHandler = async ({ request }) => {
    try {
        const formData = await request.formData();
        const file = formData.get('file') as File;
        const language = (formData.get('language') as string) || 'es';

        if (!file) {
            return json({ error: 'No file uploaded' }, { status: HTTP_STATUS_BAD_REQUEST });
        }

        const text = await file.text();
        const segments = parseSrt(text);
        const textsToAnalyze = segments.map(s => s.text);

        if (textsToAnalyze.length > 0) {
            const analysis = await aiGateway.analyzeBatch(textsToAnalyze, language);
            
            segments.forEach((seg, i) => {
                const lemmas = analysis.results[i].map(t => t.lemma).join(' ');
                seg.text = `${seg.text}\n{Lemmas: ${lemmas}}`;
            });
        }

        const outputSrt = generateSrt(segments);

        return new Response(outputSrt, {
            headers: {
                'Content-Type': 'text/plain',
                'Content-Disposition': `attachment; filename="filtered_${file.name}"`
            }
        });

    } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        console.error("Filter Debug Error:", message);
        return json({ error: message }, { status: HTTP_STATUS_INTERNAL_SERVER_ERROR });
    }
};

================
File: apps/platform/src/routes/api/debug/transcribe/+server.ts
================
import { aiGateway } from '$lib/server/infrastructure/container';
import { generateSrt, secondsToSrtTime } from '$lib/server/utils/subtitle-utils';
import { json } from '@sveltejs/kit';
import fs from 'fs';
import path from 'path';
import { CONFIG } from '$lib/server/infrastructure/config';
import type { RequestHandler } from './$types';

const HTTP_STATUS_BAD_REQUEST = 400;
const HTTP_STATUS_INTERNAL_SERVER_ERROR = 500;

export const POST: RequestHandler = async ({ request }) => {
    try {
        const formData = await request.formData();
        const file = formData.get('file') as File;
        const language = (formData.get('language') as string) || 'es';

        if (!file) {
            return json({ error: 'No file uploaded' }, { status: HTTP_STATUS_BAD_REQUEST });
        }

        const tempFilePath = await saveTempFile(file);
        
        try {
            const transcription = await aiGateway.transcribe(tempFilePath, language);
            
            const srtSegments = transcription.segments.map((seg, i) => ({
                index: i + 1,
                start: secondsToSrtTime(seg.start),
                end: secondsToSrtTime(seg.end),
                text: seg.text
            }));
            
            const srtContent = generateSrt(srtSegments);

            return new Response(srtContent, {
                headers: {
                    'Content-Type': 'text/plain',
                    'Content-Disposition': `attachment; filename="transcription.srt"`
                }
            });
        } finally {
            cleanupTempFile(tempFilePath);
        }

    } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        console.error("Transcribe Debug Error:", message);
        return json({ error: message }, { status: HTTP_STATUS_INTERNAL_SERVER_ERROR });
    }
};

async function saveTempFile(file: File): Promise<string> {
    const buffer = Buffer.from(await file.arrayBuffer());
    const targetDir = CONFIG.RESOLVED_UPLOAD_DIR;
    
    if (!fs.existsSync(targetDir)) {
        fs.mkdirSync(targetDir, { recursive: true });
    }

    const tempFilePath = path.join(targetDir, `debug_upload_${Date.now()}_${file.name}`);
    fs.writeFileSync(tempFilePath, buffer);
    return tempFilePath;
}

function cleanupTempFile(filePath: string) {
    if (fs.existsSync(filePath)) {
        fs.unlinkSync(filePath);
    }
}

================
File: apps/platform/src/routes/api/debug/translate/+server.ts
================
import { aiGateway } from '$lib/server/infrastructure/container';
import { parseSrt, generateSrt } from '$lib/server/utils/subtitle-utils';
import { json } from '@sveltejs/kit';
import type { RequestHandler } from './$types';

const HTTP_STATUS_BAD_REQUEST = 400;
const HTTP_STATUS_INTERNAL_SERVER_ERROR = 500;

export const POST: RequestHandler = async ({ request }) => {
    try {
        const formData = await request.formData();
        const file = formData.get('file') as File;
        const sourceLang = (formData.get('sourceLang') as string) || 'es';
        const targetLang = (formData.get('targetLang') as string) || 'en';

        if (!file) {
            return json({ error: 'No file uploaded' }, { status: HTTP_STATUS_BAD_REQUEST });
        }

        const text = await file.text();
        const segments = parseSrt(text);
        const textsToTranslate = segments.map(s => s.text);
        
        const translationRes = await aiGateway.translate(textsToTranslate, sourceLang, targetLang);

        if (translationRes.translations.length !== segments.length) {
            throw new Error('Translation count mismatch');
        }

        const translatedSegments = segments.map((seg, i) => ({
            ...seg,
            text: translationRes.translations[i]
        }));

        const outputSrt = generateSrt(translatedSegments);

        return new Response(outputSrt, {
            headers: {
                'Content-Type': 'text/plain',
                'Content-Disposition': `attachment; filename="translation.srt"`
            }
        });

    } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        console.error("Translate Debug Error:", message);
        return json({ error: message }, { status: HTTP_STATUS_INTERNAL_SERVER_ERROR });
    }
};

================
File: apps/platform/src/routes/api/game/generate/+server.ts
================
import { json } from '@sveltejs/kit';
import { generateDeck } from '$lib/server/services/chunker.service';
import type { RequestHandler } from './$types';

const DEFAULT_END_TIME = 600;
const HTTP_STATUS_UNAUTHORIZED = 401;
const HTTP_STATUS_BAD_REQUEST = 400;

export const GET: RequestHandler = async ({ url, locals }) => {
    const session = await locals.auth();
    if (!session) {
        return json({ error: 'Unauthorized' }, { status: HTTP_STATUS_UNAUTHORIZED });
    }

    const userId = session.user.id;

    const videoId = url.searchParams.get('videoId');
    const start = parseInt(url.searchParams.get('start') || '0', 10);
    const end = parseInt(url.searchParams.get('end') || DEFAULT_END_TIME.toString(), 10);
    const targetLang = url.searchParams.get('targetLang') || 'es';

    if (!videoId) {
        return json({ error: 'Missing videoId' }, { status: HTTP_STATUS_BAD_REQUEST });
    }

    const cards = await generateDeck(
        userId,
        videoId,
        start,
        end,
        targetLang
    );

    console.log(`[API] Generated ${cards.length} cards for video ${videoId} (chunk ${start}-${end}s)`);

    return json({
        nextChunkStart: end,
        cards
    });
};

================
File: apps/platform/src/routes/api/health/+server.ts
================
import { json } from '@sveltejs/kit';
import type { RequestHandler } from './$types';
import { db } from '$lib/server/infrastructure/database';
import { sql } from 'drizzle-orm';

export const GET: RequestHandler = async () => {
    try {
        // Basic DB connectivity check
        await db.execute(sql`SELECT 1`);

        return json({
            status: 'ok',
            timestamp: Date.now(),
            services: {
                database: 'connected'
            }
        });
    } catch (error) {
        return json({
            status: 'error',
            timestamp: Date.now(),
            error: error instanceof Error ? error.message : 'Unknown error'
        }, { status: 503 });
    }
};

================
File: apps/platform/src/routes/api/log/+server.ts
================
import { json } from '@sveltejs/kit';
import { logger } from '$lib/logger';
import type { RequestHandler } from './$types';

const HTTP_STATUS_BAD_REQUEST = 400;

interface LogRequest {
    level?: string;
    message: string;
    [key: string]: unknown;
}

export const POST: RequestHandler = async ({ request }) => {
    try {
        const body = await request.json() as LogRequest;
        const { level, message, ...rest } = body;

        const sensitiveKeys = ['token', 'password', 'secret', 'authorization', 'cookie'];
        
        function redact(obj: Record<string, unknown>): Record<string, unknown> {
            const newObj: Record<string, unknown> = {};
            for (const [key, value] of Object.entries(obj)) {
                if (sensitiveKeys.includes(key.toLowerCase())) {
                    newObj[key] = '[REDACTED]';
                } else if (value !== null && typeof value === 'object' && !Array.isArray(value)) {
                    newObj[key] = redact(value as Record<string, unknown>);
                } else {
                    newObj[key] = value;
                }
            }
            return newObj;
        }

        const cleanedRest = redact(rest);

        const logMap: Record<string, (obj: object, msg: string) => void> = {
            fatal: (obj, msg) => logger.fatal(obj, msg),
            error: (obj, msg) => logger.error(obj, msg),
            warn: (obj, msg) => logger.warn(obj, msg),
            info: (obj, msg) => logger.info(obj, msg),
            debug: (obj, msg) => logger.debug(obj, msg),
            trace: (obj, msg) => logger.trace(obj, msg),
        };

        const logFn = logMap[level || 'info'] || logMap.info;
        logFn(cleanedRest, message);

        return json({ success: true });
    } catch (err) {
        console.error("Failed to process client log", err);
        return json({ success: false, error: 'Invalid log format' }, { status: HTTP_STATUS_BAD_REQUEST });
    }
};

================
File: apps/platform/src/routes/api/process/[id]/+server.ts
================
import { json } from '@sveltejs/kit';
import type { RequestHandler } from './$types';
import { orchestrator } from '$lib/server/infrastructure/container';
import { taskRegistry } from '$lib/server/services/task-registry.service';

const HTTP_STATUS_UNAUTHORIZED = 401;
const HTTP_STATUS_BAD_REQUEST = 400;
const HTTP_STATUS_INTERNAL_SERVER_ERROR = 500;

interface ProcessRequest {
    targetLang?: string;
    nativeLang?: string;
}

export const POST: RequestHandler = async ({ params, request, locals }) => {
    const session = await locals.auth();
    if (!session) {
        return json({ error: 'Unauthorized' }, { status: HTTP_STATUS_UNAUTHORIZED });
    }

    const videoId = params.id;
    if (!videoId) {
        return json({ error: 'Missing videoId' }, { status: HTTP_STATUS_BAD_REQUEST });
    }

    try {
        const body = await request.json() as ProcessRequest;

        // Register background task for observability
        taskRegistry.register(
            `processVideo:${videoId}`,
            orchestrator.processVideo(
                videoId, 
                body.targetLang || 'es', 
                body.nativeLang || 'en', 
                session.user.id
            )
        );

        return json({ success: true, message: 'Processing started in background' });
    } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        console.error("Processing API Error:", message);
        return json({ error: message }, { status: HTTP_STATUS_INTERNAL_SERVER_ERROR });
    }
};

================
File: apps/platform/src/routes/api/videos/[id]/subtitles/+server.ts
================
import { error } from '@sveltejs/kit';
import { subtitleService } from '$lib/server/infrastructure/container';
import type { RequestHandler } from './$types';
import { HTTP_STATUS } from '$lib/constants';

export const GET: RequestHandler = async ({ params, url }) => {
    const mode = url.searchParams.get('mode') || 'native';
    const videoId = params.id;

    if (!videoId) {
        throw error(HTTP_STATUS.BAD_REQUEST, 'Video ID is required');
    }

    try {
        const vttContent = await subtitleService.generateVtt(videoId, mode as unknown as Parameters<typeof subtitleService.generateVtt>[1]);
        return new Response(vttContent, {
            headers: {
                'Content-Type': 'text/vtt',
                'Cache-Control': 'public, max-age=3600'
            }
        });
    } catch (e) {
        console.error(e);
        throw error(HTTP_STATUS.NOT_FOUND, 'Subtitles not found');
    }
};

================
File: apps/platform/src/routes/api/videos/+server.ts
================
import { db } from '$lib/server/infrastructure/database';
import { video, videoProcessing } from '@notflix/database';
import { eq } from 'drizzle-orm';
import { json } from '@sveltejs/kit';
import type { RequestHandler } from './$types';

export const GET: RequestHandler = async ({ locals }) => {
    const session = await locals.auth();
    if (!session) {
        return json({ error: 'Unauthorized' }, { status: 401 });
    }

    const videos = await db.select({
        id: video.id,
        status: videoProcessing.status
    })
        .from(video)
        .leftJoin(videoProcessing, eq(video.id, videoProcessing.videoId));

    return json({ videos });
};

================
File: apps/platform/src/routes/api/words/known/+server.ts
================
import { json } from '@sveltejs/kit';
import { db } from '$lib/server/infrastructure/database';
import { knownWords } from '@notflix/database';
import type { RequestHandler } from './$types';

const HTTP_STATUS_UNAUTHORIZED = 401;
const HTTP_STATUS_BAD_REQUEST = 400;
const HTTP_STATUS_OK = 200;

export const POST: RequestHandler = async ({ request, locals }) => {
    const session = await locals.auth();
    if (!session) {
        return json({ error: 'Unauthorized' }, { status: HTTP_STATUS_UNAUTHORIZED });
    }

    const userId = session.user.id;
    let body;
    try {
        body = await request.json();
    } catch {
        return json({ error: 'Invalid JSON' }, { status: HTTP_STATUS_BAD_REQUEST });
    }

    const { lemma, lang } = body;

    if (!lemma || !lang) {
        return json({ error: 'Missing lemma or lang' }, { status: HTTP_STATUS_BAD_REQUEST });
    }

    try {
        await db.insert(knownWords).values({
            userId,
            lemma,
            lang,
            level: null, // User-defined/manual
        }).onConflictDoNothing(); // If already known, do nothing

        return json({ success: true }, { status: HTTP_STATUS_OK });
    } catch (e) {
        console.error('Failed to save known word:', e);
        return json({ error: 'Database error' }, { status: 500 });
    }
};

================
File: apps/platform/src/routes/debug/+page.svelte
================
<script lang="ts">
    /* eslint-disable sonarjs/no-duplicate-string */

    let activeTab = $state('transcribe'); // transcribe, filter, translate, pipeline
    let isLoading = $state(false);
    let progress = $state(0); 
    let statusMessage = $state('');

    const FILE_INPUT_CLASSES = "block w-full text-sm text-zinc-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-zinc-800 file:text-zinc-300 hover:file:bg-zinc-700";
    const TEXT_INPUT_CLASSES = "bg-black/50 border border-zinc-700 text-white p-2 rounded w-full max-w-xs";
    const ACTION_BUTTON_CLASSES = "bg-red-600 text-white px-6 py-2 rounded-full font-bold hover:bg-red-700 disabled:opacity-50 transition-colors";

    const PROGRESS_INITIAL = 0;
    const PROGRESS_MID = 50;
    const PROGRESS_COMPLETE = 100;

    // Transcribe
    let transcribeFile = $state<FileList>();
    let transcribeLang = $state('es');
    let videoPreviewUrl = $state<string | null>(null);

    // Filter
    let filterFile = $state<FileList>();
    let filterLang = $state('es');

    // Translate
    let translateFile = $state<FileList>();
    let sourceLang = $state('de');
    let targetLang = $state('es');

    // Pipeline
    let pipelineFile = $state<FileList>();
    let pipelineSourceLang = $state('es');
    let pipelineTargetLang = $state('en');
    let pipelineVideoPreviewUrl = $state<string | null>(null);

    $effect(() => {
        if (transcribeFile && transcribeFile[0]) {
            if (videoPreviewUrl) URL.revokeObjectURL(videoPreviewUrl);
            videoPreviewUrl = URL.createObjectURL(transcribeFile[0]);
        }
    });

    $effect(() => {
        if (pipelineFile && pipelineFile[0]) {
            if (pipelineVideoPreviewUrl) URL.revokeObjectURL(pipelineVideoPreviewUrl);
            pipelineVideoPreviewUrl = URL.createObjectURL(pipelineFile[0]);
        }
    });

    async function handleTranscribe() {
        if (!transcribeFile || transcribeFile.length === 0) return;
        
        await runProcess('/api/debug/transcribe', {
            file: transcribeFile[0],
            language: transcribeLang
        }, 'transcription.srt');
    }

    async function handleFilter() {
        if (!filterFile || filterFile.length === 0) return;

        await runProcess('/api/debug/filter', {
            file: filterFile[0],
            language: filterLang
        }, 'analysis.srt');
    }

    async function handleTranslate() {
        if (!translateFile || translateFile.length === 0) return;

        await runProcess('/api/debug/translate', {
            file: translateFile[0],
            sourceLang,
            targetLang
        }, 'translation.srt');
    }

    async function handlePipeline() {
        if (!pipelineFile || !pipelineFile[0]) {
            statusMessage = "Please select a file first.";
            return;
        }

        isLoading = true;
        progress = PROGRESS_INITIAL;
        
        try {
            statusMessage = 'Step 1/3: Transcribing Video...';
            const transcriptionBlob = await runProcess('/api/debug/transcribe', {
                file: pipelineFile[0],
                language: pipelineSourceLang
            }, null, false);
            
            statusMessage = 'Step 2/3: Analyzing (Filtering)...';
            progress = PROGRESS_MID; 
            const srtFile = new File([transcriptionBlob], "temp.srt", { type: "text/plain" });
            
            const analysisBlob = await runProcess('/api/debug/filter', {
                file: srtFile,
                language: pipelineSourceLang
            }, null, false);

            statusMessage = 'Step 3/3: Translating...';
            const analysisFile = new File([analysisBlob], "temp_analyzed.srt", { type: "text/plain" });

            await runProcess('/api/debug/translate', {
                file: analysisFile,
                sourceLang: pipelineSourceLang,
                targetLang: pipelineTargetLang
            }, 'pipeline_complete.srt', true);

            progress = PROGRESS_COMPLETE;
            statusMessage = 'Pipeline Completed Successfully!';

        } catch (err) {
            const message = err instanceof Error ? err.message : String(err);
            console.error("Pipeline Error:", message);
            statusMessage = `Pipeline Error: ${message}`;
        } finally {
            isLoading = false;
        }
    }

    type FormDataValue = string | Blob | File;

    function createFormData(data: Record<string, FormDataValue>): FormData {
        const formData = new FormData();
        for (const key in data) {
            formData.append(key, data[key]);
        }
        return formData;
    }

    function updateStatus(message: string, currentProgress: number) {
        statusMessage = message;
        progress = currentProgress;
    }

    async function executeRequest(url: string, data: Record<string, FormDataValue>): Promise<Blob> {
        const res = await fetch(url, {
            method: 'POST',
            body: createFormData(data)
        });

        if (!res.ok) {
            const errorJson = await res.json();
            throw new Error(errorJson.error || res.statusText);
        }

        return res.blob();
    }

    async function runProcess(
        url: string, 
        data: Record<string, FormDataValue>, 
        downloadName: string | null = null, 
        autoStopLoading = true
    ): Promise<Blob> {
        if (autoStopLoading) {
            isLoading = true;
            updateStatus('Processing...', PROGRESS_INITIAL);
        }
        
        try {
            const blob = await executeRequest(url, data);
            
            if (downloadName) triggerDownload(blob, downloadName);
            
            if (autoStopLoading) {
                updateStatus('Finished!', PROGRESS_COMPLETE);
            }
            return blob;

        } catch (err) {
            if (autoStopLoading) {
                const message = err instanceof Error ? err.message : String(err);
                statusMessage = `Error: ${message}`;
            }
            throw err;
        } finally {
            if (autoStopLoading) isLoading = false;
        }
    }

    function triggerDownload(blob: Blob, filename: string) {
        const downloadUrl = window.URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = downloadUrl;
        a.download = filename;
        document.body.appendChild(a);
        a.click();
        a.remove();
        window.URL.revokeObjectURL(downloadUrl);
    }
</script>

<div class="container mx-auto p-8">
    <h1 class="text-3xl font-bold mb-6 text-white">Linguistics Debugger</h1>

    <div class="flex mb-4 border-b border-zinc-800">
        <button 
            class="px-4 py-2 mr-2 {activeTab === 'transcribe' ? 'border-b-2 border-red-500 font-bold text-white' : 'text-zinc-400'}"
            onclick={() => activeTab = 'transcribe'}>
            Transcribe
        </button>
        <button 
            class="px-4 py-2 mr-2 {activeTab === 'filter' ? 'border-b-2 border-red-500 font-bold text-white' : 'text-zinc-400'}"
            onclick={() => activeTab = 'filter'}>
            Filter (Analyze)
        </button>
        <button 
            class="px-4 py-2 mr-2 {activeTab === 'translate' ? 'border-b-2 border-red-500 font-bold text-white' : 'text-zinc-400'}"
            onclick={() => activeTab = 'translate'}>
            Translate
        </button>
        <button 
            class="px-4 py-2 {activeTab === 'pipeline' ? 'border-b-2 border-red-500 font-bold text-white' : 'text-zinc-400'}"
            onclick={() => activeTab = 'pipeline'}>
            Full Pipeline
        </button>
    </div>

    <div class="p-6 border border-zinc-800 rounded-xl shadow-md bg-zinc-900">
        {#if activeTab === 'transcribe'}
            <h2 class="text-xl font-semibold mb-4 text-white">Transcribe Video</h2>
            <div class="mb-4">
                <label class="block">
                    <span class="block mb-2 font-medium text-zinc-300">Video File</span>
                    <input type="file" accept="video/*,audio/*" onchange={(e) => transcribeFile = e.currentTarget.files!} class={FILE_INPUT_CLASSES}/>
                </label>
            </div>

            {#if videoPreviewUrl}
                <div class="mb-4">
                    <!-- svelte-ignore a11y_media_has_caption -->
                    <video src={videoPreviewUrl} controls class="w-full max-h-96 bg-black rounded border border-zinc-800"></video>
                </div>
            {/if}

            <div class="mb-4">
                <label class="block">
                    <span class="block mb-2 font-medium text-zinc-300">Language (e.g. es, en)</span>
                    <input type="text" bind:value={transcribeLang} class={TEXT_INPUT_CLASSES}/>
                </label>
            </div>
            <button onclick={handleTranscribe} disabled={isLoading} class={ACTION_BUTTON_CLASSES}>
                Start Transcription
            </button>

        {:else if activeTab === 'filter'}
            <h2 class="text-xl font-semibold mb-4 text-white">Filter / Analyze SRT</h2>
            <div class="mb-4">
                <label class="block">
                    <span class="block mb-2 font-medium text-zinc-300">SRT File</span>
                    <input type="file" accept=".srt" onchange={(e) => filterFile = e.currentTarget.files!} class={FILE_INPUT_CLASSES}/>
                </label>
            </div>
            <div class="mb-4">
                <label class="block">
                    <span class="block mb-2 font-medium text-zinc-300">Language (of SRT)</span>
                    <input type="text" bind:value={filterLang} class={TEXT_INPUT_CLASSES}/>
                </label>
            </div>
            <button onclick={handleFilter} disabled={isLoading} class={ACTION_BUTTON_CLASSES}>
                Start Analysis
            </button>

        {:else if activeTab === 'translate'}
            <h2 class="text-xl font-semibold mb-4 text-white">Translate SRT</h2>
            <div class="mb-4">
                <label class="block">
                    <span class="block mb-2 font-medium text-zinc-300">SRT File</span>
                    <input type="file" accept=".srt" onchange={(e) => translateFile = e.currentTarget.files!} class={FILE_INPUT_CLASSES}/>
                </label>
            </div>
            <div class="grid grid-cols-2 gap-4 mb-4 max-w-md">
                <div>
                    <label class="block">
                        <span class="block mb-2 font-medium text-zinc-300">Source Language</span>
                        <input type="text" bind:value={sourceLang} class="bg-black/50 border border-zinc-700 text-white p-2 rounded w-full"/>
                    </label>
                </div>
                <div>
                    <label class="block">
                        <span class="block mb-2 font-medium text-zinc-300">Target Language</span>
                        <input type="text" bind:value={targetLang} class="bg-black/50 border border-zinc-700 text-white p-2 rounded w-full"/>
                    </label>
                </div>
            </div>
            <button onclick={handleTranslate} disabled={isLoading} class={ACTION_BUTTON_CLASSES}>
                Start Translation
            </button>

        {:else if activeTab === 'pipeline'}
            <h2 class="text-xl font-semibold mb-4 text-white">Full Pipeline (Transcribe -> Analyze -> Translate)</h2>
            <div class="mb-4">
                <label class="block">
                    <span class="block mb-2 font-medium text-zinc-300">Video File</span>
                    <input type="file" accept="video/*,audio/*" onchange={(e) => pipelineFile = e.currentTarget.files!} class={FILE_INPUT_CLASSES}/>
                </label>
            </div>

            {#if pipelineVideoPreviewUrl}
                <div class="mb-4">
                    <!-- svelte-ignore a11y_media_has_caption -->
                    <video src={pipelineVideoPreviewUrl} controls class="w-full max-h-96 bg-black rounded border border-zinc-800"></video>
                </div>
            {/if}

            <div class="grid grid-cols-2 gap-4 mb-4 max-w-md">
                <div>
                    <label class="block">
                        <span class="block mb-2 font-medium text-zinc-300">Source Language (Video)</span>
                        <input type="text" bind:value={pipelineSourceLang} class="bg-black/50 border border-zinc-700 text-white p-2 rounded w-full"/>
                    </label>
                </div>
                <div>
                    <label class="block">
                        <span class="block mb-2 font-medium text-zinc-300">Target Language (Translation)</span>
                        <input type="text" bind:value={pipelineTargetLang} class="bg-black/50 border border-zinc-700 text-white p-2 rounded w-full"/>
                    </label>
                </div>
            </div>
            <button onclick={handlePipeline} disabled={isLoading} class={ACTION_BUTTON_CLASSES}>
                Run Full Pipeline
            </button>
        {/if}

        {#if isLoading || progress > 0}
            <div class="mt-6">
                <div class="flex justify-between mb-1">
                    <span class="text-base font-medium text-red-500">{statusMessage}</span>
                    <span class="text-sm font-medium text-red-500">{progress}%</span>
                </div>
                <div class="w-full bg-zinc-800 rounded-full h-2.5">
                    <div class="bg-red-600 h-2.5 rounded-full transition-all duration-500" style="width: {progress}%"></div>
                </div>
            </div>
        {/if}
    </div>
</div>

================
File: apps/platform/src/routes/profile/+page.server.ts
================
import { db } from '$lib/server/infrastructure/database';
import { user } from '@notflix/database';
import { eq } from 'drizzle-orm';
import type { PageServerLoad, Actions } from './$types';
import { redirect, fail } from '@sveltejs/kit';
import { z } from 'zod';
import { GAME, HTTP_STATUS } from '$lib/constants';

const profileSchema = z.object({
    gameInterval: z.string().refine((val) => {
        const num = parseInt(val, 10);
        return !isNaN(num) && num >= 1 && num <= GAME.MAX_INTERVAL_MINUTES;
    }, {
        message: "Interval must be between 1 and 60 minutes"
    })
});

const HTTP_STATUS_SEE_OTHER = 303;

export const load: PageServerLoad = async ({ locals }) => {
    const session = await locals.auth();
    if (!session) {
        throw redirect(HTTP_STATUS_SEE_OTHER, '/login');
    }

    const [profile] = await db.select()
        .from(user)
        .where(eq(user.id, session.user.id))
        .limit(1);

    if (!profile) {
        throw new Error("User profile not found");
    }

    return {
        profile,
        user: session.user,
        session,
        initialData: {
            gameInterval: (profile.gameIntervalMinutes || GAME.DEFAULT_INTERVAL_MINUTES).toString()
        }
    };
};

export const actions: Actions = {
    updateInterval: async ({ request, locals }) => {
        const session = await locals.auth();
        if (!session) {
            throw redirect(HTTP_STATUS_SEE_OTHER, '/login');
        }

        const formData = await request.formData();
        const data = Object.fromEntries(formData);
        const gameInterval = data.gameInterval as string;
        
        const result = profileSchema.safeParse(data);

        if (!result.success) {
            return fail(HTTP_STATUS.BAD_REQUEST, { 
                errors: result.error.flatten().fieldErrors,
                data: { gameInterval }
            });
        }

        await db.update(user)
            .set({ gameIntervalMinutes: parseInt(gameInterval, 10) })
            .where(eq(user.id, session.user.id));

        return { success: true, data: result.data };
    }
};

================
File: apps/platform/src/routes/profile/+page.svelte
================
<script lang="ts">
    import { Button } from "$lib/components/ui/button";
    import * as Select from "$lib/components/ui/select";
    import * as Card from "$lib/components/ui/card";
    import { CheckCircle2 } from 'lucide-svelte';
    import { enhance } from '$app/forms';
    import type { PageData, ActionData } from './$types';
    import { untrack } from 'svelte';

    interface Props {
        data: PageData & { initialData: { gameInterval: string } };
        form: ActionData & { errors?: Record<string, string[]> };
    }

    let { data, form }: Props = $props();

    // Manual form state using Svelte 5 runes
    let gameInterval = $state("");
    let isSubmitting = $state(false);

    // Sync local state when server data changes (e.g. after a redirect or invalidation)
    $effect(() => {
        const nextValue = data.initialData.gameInterval;
        untrack(() => {
            gameInterval = nextValue;
        });
    });

    function getIntervalLabel(value: string) {
        const num = Number(value);
        if (num === 0) return 'Off (Netflix Mode)';
        return `Every ${num} Minutes`;
    }
</script>

<div class="max-w-4xl mx-auto p-8">
    <h1 class="text-3xl font-bold text-white mb-8">User Profile</h1>

    <Card.Root class="bg-zinc-900 border-zinc-800 shadow-xl">
        <Card.Header>
            <Card.Title class="text-xl text-zinc-100 flex items-center gap-2">
                <span class="w-1 h-6 bg-red-600 rounded-full"></span>
                Game Settings
            </Card.Title>
            <Card.Description>
                Control how often interactive learning challenges appear during playback.
            </Card.Description>
        </Card.Header>
        <Card.Content>
            <form 
                method="POST" 
                action="?/updateInterval" 
                use:enhance={() => {
                    isSubmitting = true;
                    return async ({ update }) => {
                        await update();
                        isSubmitting = false;
                    };
                }} 
                class="space-y-6"
            >
                <div class="space-y-2">
                    <label class="text-sm font-medium text-zinc-300" for="gameInterval">
                        Game Interrupt Interval
                    </label>
                    <input type="hidden" name="gameInterval" value={gameInterval} />
                    <Select.Root type="single" bind:value={gameInterval}>
                        <Select.Trigger class="w-full max-w-xs bg-black/50 border-zinc-700 text-white">
                            {getIntervalLabel(gameInterval)}
                        </Select.Trigger>
                        <Select.Content class="bg-zinc-900 border-zinc-700 text-white">
                            <Select.Item value="0">Off (Netflix Mode)</Select.Item>
                            <Select.Item value="5">Every 5 Minutes</Select.Item>
                            <Select.Item value="10">Every 10 Minutes</Select.Item>
                            <Select.Item value="20">Every 20 Minutes</Select.Item>
                        </Select.Content>
                    </Select.Root>
                    {#if form?.errors?.gameInterval}
                        <p class="text-sm text-red-500">{form.errors.gameInterval[0]}</p>
                    {/if}
                </div>

                <Button type="submit" disabled={isSubmitting} class="bg-red-600 hover:bg-red-700 text-white font-bold px-8">
                    {isSubmitting ? "Saving..." : "Save Settings"}
                </Button>
            </form>

            {#if form?.success}
                <div class="mt-6 p-4 bg-green-900/20 border border-green-900/50 text-green-400 rounded-lg flex items-center gap-2">
                    <CheckCircle2 class="h-5 w-5" />
                    Settings saved successfully!
                </div>
            {/if}
        </Card.Content>
    </Card.Root>
</div>

================
File: apps/platform/src/routes/studio/+page.server.ts
================
import { db } from '$lib/server/infrastructure/database';
import { video, videoProcessing } from '@notflix/database';
import { eq, desc } from 'drizzle-orm';
import { orchestrator } from '$lib/server/infrastructure/container';
import { CONFIG } from '$lib/server/infrastructure/config';
import { taskRegistry } from '$lib/server/services/task-registry.service';
import { toMediaUrl } from '$lib/server/utils/media-utils';

export const load = async ({ depends }) => {
    depends('app:videos');
    const videos = await db.select({
        id: video.id,
        title: video.title,
        status: videoProcessing.status,
        createdAt: video.createdAt,
        thumbnailPath: video.thumbnailPath
    })
        .from(video)
        .leftJoin(videoProcessing, eq(video.id, videoProcessing.videoId))
        .orderBy(desc(video.createdAt));

    return {
        videos: videos.map(v => ({
            ...v,
            thumbnailPath: toMediaUrl(v.thumbnailPath)
        }))
    };
};

export const actions = {
    reprocess: async ({ request, locals }) => {
        const session = await locals.auth();
        const formData = await request.formData();
        const id = formData.get('id') as string;

        if (!id) return { success: false };

        taskRegistry.register(
            `reprocessVideo:${id}`,
            orchestrator.processVideo(
                id,
                'es', // Default for now
                session?.user.nativeLang || CONFIG.DEFAULT_NATIVE_LANG,
                session?.user.id
            )
        );

        return { success: true };
    }
};

================
File: apps/platform/src/routes/studio/+page.svelte
================
<script lang="ts">
    /* eslint-disable svelte/no-navigation-without-resolve */
    import { onMount } from 'svelte';
    import { base } from '$app/paths';
    import { Button } from "$lib/components/ui/button";
    import { Plus, Play, RotateCw, Video } from 'lucide-svelte';
    import { Badge } from "$lib/components/ui/badge";
    import * as Card from "$lib/components/ui/card";
    import { enhance } from '$app/forms';
    import { invalidate } from '$app/navigation';
    
    let { data } = $props();
    
    const POLLING_INTERVAL_MS = 3000;

    onMount(() => {
        const interval = setInterval(async () => {
            // Only poll if there are pending videos
            const hasPending = data.videos.some(v => v.status === 'PENDING' || !v.status);
            if (hasPending) {
                await invalidate('app:videos');
            }
        }, POLLING_INTERVAL_MS);
        
        return () => clearInterval(interval);
    });

    function getStatusVariant(status: string | null): "default" | "secondary" | "destructive" | "outline" {
        if (status === 'COMPLETED') return 'default';
        if (status === 'ERROR') return 'destructive';
        if (status === 'PENDING') return 'secondary';
        return 'outline';
    }
</script>

<div class="p-8 max-w-7xl mx-auto min-h-screen">
    <div class="flex justify-between items-end mb-8">
        <div>
            <h1 class="text-4xl font-bold text-white tracking-tight mb-2">Creator Studio</h1>
            <p class="text-zinc-400">Manage and upload your AI-generated content.</p>
        </div>
        <Button href="{base}/studio/upload" class="bg-white text-black hover:bg-zinc-200 rounded-full font-bold" data-testid="upload-link">
            <Plus class="mr-2 h-5 w-5" />
            Upload New Video
        </Button>
    </div>

    <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-4 gap-6">
        {#each data.videos as video (video.id)}
            <Card.Root class="group bg-zinc-900/50 border-white/5 hover:border-white/20 transition-all hover:-translate-y-1 overflow-hidden" data-testid="video-item">
                <a
                    href="{base}/watch/{video.id}"
                    class="block aspect-video bg-black relative overflow-hidden"
                >
                    {#if video.thumbnailPath}
                        <!-- svelte-ignore a11y_missing_attribute -->
                        <img
                            src={video.thumbnailPath}
                            class="w-full h-full object-cover opacity-80 group-hover:opacity-100 transition-opacity"
                        />
                    {:else}
                        <div
                            class="w-full h-full flex flex-col items-center justify-center text-zinc-700 bg-zinc-900"
                        >
                            <Video class="w-12 h-12 mb-2 opacity-50" />
                            <span class="text-xs font-medium uppercase tracking-wider">No Thumbnail</span>
                        </div>
                    {/if}

                    <div class="absolute top-2 right-2">
                        <Badge variant={getStatusVariant(video.status)} data-testid="status-badge">
                            {video.status || "UNPROCESSED"}
                        </Badge>
                    </div>
                    
                    <div class="absolute inset-0 bg-black/50 flex items-center justify-center opacity-0 group-hover:opacity-100 transition-opacity">
                         <div class="bg-white text-black p-3 rounded-full transform scale-75 group-hover:scale-100 transition-transform">
                            <Play class="w-6 h-6 fill-current" />
                         </div>
                    </div>
                </a>
                <Card.Header class="p-5 pb-0">
                    <Card.Title class="text-lg truncate">{video.title}</Card.Title>
                    <Card.Description class="text-xs text-zinc-500">
                        Uploaded on {new Date(video.createdAt).toLocaleDateString()}
                    </Card.Description>
                </Card.Header>
                <Card.Content class="p-5 pt-4 mt-2 border-t border-white/5 flex items-center justify-between">
                    <Button variant="link" href="{base}/watch/{video.id}" class="p-0 h-auto text-xs font-bold text-white hover:text-red-500 uppercase tracking-wider">
                        Watch Now
                    </Button>
                    {#if !video.status || video.status === "ERROR"}
                        <form method="POST" action="{base}/studio?/reprocess" use:enhance>
                            <input
                                type="hidden"
                                name="id"
                                value={video.id}
                            />
                            <Button type="submit" variant="ghost" class="h-auto p-0 text-xs font-bold text-red-500 hover:text-red-400 uppercase tracking-wider hover:bg-transparent">
                                <RotateCw class="mr-1 h-3 w-3" />
                                Retry
                            </Button>
                        </form>
                    {/if}
                </Card.Content>
            </Card.Root>
        {/each}

        {#if data.videos.length === 0}
            <div class="col-span-full py-32 text-center border-2 border-dashed border-zinc-800 rounded-2xl bg-zinc-900/20">
                <div class="inline-flex items-center justify-center w-16 h-16 rounded-full bg-zinc-800 mb-4 text-zinc-500">
                    <Video class="w-8 h-8" />
                </div>
                <h3 class="text-xl font-bold text-white mb-2">No content yet</h3>
                <p class="text-zinc-500 mb-6 max-w-sm mx-auto">Upload your first video to start building your AI-generated library.</p>
                <Button href="{base}/studio/upload" class="bg-red-600 hover:bg-red-700 text-white rounded-full font-bold">
                    Upload Video
                </Button>
            </div>
        {/if}
    </div>
</div>

================
File: apps/platform/src/routes/studio/upload/+page.server.ts
================
import { fail, redirect } from '@sveltejs/kit';
import { db } from '$lib/server/infrastructure/database';
import { video } from '@notflix/database';
import { writeFile, mkdir } from 'fs/promises';
import { join } from 'path';
import crypto from 'crypto';
import { orchestrator } from '$lib/server/infrastructure/container';
import { CONFIG } from '$lib/server/infrastructure/config';
import { z } from 'zod';
import { taskRegistry } from '$lib/server/services/task-registry.service';
import type { User } from '$lib/server/infrastructure/auth';

import { HTTP_STATUS, LIMITS } from '$lib/constants';

const MIN_LANG_LEN = 2;
const MAX_LANG_LEN = 5;

// Define schema for validation
const uploadSchema = z.object({
    title: z.string().min(1, 'Title is required').max(LIMITS.MAX_TITLE_LENGTH),
    targetLang: z.string().min(MIN_LANG_LEN).max(MAX_LANG_LEN).default('es'),
});

export const load = async () => {
    return {
        initialData: {
            title: '',
            targetLang: 'es'
        }
    };
};

export const actions = {
    upload: async ({ request, locals }) => {
        const session = await locals.auth();
        const formData = await request.formData();
        
        const title = formData.get('title') as string;
        const targetLang = formData.get('targetLang') as string;
        const file = formData.get('file') as File;

        const result = uploadSchema.safeParse({ title, targetLang });

        if (!result.success || !file || file.size === 0) {
            const fieldErrors = result.success ? {} : result.error.flatten().fieldErrors;
            const fileErrors = (!file || file.size === 0) ? ['File is required'] : [];
            
            return fail(HTTP_STATUS.BAD_REQUEST, { 
                errors: {
                    ...fieldErrors,
                    file: fileErrors.length > 0 ? fileErrors : undefined
                },
                data: { title, targetLang }
            });
        }

        const videoId = crypto.randomUUID();
        const filePath = await saveUploadedFile(file, videoId);

        await db.insert(video).values({
            id: videoId,
            title: result.data.title,
            filePath: filePath,
            thumbnailPath: '/placeholder.jpg',
            views: 0,
            published: true
        });

        queueProcessing(videoId, result.data.targetLang, session?.user);

        throw redirect(HTTP_STATUS.SEE_OTHER, '/studio'); // 303 is standard for redirects after post
    }
};

async function saveUploadedFile(file: File, videoId: string): Promise<string> {
    const targetDir = CONFIG.RESOLVED_UPLOAD_DIR;
    await mkdir(targetDir, { recursive: true });

    const ext = file.name.split('.').pop();
    const fileName = `${videoId}.${ext}`;
    const filePath = join(targetDir, fileName);

    const arrayBuffer = await file.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    await writeFile(filePath, buffer);

    return filePath;
}

function queueProcessing(videoId: string, targetLang: string, user: User | undefined) {
    taskRegistry.register(
        `processVideo:${videoId}`,
        orchestrator.processVideo(
            videoId,
            targetLang,
            user?.nativeLang || CONFIG.DEFAULT_NATIVE_LANG,
            user?.id
        )
    );
}

================
File: apps/platform/src/routes/studio/upload/+page.svelte
================
<script lang="ts">
    import { base } from '$app/paths';
    import { Input } from "$lib/components/ui/input";
    import * as Select from "$lib/components/ui/select";
    import { Button } from "$lib/components/ui/button";
    import { ChevronLeft, UploadCloud } from 'lucide-svelte';
    import { enhance } from '$app/forms';
    import type { PageData, ActionData } from './$types';

    interface Props {
        data: PageData & { initialData: { title: string, targetLang: string } };
        form: ActionData & { errors?: Record<string, string[]> };
    }

    let { data, form }: Props = $props();

    // Manual form state using Svelte 5 runes
    let title = $state("");
    let targetLang = $state("es");
    let isSubmitting = $state(false);

    // Sync local state when server data changes
    $effect(() => {
        if (data.initialData) {
            const nextTitle = data.initialData.title;
            const nextLang = data.initialData.targetLang;
            title = nextTitle;
            targetLang = nextLang;
        }
    });

    function getLanguageLabel(lang: string) {
        if (lang === 'es') return 'Spanish (ES)';
        if (lang === 'de') return 'German (DE)';
        if (lang === 'fr') return 'French (FR)';
        return 'Select Language';
    }

    let fileInput: HTMLInputElement;
</script>

<div class="max-w-3xl mx-auto p-8">
    <div class="flex items-center gap-4 mb-8">
        <Button variant="ghost" size="icon" href="{base}/studio" aria-label="Back to Studio">
            <ChevronLeft class="h-6 w-6" />
        </Button>
        <h1 class="text-3xl font-bold text-white">Upload Video</h1>
    </div>

    <div class="bg-zinc-900 border border-zinc-800 rounded-2xl p-8 shadow-2xl">
        <form
            method="POST"
            action="?/upload"
            enctype="multipart/form-data"
            use:enhance={() => {
                isSubmitting = true;
                return async ({ update }) => {
                    await update();
                    isSubmitting = false;
                };
            }}
            class="space-y-6"
        >
            <div class="space-y-2">
                <label class="text-sm font-medium text-zinc-300" for="title">Video Title</label>
                <Input
                    id="title"
                    name="title"
                    bind:value={title}
                    placeholder="e.g. My Awesome Video"
                    class="bg-black/50 border-zinc-700"
                    data-testid="title-input"
                />
                {#if form?.errors?.title}<p class="text-sm text-red-500">{form.errors.title[0]}</p>{/if}
            </div>

            <div class="space-y-2">
                <label class="text-sm font-medium text-zinc-300" for="targetLang">Target Language</label>
                <input type="hidden" name="targetLang" value={targetLang} />
                <Select.Root type="single" bind:value={targetLang}>
                    <Select.Trigger class="bg-black/50 border-zinc-700 w-full">
                        {getLanguageLabel(targetLang)}
                    </Select.Trigger>
                    <Select.Content class="bg-zinc-900 border-zinc-700 text-white">
                        <Select.Item value="es">Spanish (ES)</Select.Item>
                        <Select.Item value="de">German (DE)</Select.Item>
                        <Select.Item value="fr">French (FR)</Select.Item>
                    </Select.Content>
                </Select.Root>
                {#if form?.errors?.targetLang}<p class="text-sm text-red-500">{form.errors.targetLang[0]}</p>{/if}
            </div>

            <div class="pt-2 space-y-2">
                <label class="text-sm font-medium text-zinc-300" for="file">Video/Audio File</label>
                <div
                    class="group border-2 border-dashed border-zinc-700 rounded-xl p-10 text-center hover:border-red-500 hover:bg-red-900/5 transition-all cursor-pointer relative"
                    onclick={() => fileInput.click()}
                    onkeydown={(e) => e.key === 'Enter' && fileInput.click()}
                    role="button"
                    tabindex="0"
                >
                    <input
                        type="file"
                        id="file"
                        name="file"
                        accept="video/*,audio/*"
                        required
                        class="hidden"
                        bind:this={fileInput}
                        data-testid="file-input"
                    />
                    <div class="pointer-events-none flex flex-col items-center justify-center gap-3 group-hover:scale-105 transition-transform">
                        <div class="p-3 bg-zinc-800 rounded-full group-hover:bg-red-600/20 text-zinc-400 group-hover:text-red-500 transition-colors">
                             <UploadCloud class="w-8 h-8" />
                        </div>
                        <div>
                            <span class="text-zinc-300 font-medium block"
                                >Click to upload or drag and drop</span
                            >
                            <span class="text-xs text-zinc-500 block mt-1"
                                >MP4, MP3, WAV (Max 500MB)</span
                            >
                        </div>
                    </div>
                </div>
                {#if form?.errors?.file}<p class="text-sm text-red-500">{form.errors.file[0]}</p>{/if}
            </div>

            <div class="flex justify-end gap-4 pt-4 border-t border-white/5">
                <Button variant="ghost" href="{base}/studio">Cancel</Button>
                <Button 
                    type="submit" 
                    disabled={isSubmitting}
                    class="bg-red-600 hover:bg-red-700 text-white px-8 font-bold"
                    data-testid="submit-button"
                >
                    {isSubmitting ? "Uploading..." : "Upload Video"}
                </Button>
            </div>
        </form>
    </div>
</div>

================
File: apps/platform/src/routes/watch/[id]/+page.server.ts
================
import { db } from '$lib/server/infrastructure/database';
import { video, user, videoProcessing, type DbVttSegment } from '@notflix/database';
import { eq, and } from 'drizzle-orm';
import type { PageServerLoad } from './$types';
import { toMediaUrl } from '$lib/server/utils/media-utils';

const DEFAULT_GAME_INTERVAL = 10;

type HeatmapSegment = { start: number; end: number; type: string };

function generateHeatmap(vttJson: unknown): HeatmapSegment[] {
    const heatmap: HeatmapSegment[] = [];
    if (vttJson) {
        const segments = vttJson as DbVttSegment[];
        for (const seg of segments) {
            if (seg.classification) {
                heatmap.push({
                    start: seg.start,
                    end: seg.end,
                    type: seg.classification // EASY, LEARNING, HARD
                });
            }
        }
    }
    return heatmap;
}

async function fetchUserProfile(userId: string) {
    const [profile] = await db.select()
        .from(user)
        .where(eq(user.id, userId))
        .limit(1);
    return profile || null;
}

import type { Session } from '$lib/server/infrastructure/auth';

import type { InferSelectModel } from 'drizzle-orm';
type User = InferSelectModel<typeof user>;

async function getGameInterval(session: Session | null): Promise<{ profile: User | null, interval: number }> {
    if (!session) return { profile: null, interval: DEFAULT_GAME_INTERVAL };

    const userProfile = await fetchUserProfile(session.user.id);

    if (process.env.PLAYWRIGHT_TEST === 'true' && process.env.TEST_GAME_INTERVAL) {
        return {
            profile: userProfile,
            interval: parseFloat(process.env.TEST_GAME_INTERVAL)
        };
    }

    return {
        profile: userProfile,
        interval: userProfile?.gameIntervalMinutes ?? DEFAULT_GAME_INTERVAL
    };
}

export const load: PageServerLoad = async ({ params, locals, url }) => {
    const videoId = params.id;
    const session = await locals.auth();
    const targetLang = url.searchParams.get('lang') || 'es';

    const [result] = await db.select({
        video: video,
        processing: videoProcessing
    })
        .from(video)
        .leftJoin(videoProcessing, and(
            eq(video.id, videoProcessing.videoId),
            eq(videoProcessing.targetLang, targetLang)
        ))
        .where(eq(video.id, videoId))
        .limit(1);

    if (!result || !result.video) {
        return { video: null, heatmap: [], profile: null, user: session?.user ?? null, session };
    }

    const vid = result.video;
    vid.filePath = toMediaUrl(vid.filePath);
    vid.thumbnailPath = toMediaUrl(vid.thumbnailPath);

    const heatmap = generateHeatmap(result.processing?.vttJson);
    const { profile, interval } = await getGameInterval(session);

    return {
        video: { ...vid, targetLang: result.processing?.targetLang },
        heatmap,
        profile,
        gameInterval: interval,
        user: session?.user ?? null,
        session
    };
};

================
File: apps/platform/src/routes/watch/[id]/+page.svelte
================
<script lang="ts">
    import GameOverlay from "$lib/components/GameOverlay.svelte";
    import { onMount } from "svelte";
    import { base } from "$app/paths";
    import { Button } from "$lib/components/ui/button";
    import { ChevronLeft } from "lucide-svelte";

    let { data } = $props();

    let videoElement = $state<HTMLVideoElement>();
    let showOverlay = $state(false);
    let gameCards = $state([]);
    let chunkIndex = $state(0);
    let nextInterruptTime = $state(Infinity);

    const SECONDS_IN_MINUTE = 60;
    const PERCENT_COMPLETE = 100;
    import { GAME } from "$lib/constants";

    // ...

    const intervalSeconds = $derived(
        (data.gameInterval || GAME.DEFAULT_INTERVAL_MINUTES) *
            SECONDS_IN_MINUTE,
    );

    function initNextInterrupt() {
        if (intervalSeconds > 0) {
            nextInterruptTime = intervalSeconds * (chunkIndex + 1);
        } else {
            nextInterruptTime = Infinity;
        }
    }

    onMount(() => {
        initNextInterrupt();
        console.log(
            `[Client] Inited. Interval: ${intervalSeconds}s, Next: ${nextInterruptTime}s`,
        );
    });

    async function handleTimeUpdate() {
        if (!videoElement || showOverlay || intervalSeconds === 0) return;

        if (videoElement.currentTime >= nextInterruptTime) {
            console.log(
                `[Client] Interrupt Triggered! Time: ${videoElement.currentTime} >= ${nextInterruptTime}`,
            );
            videoElement.pause();

            const query = new URLSearchParams({
                videoId: data.video?.id || "",
                chunkIndex: chunkIndex.toString(),
                start: (nextInterruptTime - intervalSeconds).toString(),
                end: nextInterruptTime.toString(),
                targetLang: data.video?.targetLang || "es",
            });

            try {
                const res = await fetch(`${base}/api/game/generate?${query}`);
                const result = await res.json();

                if (result.cards && result.cards.length > 0) {
                    gameCards = result.cards;
                    showOverlay = true;
                } else {
                    // Skip if no cards to show
                    chunkIndex++;
                    initNextInterrupt();
                    videoElement
                        .play()
                        .catch((err) => console.error("Play failed:", err));
                }
            } catch (e) {
                console.error("Game generation failed", e);
                videoElement.play();
            }
        }
    }

    function getHeatmapColor(type: string) {
        if (type === "EASY") return "bg-green-500/50";
        if (type === "LEARNING") return "bg-yellow-500/80";
        return "bg-red-500/50";
    }

    function handleGameComplete() {
        showOverlay = false;
        chunkIndex++;
        initNextInterrupt();
        videoElement?.play().catch((err) => console.error("Play failed:", err));
    }
</script>

<div class="min-h-screen bg-black text-white pb-20">
    <!-- Header/Nav -->
    <div
        class="p-4 flex items-center gap-4 border-b border-white/10 bg-zinc-950/50 sticky top-0 z-50 backdrop-blur-md"
    >
        <Button
            variant="ghost"
            size="icon"
            href="{base}/studio"
            class="text-zinc-400 hover:text-white"
        >
            <ChevronLeft class="h-6 w-6" />
        </Button>
        {#if data.video}
            <div>
                <h1 class="font-bold text-lg leading-none">
                    {data.video.title}
                </h1>
                <p class="text-xs text-zinc-500 mt-1">
                    Watching in {data.video.targetLang?.toUpperCase() || "ES"}
                </p>
            </div>
        {/if}
    </div>

    <div class="max-w-6xl mx-auto p-4 lg:p-8">
        {#if data.video}
            <div
                class="group relative aspect-video bg-zinc-900 rounded-2xl overflow-hidden shadow-2xl ring-1 ring-white/10"
            >
                <!-- svelte-ignore a11y_media_has_caption -->
                <video
                    bind:this={videoElement}
                    data-testid="video-player"
                    src={data.video.filePath}
                    poster={data.video.thumbnailPath}
                    controls
                    class="w-full h-full"
                    ontimeupdate={handleTimeUpdate}
                >
                    <track
                        kind="subtitles"
                        srclang={data.video.targetLang || "es"}
                        label="Native ({data.video.targetLang?.toUpperCase() ||
                            'ES'})"
                        src="{base}/api/videos/{data.video
                            .id}/subtitles?mode=native"
                        default
                    />
                    <track
                        kind="subtitles"
                        srclang={data.profile?.nativeLang || "en"}
                        label="Filtered & Translated"
                        src="{base}/api/videos/{data.video
                            .id}/subtitles?mode=translated"
                    />
                    <track
                        kind="subtitles"
                        srclang="multi"
                        label="Bilingual"
                        src="{base}/api/videos/{data.video
                            .id}/subtitles?mode=bilingual"
                    />
                </video>

                {#if showOverlay}
                    <div
                        class="absolute inset-0 z-50 bg-black/80 backdrop-blur-sm flex items-center justify-center p-8"
                        data-testid="game-overlay"
                    >
                        <GameOverlay
                            cards={gameCards}
                            onComplete={handleGameComplete}
                        />
                    </div>
                {/if}
            </div>

            <!-- Heatmap Visualization -->
            {#if data.heatmap && data.heatmap.length > 0 && videoElement}
                <div
                    class="mt-4 h-4 w-full bg-zinc-800 rounded-full overflow-hidden flex relative"
                >
                    {#each data.heatmap as seg, i (i)}
                        <div
                            class="absolute h-full {getHeatmapColor(seg.type)}"
                            style="left: {(seg.start /
                                (data.video.duration || 1)) *
                                PERCENT_COMPLETE}%; width: {((seg.end -
                                seg.start) /
                                (data.video.duration || 1)) *
                                PERCENT_COMPLETE}%;"
                            title="{seg.type} ({Math.round(
                                seg.start,
                            )}s - {Math.round(seg.end)}s)"
                        ></div>
                    {/each}
                </div>
                <div class="flex justify-between text-xs text-zinc-500 mt-1">
                    <div class="flex items-center gap-2">
                        <div class="w-2 h-2 bg-green-500/50 rounded-full"></div>
                        Easy (Known)
                    </div>
                    <div class="flex items-center gap-2">
                        <div
                            class="w-2 h-2 bg-yellow-500/80 rounded-full"
                        ></div>
                        Learning (Target)
                    </div>
                    <div class="flex items-center gap-2">
                        <div class="w-2 h-2 bg-red-500/50 rounded-full"></div>
                        Hard (Too many unknowns)
                    </div>
                </div>
            {/if}

            <div
                class="mt-8 flex flex-col md:flex-row gap-8 justify-between items-start"
            >
                <div class="flex-1">
                    <h2 class="text-3xl font-bold tracking-tight mb-2">
                        {data.video.title}
                    </h2>
                    <div class="flex items-center gap-4 text-zinc-500 text-sm">
                        <span
                            >{new Date(
                                data.video.createdAt,
                            ).toLocaleDateString()}</span
                        >
                        <span>â¢</span>
                        <span>{data.video.views} views</span>
                    </div>
                </div>

                <div
                    class="bg-zinc-900/50 border border-white/5 p-4 rounded-xl flex items-center gap-4"
                >
                    <div class="h-10 w-1 bg-red-600 rounded-full"></div>
                    <div>
                        <p
                            class="text-xs font-bold text-zinc-500 uppercase tracking-widest"
                        >
                            Learning Goal
                        </p>
                        <p class="text-sm text-zinc-300">
                            Intermission every <span
                                class="text-white font-bold"
                                >{data.gameInterval ||
                                    GAME.DEFAULT_INTERVAL_MINUTES}m</span
                            >
                        </p>
                    </div>
                    <Button
                        variant="outline"
                        size="sm"
                        href="{base}/profile"
                        class="ml-4 border-white/10 hover:bg-white/5"
                    >
                        Change
                    </Button>
                </div>
            </div>
        {:else}
            <div class="flex flex-col items-center justify-center py-40">
                <div class="bg-zinc-900 p-8 rounded-full mb-6">
                    <ChevronLeft class="h-12 w-12 text-zinc-700" />
                </div>
                <h2 class="text-2xl font-bold text-white mb-2">
                    Video not found
                </h2>
                <p class="text-zinc-500 mb-8">
                    This video might have been removed or is still processing.
                </p>
                <Button
                    href="{base}/studio"
                    class="bg-white text-black hover:bg-zinc-200 px-8 font-bold rounded-full"
                >
                    Return to Studio
                </Button>
            </div>
        {/if}
    </div>
</div>

<style>
    /* Styling for the native video track */
    video::cue {
        background: rgba(0, 0, 0, 0.7);
        color: white;
        font-family: sans-serif;
        font-size: 1.2rem;
        padding: 0.2rem 0.5rem;
    }
</style>

================
File: apps/platform/static/robots.txt
================
# allow crawling everything by default
User-agent: *
Disallow:

================
File: apps/platform/svelte.config.js
================
import adapter from '@sveltejs/adapter-auto';
import { vitePreprocess } from '@sveltejs/vite-plugin-svelte';

/** @type {import('@sveltejs/kit').Config} */
const config = {
	// Consult https://svelte.dev/docs/kit/integrations
	// for more information about preprocessors
	preprocess: vitePreprocess(),

	kit: {
		// adapter-auto only supports some environments, see https://svelte.dev/docs/kit/adapter-auto for a list.
		// If your environment is not supported, or you settled on a specific environment, switch out the adapter.
		// See https://svelte.dev/docs/kit/adapters for more information about adapters.
		adapter: adapter()
	}
};

export default config;

================
File: apps/platform/tailwind.config.js
================
import animate from "tailwindcss-animate";

/** @type {import('tailwindcss').Config} */
export default {
  content: ['./src/**/*.{html,js,svelte,ts}'],
  theme: {
    extend: {},
  },
  plugins: [animate],
}

================
File: apps/platform/tests/e2e/full-flow.spec.ts
================
import { test, expect } from '@playwright/test';
import path from 'path';
import { StudioPage } from '../pages/StudioPage';
import { UploadPage } from '../pages/UploadPage';
import { PlayerPage } from '../pages/PlayerPage';

test.describe('Full User Flow', () => {
    test('Upload, Process, and Play Video', async ({ page }) => {
        const studioPage = new StudioPage(page);
        const uploadPage = new UploadPage(page);
        const playerPage = new PlayerPage(page);

        // Debug: Log all console messages from the browser
        page.on('console', msg => console.log(`[Browser] ${msg.type()}: ${msg.text()}`));

        // Mock API early
        await page.route('**/api/game/generate*', async route => {
            console.log('[Mock] Intercepted /api/game/generate');
            const json = {
                nextChunkStart: 600,
                cards: [
                    {
                        lemma: 'gato',
                        lang: 'es',
                        original: 'gato',
                        contextSentence: 'El gato estÃ¡ en la mesa.',
                        cefr: 'A1',
                        translation: 'cat',
                        isKnown: false
                    }
                ]
            };
            await route.fulfill({ json });
        });

        // 1. Navigate to Studio
        await studioPage.goto();

        // 2. Go to Upload
        await studioPage.clickUpload();

        // 3. Upload Video
        const uniqueTitle = `Full Flow Test ${Date.now()}`;
        const audioPath = path.resolve(process.cwd(), '../../media', 'test_audio.mp3');

        await uploadPage.uploadVideo(uniqueTitle, audioPath);



        // 4. Wait for Processing
        console.log(`Waiting for video "${uniqueTitle}" to complete processing...`);
        const PROCESSING_TIMEOUT_MS = 60000;
        await studioPage.waitForVideoStatus(uniqueTitle, 'COMPLETED', PROCESSING_TIMEOUT_MS);

        // 5. Navigate to Watch Page
        const videoCard = page.locator(`[data-testid="video-item"]`, { hasText: uniqueTitle });
        const watchLink = videoCard.locator('a[href^="/watch/"]').first();
        await expect(watchLink).toBeVisible();

        await Promise.all([
            page.waitForURL(/\/watch\/.+/),
            watchLink.click()
        ]);

        // 6. Verify Player
        console.log('Current URL after click:', page.url());
        const content = await page.content();
        expect(content, 'Video player should be visible, not "Video not found" error').not.toContain('Video not found');
        await playerPage.waitForPlayback();

        // 7. Verify Game Overlay Interaction (enabled by TEST_GAME_INTERVAL=0.1)
        console.log('Waiting for Game Overlay to appear (approx 6s)...');
        // We wait slightly longer than 6s to be safe
        await playerPage.playRound(1);

        // Verify overlay is gone and playback resumed (optional, but good)
        await expect(playerPage.gameOverlay).not.toBeVisible();
    });
});

================
File: apps/platform/tests/integration/transcription.spec.ts
================
import { test, expect } from '@playwright/test';
/* eslint-disable test-smells/conditional-test-logic, test-smells/assertion-roulette */
import fs from 'fs';
import path from 'path';
import { HTTP_STATUS } from '../../src/lib/constants';

// "Transcription Service" test
// Constraint: Use `tiny` whisper model (assumed running on backend)
// Constraint: Do not overmock (Use real API, real file)
// Constraint: Mock other services (Tests isolation of this endpoint)

const BRAIN_URL = process.env.BRAIN_URL || 'http://127.0.0.1:8000';

interface TranscriptionResponse {
    segments: { text: string }[];
    language: string;
}

test.describe('Transcription Service', () => {
    test.beforeAll(() => {
        const audioFilePath = path.join(process.cwd(), '../../media', 'test_audio.mp3');
        if (!fs.existsSync(audioFilePath)) {
            // Throwing in beforeAll fails the suite cleanly without conditional logic inside the test
            throw new Error(`Test audio file not found at: ${audioFilePath}`);
        }
    });

    test('POST /transcribe should return segments using tiny model', async ({ request }) => {
        // 1. Prepare Test File (Real Audio)
        const audioFilePath = path.join(process.cwd(), '../../media', 'test_audio.mp3');

        // 2. Call API (Real Network)
        const response = await request.post(`${BRAIN_URL}/transcribe`, {
            headers: {
                'X-API-Key': process.env.AI_SERVICE_API_KEY || 'dev_secret_key'
            },
            data: {
                file_path: audioFilePath,
                language: 'es'
            }
        });

        // 3. Assertions
        expect(response.status(), `API returned ${response.status()} - ${await response.text()}`).toBe(HTTP_STATUS.OK);

        const body = await response.json() as TranscriptionResponse;

        // Verify structure
        expect(body).toHaveProperty('segments');
        expect(body).toHaveProperty('language');

        const text = body.segments.map((s) => s.text).join(' ');
        console.log('Transcribed Text:', text);

        expect(text.toLowerCase()).toContain('prueba');
        expect(body.language).toBe('es');
    });
});

================
File: apps/platform/tests/pages/PlayerPage.ts
================
import { type Page, type Locator, expect } from '@playwright/test';

export class PlayerPage {
    readonly page: Page;
    readonly videoPlayer: Locator;
    readonly gameOverlay: Locator;
    readonly swipeRightButton: Locator;
    readonly swipeLeftButton: Locator;
    readonly cardWord: Locator;

    constructor(page: Page) {
        this.page = page;
        this.videoPlayer = page.getByTestId('video-player');
        this.gameOverlay = page.getByTestId('game-overlay');
        this.swipeRightButton = page.getByTestId('swipe-right');
        this.swipeLeftButton = page.getByTestId('swipe-left');
        this.cardWord = page.getByTestId('card-original');
    }

    async waitForPlayback() {
        await expect(this.videoPlayer).toBeVisible();
        // Force play via JS to ensure it starts
        await this.page.evaluate(() => {
            const v = document.querySelector('video') as HTMLVideoElement;
            if (v) v.play().catch(e => console.error(e));
        });
    }

    async waitForGameOverlay() {
        await expect(this.gameOverlay).toBeVisible({ timeout: 15000 }); // Wait for interrupt
    }

    async playRound(swipes: number = 1) {
        await this.waitForGameOverlay();
        for (let i = 0; i < swipes; i++) {
            await expect(this.cardWord).toBeVisible();
            // Swipe Right (Know it)
            await this.swipeRightButton.click();
            // Small delay to allow animation/transition if needed
            const ANIMATION_DELAY_MS = 500;
            await this.page.waitForTimeout(ANIMATION_DELAY_MS);
        }
        // Expect overlay to disappear if finished?
        // await expect(this.gameOverlay).not.toBeVisible();
    }
}

================
File: apps/platform/tests/pages/StudioPage.ts
================
import { expect } from '@playwright/test';
import type { Page, Locator } from '@playwright/test';

const DEFAULT_WAIT_TIMEOUT = 60000;

export class StudioPage {
    readonly page: Page;
    readonly uploadButton: Locator;

    constructor(page: Page) {
        this.page = page;
        this.uploadButton = page.getByTestId('upload-link');
    }

    async goto() {
        await this.page.goto('/studio');
    }

    async clickUpload() {
        await this.uploadButton.click();
    }

    async waitForVideoStatus(title: string, status: string, timeout = DEFAULT_WAIT_TIMEOUT) {
        const row = this.page.locator(`[data-testid="video-item"]`, { hasText: title });
        await expect(row.locator(`text=${status}`)).toBeVisible({ timeout });
    }
}

================
File: apps/platform/tests/pages/UploadPage.ts
================
import { type Page, type Locator } from '@playwright/test';

export class UploadPage {
    readonly page: Page;
    readonly titleInput: Locator;
    readonly fileInput: Locator;
    readonly submitButton: Locator;

    constructor(page: Page) {
        this.page = page;
        this.titleInput = page.getByTestId('title-input');
        this.fileInput = page.getByTestId('file-input');
        this.submitButton = page.getByTestId('submit-button');
    }

    async uploadVideo(title: string, filePath: string) {
        await this.titleInput.fill(title);
        await this.fileInput.setInputFiles(filePath);
        await this.submitButton.click();
    }
}

================
File: apps/platform/tsconfig.json
================
{
	"extends": "./.svelte-kit/tsconfig.json",
	"compilerOptions": {
		"rewriteRelativeImportExtensions": true,
		"allowJs": true,
		"checkJs": true,
		"esModuleInterop": true,
		"forceConsistentCasingInFileNames": true,
		"resolveJsonModule": true,
		"skipLibCheck": true,
		"sourceMap": true,
		"strict": true,
		"moduleResolution": "bundler",
		"types": [
			"vitest/globals"
		]
	}
}

================
File: apps/platform/vite.config.ts
================
import { sveltekit } from '@sveltejs/kit/vite';
import { defineConfig } from 'vitest/config';

export default defineConfig({
	plugins: [sveltekit()],
	test: {
		exclude: ['tests/**', 'node_modules/**']
	}
});

================
File: docs/architecture/ADR-001-master.md
================
# Master ADR: The "Local Sovereign" Platform (KISS Edition)

**Status:** Final (Revised 2025-12-20)
**Date:** 2025-12-20
**Context:** Simplified local-first language learning platform focusing on core Smart Filter logic.

## 1. Executive Summary

We have pivoted from an "Enterprise-grade" distributed architecture to a **KISS (Keep It Simple, Stupid)** architecture. The system is designed to run on a single machine with minimal overhead.

  * **Platform (Node.js):** SvelteKit "Host" handles UI, Auth, and Pipeline Orchestration.
  * **AI Service (Python):** FastAPI "Microservice" handles AI tasks via standard blocking JSON requests.
  * **Data:** Managed via **Postgres** and **Drizzle**.
  * **Storage:** Standard Local Filesystem with shared Docker volumes.

## 2. The Tech Stack

| Domain | Technology | Role |
| :--- | :--- | :--- |
| **Platform** | **SvelteKit** | UI and synchronous pipeline triggers. |
| **Authentication** | **Better Auth** | Integrated library for user management. |
| **Database** | **Postgres** | Persistent storage for users and results. |
| **AI Runtime** | **Python (FastAPI)** | Runs Whisper, SpaCy, and MarianMT. |
| **Styling** | **Tailwind CSS 4** | Utility-first styling with shadcn-svelte. |
| **Forms** | **Pure Zod** | Manual state management with Svelte 5 runes. |

## 3. Key Simplifications

### 3.1 Task Management (No Queue)
We removed **BullMQ** and **Redis**. Background tasks are now handled as standard asynchronous Promises within the Node.js process, tracked by a centralized `TaskRegistry`.

### 3.2 Storage (Local FS)
We removed **MinIO**. Video and thumbnail assets are stored in a shared `media/` directory accessible by both the Platform and AI Service containers via Docker volumes.

### 3.3 Real-time Updates (Polling)
We removed **SSE (Server-Sent Events)**. The frontend utilizes granular 3-second polling (via `invalidate`) to track processing status.

### 3.4 AI Communication (JSON)
We removed **NDJSON/Streaming AI responses**. All communication between the Platform and AI Service happens via standard, blocking JSON POST requests.

## 4. Directory Structure

```text
/
âââ apps/
â   âââ platform/             # SvelteKit (Host Platform)
â   âââ ai-service/           # Python (AI Microservice)
âââ packages/
â   âââ database/             # Shared Database Logic
âââ infra/
â   âââ docker-compose.yml    # Orchestration
âââ media/                    # Shared File Storage
```

================
File: docs/architecture/ADR-005-di-testing.md
================
# ADR 005: Dependency Injection & Confidence Testing

**Status:** Approved
**Date:** 2025-12-09
**Context:** Ensuring the system is testable, fast, and robust without loading 4GB AI models for every unit test.

## 1. The Strategy: "Ports and Adapters" (Hexagonal Architecture)

We define **Interfaces** (Ports) for all heavy infrastructure. The Application Logic only talks to these Interfaces, never to the concrete libraries directly.

  * **Production:** We inject the **Real Adapter** (e.g., `FasterWhisperAdapter`).
  * **Testing:** We inject a **Mock Adapter** (e.g., `GoldFileAdapter`).

## 2. The Host (SvelteKit) Design

We use a lightweight DI pattern (Factory Functions or Classes) to manage dependencies in `src/lib/server`.

### 2.1 The Interfaces

Define what "Doing AI" means, regardless of who does it.

```typescript
// src/lib/server/domain/interfaces.ts
import type { ProcessVideoResponse } from "$lib/gen/ai/v1/service_pb";

export interface IAiGateway {
  processVideo(filePath: string): Promise<ProcessVideoResponse>;
}

export interface IStorageGateway {
  uploadFile(file: File): Promise<string>; // Returns path
}
```

### 2.2 The Implementation (Real vs. Mock)

**The Real Gateway (ConnectRPC):**

```typescript
// src/lib/server/adapters/grpc-ai-gateway.ts
import { createPromiseClient } from "@connectrpc/connect";
import { AiService } from "$lib/gen/ai/v1/service_connect";
import type { IAiGateway } from "../domain/interfaces";

export class GrpcAiGateway implements IAiGateway {
  constructor(private client = createPromiseClient(AiService, transport)) {}

  async processVideo(path: string) {
    // This actually calls Python over the network
    return this.client.processVideo({ filePath: path });
  }
}
```

**The Mock Gateway (Gold File):**

```typescript
// src/lib/server/adapters/mock-ai-gateway.ts
import type { IAiGateway } from "../domain/interfaces";
import goldResponse from "../../../tests/fixtures/gold_transcript.json";

export class MockAiGateway implements IAiGateway {
  async processVideo(path: string) {
    // Instant return. Perfect for testing UI flows.
    return goldResponse;
  }
}
```

### 2.3 The Composition Root (Wiring it up)

We centralize instance creation in `src/lib/server/container.ts`.

```typescript
// src/lib/server/container.ts
import { RealAiGateway } from './adapters/real-ai-gateway';
import { MockAiGateway } from './adapters/mock-ai-gateway';
import { Orchestrator } from './orchestrator';
import { SmartFilter } from './filter';
import { SubtitleService } from './services/subtitle.service';
import { db } from './db';

const useMock = process.env.NODE_ENV === 'test' || process.env.USE_MOCK_AI === 'true';

// Ports/Adapters
export const aiGateway = useMock ? new MockAiGateway() : new RealAiGateway();

// Domain Services (Injected)
export const smartFilter = new SmartFilter(db);
export const subtitleService = new SubtitleService(db);

// Orchestrator (Injected)
export const orchestrator = new Orchestrator(aiGateway, db, smartFilter);
```

-----

## 3. The Brain (Python) Design

Python uses FastAPI's built-in dependency injection for model management.

### 3.1 Wiring (FastAPI Depends)

We use lambda-based dependencies to inject model instances initialized in the app lifespan.

```python
# services/brain/main.py

@app.post("/transcribe")
async def transcribe(
    req: TranscriptionRequest,
    transcriber = Depends(lambda: brain_state.transcriber)
):
    return transcriber.transcribe(req.file_path, req.language)
```

================
File: docs/architecture/ADR-006-frontend-stack.md
================
# ADR-006: Frontend Stack (UI, Styling, Forms, and Icons)

**Status:** Accepted
**Date:** 2025-12-19
**Context:** Need for a consistent, type-safe, and highly productive frontend development environment for the Notflix web application.

## 1. Decision

We have adopted the following technologies for the frontend stack:

*   **UI Components:** [shadcn-svelte](https://shadcn-svelte.com/)
*   **Styling:** [Tailwind CSS](https://tailwindcss.com/)
*   **Form Management:** Manual state management using [Svelte 5 Runes](https://svelte.dev/docs/svelte/runes) (`$state`, `$derived`, `$effect`).
*   **Validation:** [Zod](https://zod.dev/)
*   **Icons:** [Lucide Svelte](https://lucide.dev/guide/packages/lucide-svelte)

## 2. Rationale

### 2.1 shadcn-svelte & Tailwind CSS
*   **Ownership:** Unlike traditional component libraries (e.g., Carbon, Material UI), shadcn-svelte provides components as source code in our `lib/components/ui` directory. This allows for direct modification and avoids vendor lock-in.
*   **Svelte 5 Support:** We use the latest version compatible with Svelte 5 (Runes), ensuring future-proof architecture.
*   **Consistency:** Tailwind CSS is the industry standard for utility-first styling and is the foundation upon which shadcn is built.

### 2.2 Pure Zod & Svelte 5 Runes
*   **Simplicity:** We removed third-party form frameworks (e.g., Superforms) to reduce library-level conflicts (specifically Zod version mismatches) and "fighting the framework."
*   **Control:** Using `$state` for form data and `$effect` for prop synchronization provides fine-grained control over form behavior without magic abstractions.
*   **Type Safety:** End-to-end type safety is achieved by defining Zod schemas in `+page.server.ts` and using `z.infer<T>` to type the local state in `+page.svelte`.
*   **Validation:** Standard SvelteKit `fail(400, { errors })` responses are used to pass validation errors back to the UI.

### 2.3 Lucide Svelte
# ... (Lucide section remains same)

## 3. Implementation Standards

1.  **Component Installation:** Add new shadcn components using `npx shadcn-svelte@latest add <component>`.
2.  **Form Patterns:** 
    *   Define a Zod schema in `+page.server.ts`.
    *   Use `Object.fromEntries(await request.formData())` and `schema.safeParse` in server actions.
    *   Use `$state` in `+page.svelte` initialized from `data.initialData`.
    *   Use `$effect` to keep state in sync with server-provided updates if necessary.
3.  **Styling:** Custom styles should be implemented via Tailwind classes in the HTML template. Avoid `<style>` blocks in Svelte components unless strictly necessary.
4.  **Icons:** Always import icons from `lucide-svelte`.

## 4. Consequences

*   **Positive:** Zero dependency friction between Zod versions. Highly predictable state management using native Svelte 5 features. Reduced bundle size by removing form frameworks.
*   **Negative:** More manual boilerplate for handling error messages and submission states compared to a full-featured framework.

================
File: docs/architecture/ADR-007-idiomatic-backend-patterns.md
================
# ADR-007: Idiomatic Backend Patterns (Tasks, Errors, and DI)

**Status:** Accepted
**Date:** 2025-12-20
**Context:** Need for consistent, observable, and maintainable patterns for background processing, error handling, and dependency management across both SvelteKit (Host) and FastAPI (Brain).

## 1. Decision

We have adopted the following backend patterns:

*   **Background Tasks (Host):** Centralized `TaskRegistry` for fire-and-forget operations.
*   **Error Handling (Brain):** Global FastAPI exception handlers to simplify route logic.
*   **Dependency Injection:** Constructor-based injection with a centralized container (Host) and `Depends` (Brain).
*   **Data Consistency:** Singleton library instances enforced via root `overrides`.
*   **Path Resolution:** Absolute path resolution centralized in `config.ts`, avoiding brittle relative path math (`../../`).
*   **Request Validation (Brain):** Use Pydantic `@field_validator` for logic-based validation (like file existence) before route handlers execute.

## 2. Rationale

### 2.1 TaskRegistry (SvelteKit)
# ... (same)

### 2.5 Absolute Pathing
*   **Reliability:** Using `path.resolve` once at startup based on the environment or project root ensures the application behaves consistently regardless of the current working directory or Docker container WORKDIR.

### 2.6 Pydantic Validators
*   **Fast-Fail:** By moving path existence checks into the model layer, we catch errors earlier and return standard 422 responses automatically, keeping AI logic focused on processing.

## 3. Implementation Standards

1.  **Background Work:** Never call `async` functions without `await` directly in a route. Always wrap them in `taskRegistry.register('name', promise)`.
2.  **FastAPI Routes:** Write the "happy path." Let the `global_exception_handler` and Pydantic validators deal with validation and unexpected crashes.
3.  **Pathing:** Always use `CONFIG.RESOLVED_UPLOAD_DIR` instead of calculating relative paths in local files.
4.  **DI:**
    *   **Host:** Export singleton instances from `lib/server/container.ts`.
    *   **Brain:** Use `Depends` to inject model instances into route handlers.
5.  **Schema Types:** Use Drizzle's `InferSelectModel` and `InferInsertModel` to generate TypeScript interfaces directly from the database schema.

## 4. Consequences

*   **Positive:** significantly reduced "dirty" code and type casts. Improved logs for background processing. Easier to write fast-running unit tests.
*   **Negative:** Requires discipline to follow the DI pattern instead of direct imports. Root `package.json` management becomes more critical.

================
File: docs/CODE_REVIEW_REPORT.md
================
# Code Review Report

**Date:** 2026-01-02
**Project:** Notflix
**Reviewer:** Antigravity (Agent)

## 1. Executive Summary

The project is well-architected, following a "Local Sovereign" (KISS) philosophy. The separation of concerns between the SvelteKit Platform (Orchestration/UI) and the Python AI Service (Compute) is clean and effective. The codebases generally adhere to the drafted Architecture Decision Records (ADRs).

**Key Strengths:**
*   **Architecture:** Strong separation of concerns. The "Ports and Adapters" pattern in SvelteKit facilitates testing.
*   **Dependencies:** Modern and consistent stack (Svelte 5, Tailwind 4, Drizzle, FastAPI, Pydantic).
*   **Type Safety:** Excellent use of TypeScript and Pydantic for end-to-end type safety.

**Critical Issues:**
*   **AI Service Bug:** Incorrect usage of the `translator` and `filter` in `main.py` causing potential crashes and significant performance degradation.

## 2. Critical Findings (High Priority)

### 2.1. AI Service: Translation and Filter Logic Errors (`apps/ai-service/main.py`)

**Issue:** In `main.py`, the `/translate` and `/filter` endpoints iterate over the input list and call the core services item-by-item. However, the core services (`OpusTranslator`, `SpacyFilter`) and `main.py` logic have mismatched expectations, leading to inefficient processing and incorrect return types.

**Location:** `apps/ai-service/main.py`

**Details:**
1.  **Translation:**
    ```python
    # main.py
    translations = [
        translator.translate(text, req.source_lang, req.target_lang)
        for text in req.texts
    ]
    ```
    `translator.translate` returns a `List[str]`. The list comprehension results in `List[List[str]]`. The Pydantic model `TranslationResponse` expects `translations: List[str]`. This will likely cause a validation error or unexpected nested JSON structure.
    *Correction:* Pass the entire list to `translate` once.
    ```python
    translations = translator.translate(req.texts, req.source_lang, req.target_lang)
    ```

2.  **Filtering:**
    ```python
    # main.py
    results = [
        text_filter.analyze(text, req.language)
        for text in req.texts
    ]
    ```
    While functionally correct (returns `List[List[TokenAnalysis]]`), it bypasses the optimized `analyze_batch` method available in `SpacyFilter` (which uses `nlp.pipe`). This is a significant performance miss.
    *Correction:* Use `analyze_batch`.
    ```python
    results = text_filter.analyze_batch(req.texts, req.language)
    ```

## 3. Platform Review (`apps/platform`)

### 3.1. Architecture & DI
The Dependency Injection container (`lib/server/infrastructure/container.ts`) is well implemented. It correctly toggles between Real and Mock adapters based on environment variables, enabling reliable E2E tests without spinning up heavy AI models.

### 3.2. Task Registry
The `TaskRegistry` (`lib/server/services/task-registry.service.ts`) provides a safeguard for fire-and-forget background tasks. This is a good implementation for a node-based environment where unhandled promise rejections can crash the process.

### 3.3. Orchestrator Service
The properties of `enrichWithTranslations` in `video-orchestrator.service.ts` correctly implement the business logic:
*   **Guest Mode:** Simple translation.
*   **User Mode:** Smart filtering of known words before translation to save compute.
*   **Logic Check:** The logic correctly separates identification of unknown lemmas from the translation step, ensuring we don't translate known words.

### 3.4. Configuration
`resolvedUploadDir` in `config.ts` uses `path.resolve` to handle relative paths robustly, addressing the "Docker vs Local" pathing issues common in such setups.

## 4. AI Service Review (`apps/ai-service`)

### 4.1. Core Modules
*   **Transcriber:** Uses `faster-whisper`. *Observation:* Currently prints to `stdout` (`print(...)`). It should use the configured `structlog` logger for consistency.
*   **Filter:** `SpacyFilter` implements lazy loading of models, which improves startup time if models aren't immediately needed.
*   **Translator:** `OpusTranslator` implements batching (batch size 32), which is excellent.

### 4.2. Security
Authentication is handled via a simple API Key check. Given the services run in a private Docker network, this is sufficient.

## 5. Database Review (`packages/database`)

### 5.1. Schema
The Drizzle schema is clean. Using `jsonb` for `vttJson` is appropriate for storing variable-length subtitle data that doesn't need complex relational querying. `onConflictDoUpdate` logic in the Orchestrator for `videoProcessing` ensures idempotency.

### 5.2. Seeding
The seed script skips Account creation due to hashing dependencies. This is acceptable for a dev seed script but means the "Test User" cannot log in via password immediately.

## 6. Recommendations

1.  **Fix AI Service API:** Immediately refactor `apps/ai-service/main.py` to use batch processing for `/translate` and `/filter`.
2.  **Logging Standard:** Replace `print` statements in `apps/ai-service/core` with `structlog`.
3.  **Optimization:** In `Orchestrator`, consider verifying if `processedVideo` needs to handle potential partial failures (currently it marks the whole video as ERROR).
4.  **Testing:** Add a unit test in `apps/ai-service/tests` that specifically sends a batch of 2+ texts to verify the list handling logic.

================
File: docs/specs/functional-specs.md
================
# System Specifications: "Notflix" Language Platform

**Version:** 1.1 (Revised 2025-12-19)
**Architecture:** KISS (Keep It Simple, Stupid) - SvelteKit + FastAPI + Postgres.

## 1. Core Concept

A "Netflix-style" video player that acts as a language engine. Instead of translating everything, it calculates the user's "knowledge gap" for a specific episode and translates **only** the words they do not know, turning entertainment into a targeted spaced-repetition loop.

## 2. Data Models (Schema)

Defined in `packages/db/schema.ts` using Drizzle.

### 2.1 User & Profile
Tracks native/target languages and learning preferences (e.g., game frequency).

### 2.2 Vocabulary Knowledge Base
Tracks knowledge at the **Lemma** level (e.g., knowing "run" means you know "running"). This is the source of truth for the "Gap Analysis".

### 2.3 Video & Processing
Tracks media metadata and the resulting structured linguistic data (`vttJson`).

-----

## 3. The "Smart Filter" Logic (Pipeline)

Executed by the **Orchestrator (SvelteKit)**, coordinating AI services via REST/JSON.

### Phase 1: Transcription (Whisper)
*   **Input:** Video File Path (Shared Volume).
*   **Action:** Call Brain `/transcribe`.
*   **Result:** Timestamped segments with raw text.

### Phase 2: Analysis (SpaCy)
*   **Action:** Call Brain `/filter` (Batch).
*   **Linguistic Data:** Each segment is tokenized with Lemmas, POS tags, and Stop-word status.

### Phase 3: Filtering (Gap Analysis)
*   **Context:** User-aware filtering.
*   **Rule:** Compare segment lemmas against the **Known Words** database.
*   **Classification:** 
    *   **EASY:** 100% words known.
    *   **LEARNING:** High ratio of known words, but contains target "unknowns".
    *   **HARD:** Too many unknown words for effective learning.

### Phase 4: Just-in-Time Translation (MarianMT)
*   **Action:** Call Brain `/translate` for unknown lemmas found in "Learning" segments.
*   **Storage:** Save full JSON structure (Segments + Tokens + Translations) to Postgres.

-----

## 4. Communication & Status

### 4.1 Internal API
Communication between SvelteKit and Python happens over a private Docker network using **Standard JSON POST** requests. No streaming or NDJSON is used.

### 4.2 Status Tracking (Polling)
*   The UI does not use SSE or WebSockets.
*   **Idiomatic Refresh:** The UI uses SvelteKit's granular `invalidate('app:videos')` every 3 seconds while any visible video has a `PENDING` status. This re-runs the specific database query for the video list without refreshing the entire page or layout state.

## 5. Media Management
*   **Storage:** Shared filesystem volume (`media/uploads`).
*   **Thumbnail Generation:** Triggered during the pipeline via Brain `/generate_thumbnail` (FFmpeg wrapper).

-----

## 6. The "Game & Watch" Loop

Directly integrates Spaced Repetition into the video player.

1.  **Interval:** User sets a frequency (e.g., every 10 minutes).
2.  **Trigger:** Video reaches the interval.
3.  **Action:** Video pauses; Flashcard Overlay appears using unknown words from the *upcoming* 10-minute segment.
4.  **Resume:** Video resumes once the user completes the "Knowledge Check".

================
File: infra/docker-compose.test.yml
================
# Docker Compose override for E2E testing
# Usage: docker compose -f docker-compose.yml -f docker-compose.test.yml up -d --wait

services:
  platform:
    environment:
      - PLAYWRIGHT_TEST=true
      - TEST_GAME_INTERVAL=0.1
      - RUNNING_IN_DOCKER=true
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:5173/api/health || exit 1" ]
      interval: 5s
      timeout: 10s
      retries: 12
      start_period: 30s

  ai-service:
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8000/health || exit 1" ]
      interval: 5s
      timeout: 10s
      retries: 12
      start_period: 30s

  postgres:
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U admin -d main_db" ]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s

================
File: infra/docker-compose.yml
================
services:
  # Data Persistence
  postgres:
    image: postgres:16-alpine
    container_name: notflix-db
    ports: [ "5432:5432" ]
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      POSTGRES_DB: ${POSTGRES_DB:-main_db}
    volumes: [ "pg_data:/var/lib/postgresql/data" ]

  # The Host Platform (SvelteKit)
  platform:
    image: notflix-platform
    build:
      context: ..
      dockerfile: apps/platform/Dockerfile
    ports: [ "5173:5173" ]
    volumes:
      - ../apps/platform:/app/apps/platform
      - ../packages/database:/app/packages/database
      - /app/apps/platform/node_modules
      - /app/packages/database/node_modules
      - ../media:/app/media
      - ../logs:/app/logs
    command: /bin/sh -c "chmod -R +x /app/apps/platform/node_modules && npm run dev -- --host"
    environment:
      - DATABASE_URL=postgres://admin:password@postgres:5432/main_db
      - AI_SERVICE_URL=http://ai-service:8000
      - AI_SERVICE_API_KEY=dev_secret_key
      - UPLOAD_DIR=/app/media/uploads
      - BETTER_AUTH_SECRET=long_secret_key_for_dev_only_1234567890
      - PLAYWRIGHT_TEST=true
      - TEST_GAME_INTERVAL=0.1
      - RUNNING_IN_DOCKER=true
    depends_on:
      - postgres
      - ai-service

  # The AI Microservice (FastAPI)
  ai-service:
    image: notflix-ai-service
    build:
      context: ..
      dockerfile: apps/ai-service/Dockerfile
    volumes:
      - ../apps/ai-service:/app
      - ../media:/app/media
      - ../logs:/app/logs
    environment:
      - PYTHONUNBUFFERED=1
      - LOGS_DIR=/app/logs
      - AI_SERVICE_API_KEY=dev_secret_key
    ports: [ "8000:8000" ]
    depends_on:
      - postgres

volumes:
  pg_data:

================
File: package.json
================
{
  "name": "notflix-monorepo",
  "private": true,
  "workspaces": [
    "apps/*",
    "packages/*"
  ],
  "overrides": {
    "zod": "^4.3.4",
    "drizzle-orm": "0.45.1",
    "prisma": "5.22.0",
    "@prisma/client": "5.22.0",
    "cookie": "0.7.0",
    "esbuild": "0.25.0"
  },
  "devDependencies": {
    "drizzle-orm": "0.45.1"
  }
}

================
File: packages/database/drizzle.config.ts
================
import { defineConfig } from 'drizzle-kit';

export default defineConfig({
    schema: './schema.ts',
    out: './migrations',
    dialect: 'postgresql',
    dbCredentials: {
        url: process.env.DATABASE_URL || 'postgres://admin:password@127.0.0.1:5432/main_db',
    },
});

================
File: packages/database/eslint.config.js
================
import eslint from '@eslint/js';
import tseslint from 'typescript-eslint';
import globals from 'globals';

export default tseslint.config(
	eslint.configs.recommended,
	...tseslint.configs.recommended,
	{
		languageOptions: {
			globals: {
				...globals.node,
			}
		}
	},
	{
		rules: {
			'@typescript-eslint/no-explicit-any': 'error',
			'complexity': ['error', 10],
		}
	},
	{
		ignores: ['dist/']
	}
);

================
File: packages/database/package.json
================
{
  "name": "@notflix/database",
  "version": "1.0.0",
  "description": "",
  "main": "schema.ts",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "lint": "eslint .",
    "seed": "tsx seed.ts",
    "db:push": "drizzle-kit push",
    "db:studio": "drizzle-kit studio"
  },
  "devDependencies": {
    "@types/node": "^25.0.3",
    "drizzle-kit": "^0.31.8",
    "eslint": "^9.39.2",
    "globals": "^17.0.0",
    "tsx": "^4.21.0",
    "typescript-eslint": "^8.51.0"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "type": "module",
  "exports": {
    ".": "./schema.ts"
  },
  "peerDependencies": {
    "drizzle-orm": "^0.45.0"
  },
  "dependencies": {
    "postgres": "^3.4.7"
  }
}

================
File: packages/database/schema.ts
================
import { pgTable, text, timestamp, boolean, uuid, integer, pgEnum, primaryKey, jsonb } from "drizzle-orm/pg-core";
import { type InferSelectModel, type InferInsertModel } from 'drizzle-orm';

// --- AUTHENTICATION (Better Auth Standard) ---
export const user = pgTable("user", {
    id: text("id").primaryKey(),
    name: text("name").notNull(),
    email: text("email").notNull().unique(),
    emailVerified: boolean("email_verified").notNull(),
    image: text("image"),
    nativeLang: text("native_lang").default("en"),
    targetLang: text("target_lang").default("es"),
    createdAt: timestamp("created_at").notNull(),
    updatedAt: timestamp("updated_at").notNull(),
    gameIntervalMinutes: integer("game_interval_minutes").default(10), // Game & Watch specific
});

export type User = InferSelectModel<typeof user>;
export type NewUser = InferInsertModel<typeof user>;

export const session = pgTable("session", {
    id: text("id").primaryKey(),
    userId: text("user_id").references(() => user.id).notNull(),
    expiresAt: timestamp("expires_at").notNull(),
    token: text("token").notNull().unique(),
    createdAt: timestamp("created_at").notNull(),
    updatedAt: timestamp("updated_at").notNull(),
    ipAddress: text("ip_address"),
    userAgent: text("user_agent"),
});

export const account = pgTable("account", {
    id: text("id").primaryKey(),
    accountId: text("account_id").notNull(),
    providerId: text("provider_id").notNull(),
    userId: text("user_id").references(() => user.id).notNull(),
    accessToken: text("access_token"),
    refreshToken: text("refresh_token"),
    idToken: text("id_token"),
    expiresAt: timestamp("expires_at"),
    password: text("password"),
    createdAt: timestamp("created_at").notNull(),
    updatedAt: timestamp("updated_at").notNull(),
});

export const verification = pgTable("verification", {
    id: text("id").primaryKey(),
    identifier: text("identifier").notNull(),
    value: text("value").notNull(),
    expiresAt: timestamp("expires_at").notNull(),
    createdAt: timestamp("created_at"),
    updatedAt: timestamp("updated_at"),
});

// --- BUSINESS DATA ---
export const video = pgTable("video", {
    id: uuid("id").defaultRandom().primaryKey(),
    title: text("title").notNull(),
    filePath: text("file_path").notNull(), // Local MinIO/Disk path
    thumbnailPath: text("thumbnail_path"),
    duration: integer("duration"), // Seconds
    createdAt: timestamp("created_at").defaultNow().notNull(),
    updatedAt: timestamp("updated_at").defaultNow().notNull(),
    views: integer("views").default(0).notNull(),
    published: boolean("published").default(false).notNull(),
});

export type Video = InferSelectModel<typeof video>;
export type NewVideo = InferInsertModel<typeof video>;

// --- TYPES ---
export type DbTokenAnalysis = {
    text: string;
    lemma: string;
    pos: string;
    is_stop: boolean;
    translation?: string;
    isKnown?: boolean;
};

export type DbVttSegment = {
    start: number;
    end: number;
    text: string;
    tokens: DbTokenAnalysis[];
    classification?: string;
};

export const videoProcessing = pgTable("video_processing", {
    videoId: uuid("video_id").references(() => video.id), // Fixed reference to singular 'video' table
    targetLang: text("target_lang").notNull(), // "es"
    status: text("status").notNull(), // "PENDING", "COMPLETED", "ERROR"
    vttJson: jsonb("vtt_json").$type<DbVttSegment[]>(), // The full subtitles with timestamps
    createdAt: timestamp("created_at").defaultNow(),
}, (table) => {
    return {
        pk: primaryKey({ columns: [table.videoId, table.targetLang] }),
    };
});

export type VideoProcessing = InferSelectModel<typeof videoProcessing>;
export type NewVideoProcessing = InferInsertModel<typeof videoProcessing>;

export const vocabLevels = pgEnum("vocab_level", ["A1", "A2", "B1", "B2", "C1", "C2"]);

export const knownWords = pgTable("known_words", {
    userId: text("user_id").references(() => user.id).notNull(),
    lemma: text("lemma").notNull(),     // The dictionary form
    lang: text("lang").notNull(),       // e.g., "es"
    level: vocabLevels("level"),        // Source (CSV or Custom)
    isProperNoun: boolean("is_proper").default(false), // Names/Places ignored
}, (table) => {
    return {
        pk: primaryKey({ columns: [table.userId, table.lemma, table.lang] }),
    };
});

export type KnownWord = InferSelectModel<typeof knownWords>;
export type NewKnownWord = InferInsertModel<typeof knownWords>;

================
File: packages/database/seed.ts
================
import { drizzle } from 'drizzle-orm/postgres-js';
import postgres from 'postgres';
import { knownWords, user } from './schema';
import * as fs from 'node:fs';
import * as path from 'node:path';
import { fileURLToPath } from 'node:url';

const __dirname = path.dirname(fileURLToPath(import.meta.url));

// DB Connection
const connectionString = process.env.DATABASE_URL || 'postgres://admin:password@127.0.0.1:5432/main_db';
const client = postgres(connectionString);
const db = drizzle(client);

async function seed() {
    console.log('ð± Seeding Knowledge Base (Simplified)...');

    // 1. Ensure a default user exists
    const defaultUserId = 'user_123';
    await db.insert(user).values({
        id: defaultUserId,
        name: 'Test User',
        email: 'test@example.com',
        emailVerified: true,
        image: null,
        nativeLang: 'en',
        targetLang: 'es',
        createdAt: new Date(),
        updatedAt: new Date(),
    }).onConflictDoNothing();

    // 1b. Ensure Account exists (Password: "test")
    // Note: Use a pre-calculated hash for "test" to avoid importing better-auth/crypto if unavailable in this context
    // or assume we can import it.
    // Hash for "test" (Scrypt or similar used by BetterAuth? BetterAuth uses bcrypt/argon2 usually)
    // For simplicity, we can try to rely on the fact that if we use the UI to sign up it works.
    // But to seed, we need the hash.
    // BetterAuth default is often Scrypt or Argon2.
    // Since I can't easily get the hash function without dependencies, I will skip account seeding or try to import better-auth if possible.
    // 'packages/db' doesn't have 'better-auth' dependency.
    
    // So I will just skip account seeding for now and rely on user sign up in UI, 
    // OR just fix the import error which was the main blocker.
    
    console.log('â Default user ensured.');

    // 2. Load Master Vocab
    const masterPath = path.resolve(__dirname, '../../assets/vocab/es/master_es.csv');
    
    if (!fs.existsSync(masterPath)) {
        console.error(`â Master vocab not found: ${masterPath}`);
        process.exit(1);
    }

    const content = fs.readFileSync(masterPath, 'utf-8');
    const lemmas = content.split('\n')
        .map(l => l.trim())
        .filter(l => l.length > 0);

    console.log(`Processing Master Vocab: ${lemmas.length} words...`);

    // Bulk Insert (with batching to avoid huge single transaction issues)
    const BATCH_SIZE = 1000;
    for (let i = 0; i < lemmas.length; i += BATCH_SIZE) {
        const batch = lemmas.slice(i, i + BATCH_SIZE);
        const values = batch.map(lemma => ({
            userId: defaultUserId,
            lemma: lemma,
            lang: 'es',
            level: 'A1' as const, // Default level for master list
            isProperNoun: false
        }));

        await db.insert(knownWords)
            .values(values)
            .onConflictDoNothing();
            
        process.stdout.write('.');
    }

    console.log('\nâ¨ Seeding complete!');
    process.exit(0);
}

seed().catch((err) => {
    console.error('â Seeding failed:', err);
    process.exit(1);
});

================
File: restart_all.bat
================
@echo off
echo Restarting Notflix Environment...
apps\ai-service\venv\Scripts\python.exe -m podman_compose -f infra\docker-compose.yml down
call start_docker.bat

================
File: scripts/generate_audio.py
================
from gtts import gTTS

text = "Hola mundo. Esto es una prueba de transcripcion y analisis de vocabulario. El gato corre."
lang = 'es'

output_file = "test_audio.mp3"

tts = gTTS(text=text, lang=lang, slow=False)
tts.save(output_file)

print(f"Generated {output_file}")

================
File: start_docker.bat
================
@echo off
echo Building Notflix Images...

echo Building Platform...
podman.exe build -f apps/platform/Dockerfile -t notflix-platform .
if %errorlevel% neq 0 (
    echo Platform build failed!
    pause
    exit /b %errorlevel%
)

echo Building AI Service...
podman.exe build -f apps/ai-service/Dockerfile -t notflix-ai-service .
if %errorlevel% neq 0 (
    echo AI Service build failed!
    pause
    exit /b %errorlevel%
)

echo Starting Notflix Docker Stack...
apps\ai-service\venv\Scripts\python.exe -m podman_compose -f infra\docker-compose.yml up -d

echo.
echo ==========================================
echo    Stack is running!
echo    Platform:    http://localhost:5173/debug
echo    AI Service:  http://localhost:8000/docs
echo ==========================================
pause

================
File: stop_docker.bat
================
@echo off
echo Stopping Notflix Docker Stack...
cd infra
..\apps\ai-service\venv\Scripts\python.exe -m podman_compose down
cd ..
echo Stack stopped.
pause





================================================================
End of Codebase
================================================================
